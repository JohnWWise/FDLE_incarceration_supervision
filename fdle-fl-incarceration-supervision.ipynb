{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db23250e",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-07-27T18:39:11.085222Z",
     "iopub.status.busy": "2024-07-27T18:39:11.084862Z",
     "iopub.status.idle": "2024-07-27T18:40:46.728393Z",
     "shell.execute_reply": "2024-07-27T18:40:46.727387Z"
    },
    "papermill": {
     "duration": 95.658171,
     "end_time": "2024-07-27T18:40:46.731106",
     "exception": false,
     "start_time": "2024-07-27T18:39:11.072935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markdown2\r\n",
      "  Downloading markdown2-2.5.0-py2.py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Downloading markdown2-2.5.0-py2.py3-none-any.whl (47 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: markdown2\r\n",
      "Successfully installed markdown2-2.5.0\r\n",
      "Collecting openai\r\n",
      "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\r\n",
      "Downloading openai-1.37.1-py3-none-any.whl (337 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: openai\r\n",
      "Successfully installed openai-1.37.1\r\n",
      "Collecting langchain_core\r\n",
      "  Downloading langchain_core-0.2.24-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (6.0.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (1.33)\r\n",
      "Collecting langsmith<0.2.0,>=0.1.75 (from langchain_core)\r\n",
      "  Downloading langsmith-0.1.93-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting packaging<25,>=23.2 (from langchain_core)\r\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (2.5.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (8.2.3)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\r\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain_core)\r\n",
      "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (2.32.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (2.14.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2024.2.2)\r\n",
      "Downloading langchain_core-0.2.24-py3-none-any.whl (377 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langsmith-0.1.93-py3-none-any.whl (139 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain_core\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "  Attempting uninstall: orjson\r\n",
      "    Found existing installation: orjson 3.9.10\r\n",
      "    Uninstalling orjson-3.9.10:\r\n",
      "      Successfully uninstalled orjson-3.9.10\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 24.4.1 requires cubinlinker, which is not installed.\r\n",
      "cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 24.4.1 requires ptxcompiler, which is not installed.\r\n",
      "cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "keras-cv 0.9.0 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.12.1 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\r\n",
      "cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\r\n",
      "distributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\r\n",
      "jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "rapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\r\n",
      "rapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed langchain_core-0.2.24 langsmith-0.1.93 orjson-3.10.6 packaging-24.1\r\n",
      "Collecting langchain-openai\r\n",
      "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.24 in /opt/conda/lib/python3.10/site-packages (from langchain-openai) (0.2.24)\r\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from langchain-openai) (1.37.1)\r\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\r\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (6.0.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (0.1.93)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (24.1)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (2.5.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.24->langchain-openai) (8.2.3)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.9.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.6)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.24->langchain-openai) (2.4)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.24->langchain-openai) (3.10.6)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.24->langchain-openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.24->langchain-openai) (2.14.6)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.18)\r\n",
      "Downloading langchain_openai-0.1.19-py3-none-any.whl (47 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\r\n",
      "Successfully installed langchain-openai-0.1.19 tiktoken-0.7.0\r\n",
      "Collecting langchain-community\r\n",
      "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.9.1)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.6)\r\n",
      "Collecting langchain<0.3.0,>=0.2.9 (from langchain-community)\r\n",
      "  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.2.24)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.1.93)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (1.26.4)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (8.2.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\r\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.9->langchain-community)\r\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (2.5.3)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community) (1.33)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community) (24.1)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.9.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain-community) (2.4)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (2.14.6)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\r\n",
      "Downloading langchain_community-0.2.10-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain-0.2.11-py3-none-any.whl (990 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\r\n",
      "Installing collected packages: langchain-text-splitters, langchain, langchain-community\r\n",
      "Successfully installed langchain-0.2.11 langchain-community-0.2.10 langchain-text-splitters-0.2.2\r\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.11)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.24)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.93)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (24.1)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (2.4)\r\n",
      "Collecting langgraph\r\n",
      "  Downloading langgraph-0.1.15-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.22 in /opt/conda/lib/python3.10/site-packages (from langgraph) (0.2.24)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (6.0.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (0.1.93)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (24.1)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (2.5.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (8.2.3)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.22->langgraph) (2.4)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.10.6)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (2.32.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.22->langgraph) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.22->langgraph) (2.14.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.22->langgraph) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (2024.2.2)\r\n",
      "Downloading langgraph-0.1.15-py3-none-any.whl (102 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: langgraph\r\n",
      "Successfully installed langgraph-0.1.15\r\n"
     ]
    }
   ],
   "source": [
    "!pip install markdown2\n",
    "!pip install openai\n",
    "!pip install langchain_core\n",
    "!pip install langchain-openai\n",
    "!pip install -U langchain-community\n",
    "!pip install langchain\n",
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d152522",
   "metadata": {
    "papermill": {
     "duration": 0.015437,
     "end_time": "2024-07-27T18:40:46.762558",
     "exception": false,
     "start_time": "2024-07-27T18:40:46.747121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<style>\n",
    "    .custom-header {\n",
    "        color: #4a77d4;\n",
    "        border-bottom: 2px solid #4a77d4;\n",
    "        padding-bottom: 5px;\n",
    "    }\n",
    "    .custom-text {\n",
    "        font-family: Arial, sans-serif;\n",
    "        line-height: 1.6;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<h1 class=\"custom-header\">Exploration of Florida Corrections Data with AI</h1>\n",
    "\n",
    "<h3 class=\"custom-header\">Abstract</h3>\n",
    "\n",
    "<div style=\"background-color: #FFA07A; padding: 10px; border-radius: 5px;\">\n",
    "    This notebook project uses artificial intelligence to interactively present data provided by the Florida Department of Law Enforcement. After downloading and cleaning the dataset on Florida Department of Corrections incarceration and supervision data, I embedded AI to present the data along with interactive visualizations to represent the data's condition and contents. After the AI presentations, a chatbot has been integrated, allowing users to ask questions, request customizations/adjustments of visualizations or novel ones, or discuss potential insights.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777aaba",
   "metadata": {
    "papermill": {
     "duration": 0.016208,
     "end_time": "2024-07-27T18:40:46.794083",
     "exception": false,
     "start_time": "2024-07-27T18:40:46.777875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "   - [Project Overview](#Project-Overview)\n",
    "2. [Data Sources](#Data-Sources)\n",
    "   - [Data Origin and Access](#Data-Origin-and-Access)\n",
    "   - [Data Updates and Scope](#Data-Updates-and-Scope)\n",
    "   - Code Importing Libraries, Datasets, and API Keys\n",
    "3. [Preprocessing, Data Dictionaries, and AI Presentations](#Preprocessing,-Data-Dictionaries,-and-AI-Presentations )\n",
    "   - [Incarcerationsupervision_00000 File](#Incarcerationsupervision_00000-File)\n",
    "     - Code: Import, Cleaning, and Data Dictionary Generation\n",
    "     - Output: df_root Data Dictionary\n",
    "     - Code: Generating Visualizations\n",
    "     - Code: Embedding AI for Data Presentaion of Incarcerationsupervision_00000 dataset\n",
    "     - AI Presentation: Incarcerationsupervision_00000 file and Visualizations\n",
    "   - [IncarcerationSupervisionCharge_00000 File](#IncarcerationSupervisionCharge_00000-File)\n",
    "     - Code: Import, Cleaning, and Data Dictionary Generation\n",
    "     - Output: Data Dictionary\n",
    "     - Code: Generating Visualizations\n",
    "     - Code: Embedding AI for Data Presentaion of IncarcerationSupervisionCharge_00000 dataset\n",
    "     - AI Presentation: IncarcerationSupervisionCharge_00000 file and Visualizations\n",
    "   - [IncarcerationSupervisionDisciplinary_00000 File](#IncarcerationSupervisionDisciplinary_00000-File)\n",
    "     - Code: Import, Cleaning, and Data Dictionary Generation\n",
    "     - Output: Data Dictionary\n",
    "     - Code: Generating Visualizations\n",
    "     - Code: Embedding AI for Data Presentaion of IncarcerationsupervisionDisciplinary_00000 dataset\n",
    "     - AI Presentation: IncarcerationsupervisionDisciplinary_00000 file and Visualizations\n",
    "4. [AI Chatbot](#Exploratory-Data-Analysis-EDA)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739518a2",
   "metadata": {
    "papermill": {
     "duration": 0.015302,
     "end_time": "2024-07-27T18:40:46.825138",
     "exception": false,
     "start_time": "2024-07-27T18:40:46.809836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "## Project Overview\n",
    "# Florida Department of Corrections Data Access Project\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This initiative aims to enhance public access to Florida Department of Corrections (FDOC) data, as made available by the Florida Department of Law Enforcement (FDLE). The project seeks to transform technically available but practically inaccessible public data into a truly accessible and understandable resource.\n",
    "\n",
    "## Author Background\n",
    "\n",
    "The project lead brings a unique perspective to this work:\n",
    "\n",
    "- Spent nearly 19 years in the FDOC system\n",
    "- Earned a degree in data science post-incarceration\n",
    "- Currently works as a data annotator\n",
    "- Planning to pursue a master's degree in information and data science\n",
    "\n",
    "The author's experience of incarceration provides valuable context for understanding the data and its importance. However, the author has found that this experience can make the objective presentation of incarceration data difficult.\n",
    "\n",
    "## Project Goals\n",
    "\n",
    "1. Clean and organize FDOC data that FDLE is legally required to make public\n",
    "2. Create a more accessible portal for this data, addressing limitations of the current FDLE public dashboard\n",
    "3. Provide a platform for public, researchers, and policymakers to explore and analyze the data independently\n",
    "4. Integrate AI assistance to enhance data navigation and comprehension (experimental approach)\n",
    "\n",
    "## Key Principles\n",
    "\n",
    "- **Objectivity**: The project aims to present data as objectively as possible, without drawing conclusions about the correctional or criminal legal systems\n",
    "- **Transparency**: By improving access to information, the project seeks to facilitate more informed discussions about Florida's correctional system\n",
    "- **Data Limitations**: Acknowledge and highlight gaps or unclear areas in current reporting\n",
    "- **Accessibility**: Transform technically available but difficult-to-use public data into a truly accessible and understandable resource\n",
    "\n",
    "## Expected Impact\n",
    "\n",
    "This project has the potential to:\n",
    "- Empower researchers, policymakers, and the public with better access to critical information\n",
    "- Highlight areas where data collection or reporting could be improved\n",
    "- Foster more informed discussions and decision-making regarding Florida's correctional system\n",
    "- Demonstrate innovative approaches to making public data more accessible and useful\n",
    "\n",
    "# Data Sources\n",
    "\n",
    "The data used in this project is sourced from the Florida Department of Law Enforcement (FDLE) as part of the Criminal Justice Data Transparency (CJDT) initiative. This initiative was established by the Florida Legislature through Florida Statutes §900.05 and §943.6871 to increase public visibility of criminal justice processes throughout the state and provide policymakers with information for informed decision-making. As per the CJDT data specifications it should include the records of juveniles treated as adults and the records of adults only.\n",
    "\n",
    "\n",
    "### Data Origin and Access\n",
    "\n",
    "The raw data is available through the [FDC Incarceration and Supervision Reports](https://www.fdle.state.fl.us/CJAB/CJDT/FDC-IS-Reports) page on the FDLE website.\n",
    "\n",
    "For a description of the CJDT initiative and the data it encompasses, please refer to the [Criminal Justice Data Transparency](https://www.fdle.state.fl.us/CJAB/CJDT) page.\n",
    "\n",
    "In this project, we are specifically working with the Incarceration and Supervision Reports from the Florida Department of Corrections, which form a subset of the larger FDLE CJDT initiative.\n",
    "\n",
    "**The following context from the first of the two previous links is of critical importance:**\n",
    "\n",
    "<div style=\"background-color: #f0f0f0; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "\"The CJDT data collection process began in 2020 upon establishing state and local system capabilities that allow electronic data transmission from the contributor agencies to FDLE. CJDT records go only as far back as the inception of the initiative in 2018. However, if individual agencies choose to provide older records as part of their submission process, they will be included in the publicly available datasets.\"</div>\n",
    "\n",
    "It is **not clear** if the records in the dataset are for those currently in custody or under supervision, or if they include everyone who has been under the jurisdiction of the Florida Department of Corrections since that time.\n",
    "\n",
    "### Data Updates\n",
    "\n",
    "While the FDLE updates the CJDT data daily, this project operates on a monthly update cycle. The data used in this analysis is manually retrieved and updated on a monthly basis. The project may eventually be updated to establish a live connection to the data source.\n",
    "\n",
    "The most recent data download used in this analysis was performed on 2024-07-07.\n",
    "\n",
    "This notebook is designed to dynamically update its analysis when new data is provided. To update the data:\n",
    "\n",
    "1. Download and unzip the latest data file from the FDLE website. This single file contains all three required datasets.\n",
    "2. Upload the new file to this notebook's environment.\n",
    "3. Update the filepath in the notebook to point to the new file.\n",
    "4. Run the notebook to automatically incorporate the new data into the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8e1f9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:40:46.858118Z",
     "iopub.status.busy": "2024-07-27T18:40:46.857370Z",
     "iopub.status.idle": "2024-07-27T18:40:53.072659Z",
     "shell.execute_reply": "2024-07-27T18:40:53.071673Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 6.23453,
     "end_time": "2024-07-27T18:40:53.074984",
     "exception": false,
     "start_time": "2024-07-27T18:40:46.840454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Working with files from:\n",
    "update_path = 'fdle-fl-data-2024-07'\n",
    "\n",
    "# Picking an AI model\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "# Libraries \n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import folium\n",
    "import altair as alt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import openai\n",
    "import ipywidgets as widgets\n",
    "from io import StringIO\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from markdown2 import markdown\n",
    "from typing import Union, Tuple, Dict, Any\n",
    "from folium.plugins import MarkerCluster\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.tools import tool, Tool\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import branca.colormap as cm\n",
    "\n",
    "\n",
    "\n",
    "# Datasets\n",
    "df_charges = pd.read_csv('/kaggle/input/' + update_path + '/IncarcerationSupervisionCharge_00000.csv')\n",
    "df_dis = pd.read_csv('/kaggle/input/' + update_path + '/IncarcerationSupervisionDisciplinary_00000.csv')\n",
    "df_root = pd.read_csv('/kaggle/input/' + update_path + '/Incarcerationsupervision_00000.csv')\n",
    "\n",
    "# Bringing in API Keys\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"OpenAIKey\")\n",
    "secret_value_1 = user_secrets.get_secret(\"tracker API\")\n",
    "\n",
    "# Connecting to Langsmith for Model Traces\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = secret_value_1\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"fdle-fdoc-data\"\n",
    "\n",
    "# Function for parsing markdown metadata\n",
    "def extract_rows(markdown_string, column_names):\n",
    "    results = []\n",
    "    \n",
    "    for column_name in column_names:\n",
    "        # Pattern to match the entire row\n",
    "        pattern = rf\"\\| *{re.escape(column_name)} *\\|.*?(?=\\n\\||\\Z)\"\n",
    "        \n",
    "        # Search for the pattern in the markdown string\n",
    "        match = re.search(pattern, markdown_string, re.DOTALL)\n",
    "        \n",
    "        if match:\n",
    "            # Add the matched row to the results, stripping any leading/trailing whitespace\n",
    "            results.append(match.group().strip())\n",
    "        else:\n",
    "            results.append(f\"Column '{column_name}' not found in the markdown string.\")\n",
    "    \n",
    "    # Join all results into a single string, separated by newlines\n",
    "    return '\\n'.join(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410cf259",
   "metadata": {
    "papermill": {
     "duration": 0.015591,
     "end_time": "2024-07-27T18:40:53.106634",
     "exception": false,
     "start_time": "2024-07-27T18:40:53.091043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Import, Preprocessing, and Data Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be489aa7",
   "metadata": {
    "papermill": {
     "duration": 0.015457,
     "end_time": "2024-07-27T18:40:53.137927",
     "exception": false,
     "start_time": "2024-07-27T18:40:53.122470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Incarcerationsupervision_00000 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83000a7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:40:53.171354Z",
     "iopub.status.busy": "2024-07-27T18:40:53.170497Z",
     "iopub.status.idle": "2024-07-27T18:40:53.438295Z",
     "shell.execute_reply": "2024-07-27T18:40:53.437425Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.286749,
     "end_time": "2024-07-27T18:40:53.440467",
     "exception": false,
     "start_time": "2024-07-27T18:40:53.153718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Incarcerationsupervision_00000 Data Information:\n",
       "- **Rows**: 112894\n",
       "- **Columns**: 18\n",
       "- **Memory Usage**: 4.22 MB\n",
       "### Data Details:\n",
       "| Column | Non-Null Count | Python Datatype | Description | Value Distribution |\n",
       "|--------|----------------|-------|-------------|---------------------|\n",
       "| INCARCERATION_SUPERVISION_ID | 112894 non-null | int64 | Anonymized unique identifier | 112894 unique values |\n",
       "| RACE_CODE | 112894 non-null | category | Race of the incarcerated/supervised person | White: 55703, Black: 51239, Unknown: 5815, American Indian or Alaska Native: 108, Asian: 29 |\n",
       "| SEX_CODE | 112894 non-null | category | Sex of the incarcerated/supervised person | Male: 103420, Female: 9474 |\n",
       "| ETHNICITY_CODE | 112894 non-null | category | Ethnicity of the incarcerated/supervised person | Not Hispanic or Latino: 97214, Hispanic or Latino: 13519, Unknown: 2161 |\n",
       "| CUSTODY_ADMISSION_DATE | 112894 non-null | datetime64[ns] | Date of admission to custody | Oldest: 1960-01-19, Most recent: 2024-06-04 |\n",
       "| SUPERVISION_BEGIN_DATE | 3665 non-null | datetime64[ns] | Date supervision began (if applicable) | Oldest: 2006-04-27, Most recent: 2024-05-14 |\n",
       "| PRIOR_INCARCERATION_IND | 112894 non-null | bool | Indicator for prior incarceration | False: 65542, True: 47352 |\n",
       "| INCARC_PROG_PARTICIPATION_IND | 112894 non-null | bool | Indicator for participation in incarceration programs | True: 59011, False: 53883 |\n",
       "| HIGHEST_EDUCATION_LEVEL | 107976 non-null | category | Highest level of education attained | Twelfth Grade: 39824, Eleventh Grade: 17371, Tenth Grade: 14324, Ninth Grade: 12960, Eighth Grade: 5185, Unknown: 4845, Second Year of College: 3807, First Year of College: 3464, Seventh Grade: 1918, Fourth Year of College: 1405, Six Grade: 1249, Third Year of College: 442, Fifth Grade: 384, Third Grade: 156, Second Year of Grad School: 151, Fourth Grade: 148, Second Grade: 103, Fourth or More Years of Grad School: 86, First Grade: 69, First Year of Grad School: 63, Third Year of Grad School: 22 |\n",
       "| SEXUAL_OFFENDER_IND | 112894 non-null | bool | Indicator for sexual offense status | False: 92159, True: 20735 |\n",
       "| GANG_AFFILIATION_IND | 112894 non-null | bool | Indicator for gang affiliation | False: 93225, True: 19669 |\n",
       "| INMATE_AGE | 112894 non-null | uint8 | Age of the incarcerated/supervised person | <18: 0, 18-24: 18394, 25-34: 37926, 35-44: 31355, 45-54: 16142, 55-64: 7471, 65+: 1606 |\n",
       "| CORRECTION_ADMISSION_REASON_DESC | 112894 non-null | category | Reason for admission to corrections | New Conviction: 95010, Violation of Probation - New Law Violation: 9900, Violation of Probation - Technical: 4655, Violation of Community Control - New Law Violation: 1641, Violation of Community Control - Technical: 1612, Violation of Post-Prison Supervision/Parole - New Law Violation: 56, Violation of Post-Prison Supervision/Parole - Technical: 20 |\n",
       "| CURRENT_INSTITUTION_ORI_TYPE_DESC | 112894 non-null | category | Name of Current institution | 120 unique values |\n",
       "| CUSTODY_RELEASE_REASON_DESC | 25310 non-null | category | Reason for release from custody (if applicable) | Released: 20070, Paroled/Probation: 4527, Discharged/Expiration: 689, Paroled: 24 |\n",
       "| INCARCERATION_CUSTODY_LEVEL_TYPE_DESC | 78637 non-null | category | Custody level type | Close: 33335, Medium: 26318, Minimum: 13509, Community: 5347, Maximum: 128 |\n",
       "| SUPERVISION_CATEGORY_DESC | 3665 non-null | category | Category of supervision (if applicable) | Probation: 2051, Post-Prison Supervision/Parole: 1271, Community Control: 343 |\n",
       "| COUNTY_DESCRIPTION | 112894 non-null | category | County of the institution | 52 unique values |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of columns to drop from the df_root DataFrame\n",
    "root_to_drop = ['STATE', 'UNIQUE_CORRELATION_ID', 'OWNER_ORI', 'PERSON_ID', 'MDM_PERSON_ID', 'CURRENT_INSTITUTION_ORI_TYP_CODE', 'INCAR_CUSTODY_LEVEL_TYPE_CODE', 'CORRECTION_ADMISSION_REASON_CODE', 'SUPERVISION_CATEGORY_CODE', 'AGENCY_NAME', 'CUSTODY_RELEASE_REASON_CODE']\n",
    "# Drop the specified columns\n",
    "df_root = df_root.drop(columns = root_to_drop)\n",
    "\n",
    "# Convert 'INMATE_AGE' column to unsigned 8-bit integer type\n",
    "int_columns = ['INMATE_AGE']\n",
    "for col in df_root[int_columns]:\n",
    "        df_root[col] = df_root[col].astype('uint8')        \n",
    "\n",
    "# Convert specified columns to categorical type\n",
    "categorical_columns = ['RACE_CODE', 'SEX_CODE', 'ETHNICITY_CODE', 'CORRECTION_ADMISSION_REASON_DESC', \n",
    "                       'CURRENT_INSTITUTION_ORI_TYPE_DESC', 'CUSTODY_RELEASE_REASON_DESC', 'SUPERVISION_CATEGORY_DESC', 'COUNTY_DESCRIPTION']\n",
    "for col in categorical_columns:\n",
    "    df_root[col] = df_root[col].astype('category')\n",
    "\n",
    "# Convert date columns to datetime type\n",
    "datetime_columns = ['CUSTODY_ADMISSION_DATE', 'SUPERVISION_BEGIN_DATE']\n",
    "for col in datetime_columns:\n",
    "    df_root[col] = pd.to_datetime(df_root[col])\n",
    "\n",
    "# Define the order of education levels\n",
    "education_order = [\n",
    "    'Unknown', 'First Grade', 'Second Grade', 'Third Grade', 'Fourth Grade', 'Fifth Grade',\n",
    "    'Six Grade', 'Seventh Grade', 'Eighth Grade', 'Ninth Grade', 'Tenth Grade',\n",
    "    'Eleventh Grade', 'Twelfth Grade', 'First Year of College', 'Second Year of College',\n",
    "    'Third Year of College', 'Fourth Year of College', 'First Year of Grad School',\n",
    "    'Second Year of Grad School', 'Third Year of Grad School', 'Fourth or More Years of Grad School'\n",
    "    \n",
    "]\n",
    "\n",
    "# Convert 'HIGHEST_EDUCATION_LEVEL' to an ordered categorical type\n",
    "df_root['HIGHEST_EDUCATION_LEVEL'] = pd.Categorical(\n",
    "    df_root['HIGHEST_EDUCATION_LEVEL'],\n",
    "    categories=education_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Define the order of custody levels\n",
    "custody_level_order = ['Community', 'Minimum', 'Medium', 'Close', 'Maximum']\n",
    "# Convert 'INCARCERATION_CUSTODY_LEVEL_TYPE_DESC' to an ordered categorical type\n",
    "df_root['INCARCERATION_CUSTODY_LEVEL_TYPE_DESC'] = pd.Categorical(\n",
    "    df_root['INCARCERATION_CUSTODY_LEVEL_TYPE_DESC'],\n",
    "    categories=custody_level_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Define descriptions for each column in df_root\n",
    "descriptions = [\n",
    "    \"Anonymized unique identifier\",\n",
    "    \"Race of the incarcerated/supervised person\",\n",
    "    \"Sex of the incarcerated/supervised person\",\n",
    "    \"Ethnicity of the incarcerated/supervised person\",\n",
    "    \"Date of admission to custody\",\n",
    "    \"Date supervision began (if applicable)\",\n",
    "    \"Indicator for prior incarceration\",\n",
    "    \"Indicator for participation in incarceration programs\",\n",
    "    \"Highest level of education attained\",\n",
    "    \"Indicator for sexual offense status\",\n",
    "    \"Indicator for gang affiliation\",\n",
    "    \"Age of the incarcerated/supervised person\",\n",
    "    \"Reason for admission to corrections\",\n",
    "    \"Name of Current institution\",\n",
    "    \"Reason for release from custody (if applicable)\",\n",
    "    \"Custody level type\",\n",
    "    \"Category of supervision (if applicable)\",\n",
    "    \"County of the institution\"\n",
    "]\n",
    "\n",
    "# Function to generate a Markdown table with DataFrame information\n",
    "def df_info_markdown(df, descriptions=None, display_output=True):\n",
    "    # Get basic DataFrame info\n",
    "    rows, cols = df.shape\n",
    "    memory_usage = df.memory_usage(deep=True).sum()\n",
    "    memory_usage_str = f\"{memory_usage / 1024**2:.2f} MB\" if memory_usage > 1024**2 else f\"{memory_usage / 1024:.2f} KB\"\n",
    "    \n",
    "    # Construct the Markdown content\n",
    "    content = f\"\"\"\n",
    "## Incarcerationsupervision_00000 Data Information:\n",
    "- **Rows**: {rows}\n",
    "- **Columns**: {cols}\n",
    "- **Memory Usage**: {memory_usage_str}\n",
    "### Data Details:\n",
    "| Column | Non-Null Count | Python Datatype | Description | Value Distribution |\n",
    "|--------|----------------|-------|-------------|---------------------|\n",
    "\"\"\"\n",
    "    # Columns that require value counts\n",
    "    value_count_columns = [\n",
    "        \"RACE_CODE\", \"SEX_CODE\", \"ETHNICITY_CODE\", \"PRIOR_INCARCERATION_IND\",\n",
    "        \"INCARC_PROG_PARTICIPATION_IND\", \"HIGHEST_EDUCATION_LEVEL\", \"SEXUAL_OFFENDER_IND\",\n",
    "        \"GANG_AFFILIATION_IND\", \"CORRECTION_ADMISSION_REASON_DESC\",\n",
    "        \"INCARCERATION_CUSTODY_LEVEL_TYPE_DESC\", \"SUPERVISION_CATEGORY_DESC\",\n",
    "        \"CUSTODY_RELEASE_REASON_DESC\"\n",
    "    ]\n",
    "    \n",
    "    # Iterate through columns to add their details to the Markdown table\n",
    "    for i, col in enumerate(df.columns):\n",
    "        dtype = df[col].dtype\n",
    "        non_null = df[col].count()\n",
    "        description = descriptions[i] if descriptions and i < len(descriptions) else \"\"\n",
    "        \n",
    "        # Determine value distribution based on column type\n",
    "        if col == \"INMATE_AGE\":\n",
    "            bins = [0, 18, 25, 35, 45, 55, 65, np.inf]\n",
    "            labels = ['<18', '18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "            age_bins = pd.cut(df[col], bins=bins, labels=labels, right=False)\n",
    "            value_dist = age_bins.value_counts().sort_index().to_dict()\n",
    "            value_dist_str = \", \".join([f\"{k}: {v}\" for k, v in value_dist.items()])\n",
    "        elif col in value_count_columns:\n",
    "            value_dist = df[col].value_counts().to_dict()\n",
    "            value_dist_str = \", \".join([f\"{k}: {v}\" for k, v in value_dist.items()])\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            value_dist_str = f\"Oldest: {df[col].min().strftime('%Y-%m-%d')}, Most recent: {df[col].max().strftime('%Y-%m-%d')}\"\n",
    "        else:\n",
    "            value_dist_str = f\"{df[col].nunique()} unique values\"\n",
    "        \n",
    "        content += f\"| {col} | {non_null} non-null | {dtype} | {description} | {value_dist_str} |\\n\"\n",
    "    \n",
    "    # Display the Markdown if display_output is True\n",
    "    if display_output:\n",
    "        display(Markdown(content))\n",
    "    \n",
    "    # Return the Markdown content as a string for AI summarizer\n",
    "    return content\n",
    "\n",
    "# Generate the Markdown content for df_root\n",
    "df_root_content = df_info_markdown(df_root, descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d126f2d",
   "metadata": {
    "papermill": {
     "duration": 0.016023,
     "end_time": "2024-07-27T18:40:53.473280",
     "exception": false,
     "start_time": "2024-07-27T18:40:53.457257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Code to Generate Visualizations for the IncarcerationSupervision_00000 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb190e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:40:53.507495Z",
     "iopub.status.busy": "2024-07-27T18:40:53.507110Z",
     "iopub.status.idle": "2024-07-27T18:40:56.234928Z",
     "shell.execute_reply": "2024-07-27T18:40:56.234005Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 2.747843,
     "end_time": "2024-07-27T18:40:56.237349",
     "exception": false,
     "start_time": "2024-07-27T18:40:53.489506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generating Visualizations\n",
    "## Demogrpahics Visual\n",
    "def combine_race_ethnicity(row):\n",
    "    race = row['RACE_CODE']\n",
    "    ethnicity = row['ETHNICITY_CODE']\n",
    "    if ethnicity == 'Hispanic or Latino':\n",
    "        return f\"{race} Hispanic or Latino\"\n",
    "    elif ethnicity == 'Not Hispanic or Latino':\n",
    "        return f\"{race} Non-Hispanic\"\n",
    "    else:  \n",
    "        return f\"{race} Unknown Ethnicity\"\n",
    "df_root['race_ethnicity'] = df_root.apply(combine_race_ethnicity, axis=1)\n",
    "\n",
    "age_mapping = {\n",
    "    (0, 17): '<18',\n",
    "    (18, 24): '18-24',\n",
    "    (25, 34): '25-34',\n",
    "    (35, 44): '35-44',\n",
    "    (45, 54): '45-54',\n",
    "    (55, 64): '55-64',\n",
    "    (65, float('inf')): '65+'\n",
    "}\n",
    "\n",
    "df_root['age_group'] = pd.cut(df_root['INMATE_AGE'], \n",
    "                                      bins=[0, 17, 24, 34, 44, 54, 64, float('inf')], \n",
    "                                      labels=[v for v in age_mapping.values()])\n",
    "\n",
    "aggregated_data = df_root.groupby(['age_group', 'SEX_CODE', 'race_ethnicity'], observed = True).size().reset_index(name='count')\n",
    "\n",
    "\n",
    "# Create the base chart\n",
    "base = alt.Chart(aggregated_data).mark_bar().encode(\n",
    "    y=alt.Y('age_group:O', \n",
    "            axis=None, \n",
    "            sort=['65+', '55-64', '45-54', '35-44', '25-34', '18-24', '<18']),  # Inverted order\n",
    "    color=alt.Color('race_ethnicity:N', scale=alt.Scale(scheme='tableau20')),\n",
    "    tooltip=['age_group', 'SEX_CODE', 'race_ethnicity', 'sum(count)']\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Calculate the maximum value for scaling\n",
    "max_value = aggregated_data.groupby('SEX_CODE', observed=True)['count'].sum().max()\n",
    "\n",
    "# Create the male chart (left side)\n",
    "male_chart = base.transform_filter(\n",
    "    alt.datum.SEX_CODE == 'Male'\n",
    ").encode(\n",
    "    x=alt.X('sum(count):Q', \n",
    "            title='Male',\n",
    "            scale=alt.Scale(domain=[0, max_value*.4]))\n",
    ")\n",
    "\n",
    "# Create the female chart (right side)\n",
    "female_chart = base.transform_filter(\n",
    "    alt.datum.SEX_CODE == 'Female'\n",
    ").encode(\n",
    "    x=alt.X('sum(count):Q', \n",
    "            title='Female',\n",
    "            scale=alt.Scale(domain=[max_value*.4, 0])),  # Reverse the scale\n",
    "    y=alt.Y('age_group:O', \n",
    "        axis=alt.Axis(title='Age Group'),\n",
    "        sort=['65+', '55-64', '45-54', '35-44', '25-34', '18-24', '<18'])\n",
    ")\n",
    "\n",
    "# Combine the charts\n",
    "pyramid = alt.hconcat(female_chart, male_chart, spacing=0).resolve_scale(\n",
    "    x='independent'\n",
    ")\n",
    "\n",
    "# Add chart title and labels\n",
    "pyramid_chart = pyramid.properties(\n",
    "    title='Demographic Age and Race Distribution by Sex'\n",
    ").configure_view(\n",
    "    stroke=None\n",
    ").configure_axis(\n",
    "    grid=False\n",
    ").configure_title(\n",
    "    fontSize=20,\n",
    "    font='Courier',\n",
    "    anchor='middle',\n",
    "    color='gray'\n",
    ").configure_legend(\n",
    "    orient='bottom',\n",
    "    title=None,\n",
    "    columns=3\n",
    ")\n",
    "pyramid_chart.save('Demographic_Age_and_Race_Distribution_by_Sex.html')\n",
    "\n",
    "## Education Visual\n",
    "education_tiers = {\n",
    "    'Unknown': 'Unknown',\n",
    "    'First Grade': 'Primary School',\n",
    "    'Second Grade': 'Primary School',\n",
    "    'Third Grade': 'Primary School',\n",
    "    'Fourth Grade': 'Primary School',\n",
    "    'Fifth Grade': 'Primary School',\n",
    "    'Six Grade': 'Primary School',\n",
    "    'Seventh Grade': 'Primary School',\n",
    "    'Eighth Grade': 'Primary School',\n",
    "    'Ninth Grade': 'High School',\n",
    "    'Tenth Grade': 'High School',\n",
    "    'Eleventh Grade': 'High School',\n",
    "    'Twelfth Grade': 'High School',\n",
    "    'First Year of College': 'College',\n",
    "    'Second Year of College': 'College',\n",
    "    'Third Year of College': 'College',\n",
    "    'Fourth Year of College': 'College',\n",
    "    'First Year of Grad School': 'Grad School',\n",
    "    'Second Year of Grad School': 'Grad School',\n",
    "    'Third Year of Grad School': 'Grad School',\n",
    "    'Fourth or More Years of Grad School': 'Grad School'\n",
    "}\n",
    "df_education = df_root[['HIGHEST_EDUCATION_LEVEL']]\n",
    "df_education = df_education['HIGHEST_EDUCATION_LEVEL'].value_counts().sort_index(ascending = False).reset_index(name='count').rename(columns={'index': 'education_level'})\n",
    "df_education['percentage'] = round((df_education['count'] / df_education['count'].sum()) * 100, 2)\n",
    "df_education['cumulative percentage'] = df_education['percentage'].cumsum()\n",
    "df_education['educational_tier'] = df_education['HIGHEST_EDUCATION_LEVEL'].map(education_tiers)\n",
    "df_education = df_education.sort_values('HIGHEST_EDUCATION_LEVEL').reset_index(drop=True)\n",
    "df_education = df_education.iloc[1:].reset_index(drop=True)\n",
    "eduction_chart = alt.Chart(df_education).mark_bar().encode(\n",
    "    x=alt.X('HIGHEST_EDUCATION_LEVEL:N', sort=education_order, axis=alt.Axis(labelAngle=-45)),\n",
    "    y=alt.Y('cumulative percentage:Q', axis=alt.Axis()),\n",
    "    color=alt.Color('educational_tier:N', scale=alt.Scale(scheme='set3')),\n",
    "    tooltip=['HIGHEST_EDUCATION_LEVEL', 'educational_tier', 'count', 'percentage', 'cumulative percentage']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title='Higest Grade Completed by Cumulative Percentage and Educational Tier'\n",
    ")\n",
    "eduction_chart.save('Higest_Grade_Completed_by_Cumulative_Percentage_and_Educational_Tier.html')\n",
    "\n",
    "# Dates Charts (full data for display, filtered data for model review)\n",
    "##full data\n",
    "df_custody = df_root[['CUSTODY_ADMISSION_DATE']].copy()\n",
    "df_supervision = df_root[['SUPERVISION_BEGIN_DATE']].copy()\n",
    "\n",
    "df_custody['CUSTODY_ADMISSION_DATE'] = df_custody['CUSTODY_ADMISSION_DATE'].dt.to_period('M')\n",
    "df_supervision['SUPERVISION_BEGIN_DATE'] = df_supervision['SUPERVISION_BEGIN_DATE'].dt.to_period('M')\n",
    "\n",
    "# Count occurrences by month\n",
    "count_by_month_custody = df_custody['CUSTODY_ADMISSION_DATE'].value_counts().sort_index().reset_index()\n",
    "count_by_month_supervision = df_supervision['SUPERVISION_BEGIN_DATE'].value_counts().sort_index().reset_index()\n",
    "\n",
    "# Rename columns\n",
    "count_by_month_custody.columns = ['Date', 'Count']\n",
    "count_by_month_supervision.columns = ['Date', 'Count']\n",
    "\n",
    "# Add a type column to distinguish between the two series\n",
    "count_by_month_custody['Type'] = 'Custody Admission'\n",
    "count_by_month_supervision['Type'] = 'Supervision Begin'\n",
    "\n",
    "# Combine the two dataframes\n",
    "df_combined = pd.concat([count_by_month_custody, count_by_month_supervision])\n",
    "\n",
    "# Convert Period to datetime for Altair\n",
    "df_combined['Date'] = df_combined['Date'].dt.to_timestamp()\n",
    "max_date = df_combined['Date'].max()\n",
    "# Create the Altair plot with initial view set using scale\n",
    "custody_supervision_vs_time = alt.Chart(df_combined).mark_line().encode(\n",
    "    x=alt.X('Date:T', title='Month', \n",
    "            scale=alt.Scale(domain=(pd.Timestamp('2021-01-01'), max_date))),\n",
    "    y=alt.Y('Count:Q', title='Count', \n",
    "            scale=alt.Scale(domain=(1, 2800))),\n",
    "    color=alt.Color('Type:N', \n",
    "                    legend=alt.Legend(\n",
    "                        title=\"Event Type\",\n",
    "                        orient=\"top-left\",  \n",
    "                        fillColor=\"white\",  \n",
    "                        strokeColor=\"gray\",  \n",
    "                        padding=10,  \n",
    "                        cornerRadius=5 \n",
    "                    )),\n",
    "    tooltip=['Type', 'Count', alt.Tooltip('Date:T', title='Date')]\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title='Counts of Custody Admissions and Supervison Starts, 2021 to Present'\n",
    ").interactive()\n",
    "\n",
    "# Configure the view\n",
    "view = custody_supervision_vs_time.configure_view(\n",
    "    continuousWidth=800,\n",
    "    continuousHeight=400,\n",
    "    stroke=None\n",
    ")\n",
    "\n",
    "view.save('Counts_of_Custody_Admissions_And_Supervison_Starts,_2021_To_Present.html')\n",
    "\n",
    "## Filtered data for passing to ai as .to_json()\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "# List of the last 3 years\n",
    "last_3_years = [current_year - i for i in range(1, 4)]\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = df_root[\n",
    "    (df_root['CUSTODY_ADMISSION_DATE'].dt.year.isin(last_3_years) | df_root['CUSTODY_ADMISSION_DATE'].isnull()) &\n",
    "    (df_root['SUPERVISION_BEGIN_DATE'].dt.year.isin(last_3_years) | df_root['SUPERVISION_BEGIN_DATE'].isnull())\n",
    "]\n",
    "\n",
    "filtered_df = df_root[\n",
    "    (df_root['CUSTODY_ADMISSION_DATE'].dt.year.isin(last_3_years) | df_root['CUSTODY_ADMISSION_DATE'].isnull()) &\n",
    "    (df_root['SUPERVISION_BEGIN_DATE'].dt.year.isin(last_3_years) | df_root['SUPERVISION_BEGIN_DATE'].isnull())\n",
    "]\n",
    "\n",
    "df_custody2 = filtered_df[['CUSTODY_ADMISSION_DATE']].copy()\n",
    "df_supervision2 = filtered_df[['SUPERVISION_BEGIN_DATE']].copy()\n",
    "\n",
    "df_custody2['CUSTODY_ADMISSION_DATE'] = df_custody2['CUSTODY_ADMISSION_DATE'].dt.to_period('M')\n",
    "df_supervision2['SUPERVISION_BEGIN_DATE'] = df_supervision2['SUPERVISION_BEGIN_DATE'].dt.to_period('M')\n",
    "\n",
    "# Count occurrences by month\n",
    "count_by_month_custody2 = df_custody2['CUSTODY_ADMISSION_DATE'].value_counts().sort_index().reset_index()\n",
    "count_by_month_supervision2 = df_supervision2['SUPERVISION_BEGIN_DATE'].value_counts().sort_index().reset_index()\n",
    "\n",
    "# Rename columns\n",
    "count_by_month_custody2.columns = ['Date', 'Count']\n",
    "count_by_month_supervision2.columns = ['Date', 'Count']\n",
    "\n",
    "# Add a type column to distinguish between the two series\n",
    "count_by_month_custody2['Type'] = 'Custody Admission'\n",
    "count_by_month_supervision2['Type'] = 'Supervision Begin'\n",
    "\n",
    "# Combine the two dataframes\n",
    "df_combined = pd.concat([count_by_month_custody2, count_by_month_supervision2])\n",
    "\n",
    "# Convert Period to datetime for Altair\n",
    "df_combined['Date'] = df_combined['Date'].dt.to_timestamp()\n",
    "max_date = df_combined['Date'].max()\n",
    "# Create the Altair plot with initial view set using scale\n",
    "custody_supervision_vs_time_ai = alt.Chart(df_combined).mark_line().encode(\n",
    "    x=alt.X('Date:T', title='Month', \n",
    "            scale=alt.Scale(domain=(pd.Timestamp('2021-01-01'), max_date))),\n",
    "    y=alt.Y('Count:Q', title='Count', \n",
    "            scale=alt.Scale(domain=(1, 2800))),\n",
    "    color=alt.Color('Type:N', \n",
    "                    legend=alt.Legend(\n",
    "                        title=\"Event Type\",\n",
    "                        orient=\"top-left\",  \n",
    "                        fillColor=\"white\",  \n",
    "                        strokeColor=\"gray\",  \n",
    "                        padding=10,  \n",
    "                        cornerRadius=5 \n",
    "                    )),\n",
    "    tooltip=['Type', 'Count', alt.Tooltip('Date:T', title='Date')]\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title='Counts of Custody Admissions and Supervison Starts, 2021 to Present'\n",
    ").interactive()\n",
    "\n",
    "# Configure the view\n",
    "view2 = custody_supervision_vs_time_ai.configure_view(\n",
    "    continuousWidth=800,\n",
    "    continuousHeight=400,\n",
    "    stroke=None\n",
    ")\n",
    "\n",
    "\n",
    "bool_columns = ['PRIOR_INCARCERATION_IND', 'INCARC_PROG_PARTICIPATION_IND', \n",
    "                'SEXUAL_OFFENDER_IND', 'GANG_AFFILIATION_IND']\n",
    "\n",
    "# Function to create a pie chart for a single column\n",
    "def create_pie_chart(column):\n",
    "    chart_data = df_root[column].value_counts().reset_index()\n",
    "    chart_data.columns = ['value', 'count']\n",
    "    chart_data['percentage'] = chart_data['count'] / chart_data['count'].sum() * 100\n",
    "    \n",
    "    base = alt.Chart(chart_data).encode(\n",
    "        theta='count:Q',\n",
    "        color='value:N',\n",
    "        tooltip=['value:N', 'count:Q', alt.Tooltip('percentage:Q', format='.1f')]\n",
    "    )\n",
    "\n",
    "    pie = base.mark_arc()\n",
    "    return (pie).properties(\n",
    "        title=column,\n",
    "        width=250,\n",
    "        height=250\n",
    "    )\n",
    "\n",
    "# Create pie charts for each boolean column\n",
    "charts = [create_pie_chart(col) for col in bool_columns]\n",
    "\n",
    "# Combine the charts into a 2x2 grid\n",
    "combined_pie_chart = alt.vconcat(\n",
    "    alt.hconcat(charts[0], charts[1]),\n",
    "    alt.hconcat(charts[2], charts[3])\n",
    ")\n",
    "# Display the chart\n",
    "combined_pie_chart.save('Combined_Pie_Carts_For_bools.html')\n",
    "\n",
    "cbf_palette = [\n",
    "    '#1170aa', '#fc7d0b', '#a3acb9', '#57606c', '#5fa2ce', \n",
    "    '#c85200', '#7b848f', '#e15759', '#76b7b2', '#59a14f',\n",
    "    '#edc948'\n",
    "]\n",
    "\n",
    "# Function to create a pie chart for a single column\n",
    "def create_pie_chart(df, column):\n",
    "    # Calculate value counts and percentages\n",
    "    chart_data = df[column].value_counts().reset_index()\n",
    "    chart_data.columns = ['category', 'count']\n",
    "    chart_data['percentage'] = chart_data['count'] / chart_data['count'].sum() * 100\n",
    "    \n",
    "    # Calculate the cumulative percentages and midpoints for label positioning\n",
    "    chart_data['cumulative'] = chart_data['percentage'].cumsum() - chart_data['percentage'] / 2\n",
    "    chart_data['angle'] = chart_data['cumulative'] * 2 * np.pi / 100\n",
    "    chart_data['x'] = np.cos(chart_data['angle']) * 0.5 + 0.5\n",
    "    chart_data['y'] = np.sin(chart_data['angle']) * 0.5 + 0.5\n",
    "\n",
    "    # Create the base chart\n",
    "    base = alt.Chart(chart_data).encode(\n",
    "        theta=alt.Theta('count:Q', stack=True),\n",
    "        color=alt.Color('category:N', scale=alt.Scale(range=cbf_palette)),\n",
    "        tooltip=['category:N', 'count:Q', alt.Tooltip('percentage:Q', format='.1f')]\n",
    "    )\n",
    "\n",
    "    # Create the pie chart\n",
    "    pie = base.mark_arc(outerRadius=120)\n",
    "    \n",
    "    # Combine pie and text\n",
    "    return (pie).properties(\n",
    "        title=column,\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "\n",
    "# Create pie charts for both columns\n",
    "admission_chart = create_pie_chart(df_root, 'CORRECTION_ADMISSION_REASON_DESC')\n",
    "release_chart = create_pie_chart(df_root, 'CUSTODY_RELEASE_REASON_DESC')\n",
    "\n",
    "# Combine the charts side by side\n",
    "reasons_chart = alt.hconcat(admission_chart, release_chart).properties(\n",
    "    title='Correction Admission Reasons vs Custody Release Reasons'\n",
    ")\n",
    "reasons_chart.save('Correction_Admission_Reasons_Vs_Custody_Release_Reasons.html')\n",
    "\n",
    "# Function to create a pie chart for a single column\n",
    "def create_pie_chart(df, column):\n",
    "    # Calculate value counts and percentages\n",
    "    chart_data = df[column].value_counts().reset_index()\n",
    "    chart_data.columns = ['category', 'count']\n",
    "    chart_data['percentage'] = chart_data['count'] / chart_data['count'].sum() * 100\n",
    "    \n",
    "    # Calculate the cumulative percentages and midpoints for label positioning\n",
    "    chart_data['cumulative'] = chart_data['percentage'].cumsum() - chart_data['percentage'] / 2\n",
    "    chart_data['angle'] = chart_data['cumulative'] * 2 * np.pi / 100\n",
    "    chart_data['x'] = np.cos(chart_data['angle']) * 0.5 + 0.5\n",
    "    chart_data['y'] = np.sin(chart_data['angle']) * 0.5 + 0.5\n",
    "\n",
    "    # Create the base chart\n",
    "    base = alt.Chart(chart_data).encode(\n",
    "        theta=alt.Theta('count:Q', stack=True),\n",
    "        color=alt.Color('category:N', scale=alt.Scale(range=cbf_palette)),\n",
    "        tooltip=['category:N', 'count:Q', alt.Tooltip('percentage:Q', format='.1f')]\n",
    "    )\n",
    "\n",
    "    # Create the pie chart\n",
    "    pie = base.mark_arc(outerRadius=120)\n",
    "    \n",
    "    # Combine pie and text\n",
    "    return (pie).properties(\n",
    "        title=column,\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "\n",
    "# Create pie charts for both columns\n",
    "custody_chart = create_pie_chart(df_root, 'INCARCERATION_CUSTODY_LEVEL_TYPE_DESC')\n",
    "sup_cat_chart = create_pie_chart(df_root, 'SUPERVISION_CATEGORY_DESC')\n",
    "\n",
    "# Combine the charts side by side\n",
    "cats_chart = alt.hconcat(custody_chart, sup_cat_chart).properties(\n",
    "    title='Incarceration Custody Level vs Supervision Categories'\n",
    ")\n",
    "cats_chart.save('Incarceration_Custody_Level_Vs_Supervision_Categories.html')\n",
    "\n",
    "value_counts = df_root['CURRENT_INSTITUTION_ORI_TYPE_DESC'].value_counts()\n",
    "\n",
    "# Convert to DataFrame for Altair\n",
    "df_counts = value_counts.reset_index()\n",
    "df_counts.columns = ['category', 'count']\n",
    "\n",
    "# Sort by count descending\n",
    "df_counts = df_counts.sort_values('count', ascending=False)\n",
    "\n",
    "# Create the stacked bar chart\n",
    "chart = alt.Chart(df_counts).mark_bar().encode(\n",
    "    y=alt.Y('category:N', \n",
    "            sort='-x', \n",
    "            title='Institution Type',\n",
    "            axis=alt.Axis(labelLimit=250, labelFontSize=8)),  # Increase label limit and decrease font size\n",
    "    x=alt.X('count:Q', title='Count'),\n",
    "    color=alt.Color('category:N', legend=None),\n",
    "    tooltip=['category', 'count']\n",
    ").properties(\n",
    "    title='Institutions by Count',\n",
    "    width=900,\n",
    "    height=2000  # Increase height significantly\n",
    ")\n",
    "\n",
    "# Add text labels\n",
    "text = chart.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=3,\n",
    "    fontSize=8  # Decrease font size for labels\n",
    ").encode(\n",
    "    text='count:Q'\n",
    ")\n",
    "\n",
    "# Combine chart and text\n",
    "institutions_chart = (chart + text).configure_axis(\n",
    "    labelFontSize=8,\n",
    "    titleFontSize=12\n",
    ").configure_title(\n",
    "    fontSize=14\n",
    ")\n",
    "\n",
    "institutions_chart.save('Institutions_by_Count.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9b60c",
   "metadata": {
    "papermill": {
     "duration": 0.015297,
     "end_time": "2024-07-27T18:40:56.268665",
     "exception": false,
     "start_time": "2024-07-27T18:40:56.253368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## AI Presentation of IncarcerationSupervison_00000 Dataset and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d02b32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:40:56.302275Z",
     "iopub.status.busy": "2024-07-27T18:40:56.301681Z",
     "iopub.status.idle": "2024-07-27T18:42:05.065375Z",
     "shell.execute_reply": "2024-07-27T18:42:05.064474Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 68.800005,
     "end_time": "2024-07-27T18:42:05.084405",
     "exception": false,
     "start_time": "2024-07-27T18:40:56.284400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: red;\"> \n",
       "\n",
       "# AI Generated Presentation of `IncarcerationSupervision_00000` and Visualizations\n",
       "## Demographics:\n",
       "\n",
       "### Overview of the Dataset\n",
       "The dataset contains metadata related to the demographics of incarcerated and supervised persons in Florida. It includes a total of 112,894 records, each identified by a unique identifier (INCARCERATION_SUPERVISION_ID). The dataset encompasses various demographic variables, including race, sex, ethnicity, and age.\n",
       "\n",
       "### Key Variables\n",
       "- **INCARCERATION_SUPERVISION_ID**: Anonymized unique identifier for each record (112,894 unique values).\n",
       "- **RACE_CODE**: Categorical variable representing the race of the incarcerated/supervised person. The distribution is as follows:\n",
       "  - White: 55,703\n",
       "  - Black: 51,239\n",
       "  - Unknown: 5,815\n",
       "  - American Indian or Alaska Native: 108\n",
       "  - Asian: 29\n",
       "- **SEX_CODE**: Categorical variable indicating the sex of the incarcerated/supervised person:\n",
       "  - Male: 103,420\n",
       "  - Female: 9,474\n",
       "- **ETHNICITY_CODE**: Categorical variable for ethnicity:\n",
       "  - Not Hispanic or Latino: 97,214\n",
       "  - Hispanic or Latino: 13,519\n",
       "  - Unknown: 2,161\n",
       "- **INMATE_AGE**: Age of the incarcerated/supervised person, categorized as follows:\n",
       "  - <18: 0\n",
       "  - 18-24: 18,394\n",
       "  - 25-34: 37,926\n",
       "  - 35-44: 31,355\n",
       "  - 45-54: 16,142\n",
       "  - 55-64: 7,471\n",
       "  - 65+: 1,606\n",
       "\n",
       "### Visualization: Demographic Age and Race Distribution by Sex\n",
       "The visualization presents the demographic distribution of incarcerated and supervised persons by age group and race, separated by sex. The data is represented in two bar charts, one for females and one for males, allowing for a comparative analysis of the demographic characteristics.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Demographic_Age_and_Race_Distribution_by_Sex.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Insights from the Visualization\n",
       "- The age group of 25-34 years has the highest representation among both sexes, indicating a significant concentration of incarcerated and supervised persons in this age range.\n",
       "- The racial distribution shows that Black Non-Hispanic individuals are notably prevalent in both male and female categories, particularly in the 25-34 and 35-44 age groups.\n",
       "- The visualization allows policymakers and researchers to identify demographic trends and disparities, which can inform targeted interventions and policy decisions.\n",
       "\n",
       "### Data Quality Considerations\n",
       "- The dataset includes a category for \"Unknown\" in race and ethnicity, which may indicate gaps in data collection or reporting. This could affect the accuracy of demographic analyses.\n",
       "- The age category \"<18\" has no recorded instances, suggesting that individuals under 18 are not included in this dataset, which may limit the understanding of youth demographics in the context of incarceration and supervision.\n",
       "\n",
       "This detailed examination of the demographics provides a foundation for further analysis and discussion regarding the implications of these trends in the context of criminal justice and social policy.\n",
       "\n",
       "## Education\n",
       "\n",
       "### Overview of Highest Education Level\n",
       "\n",
       "The dataset contains information on the highest level of education attained by 107,976 individuals. The variable **HIGHEST_EDUCATION_LEVEL** is categorized into various educational tiers, including Primary School, High School, College, and Grad School. The counts for each educational level are as follows:\n",
       "\n",
       "- **Twelfth Grade**: 39,824 (36.88%)\n",
       "- **Eleventh Grade**: 17,371 (16.09%)\n",
       "- **Tenth Grade**: 14,324 (13.27%)\n",
       "- **Ninth Grade**: 12,960 (12.0%)\n",
       "- **Eighth Grade**: 5,185 (4.8%)\n",
       "- **Seventh Grade**: 1,918 (1.78%)\n",
       "- **Sixth Grade**: 1,249 (1.16%)\n",
       "- **Fifth Grade**: 384 (0.36%)\n",
       "- **Fourth Grade**: 148 (0.14%)\n",
       "- **Third Grade**: 156 (0.14%)\n",
       "- **Second Grade**: 103 (0.1%)\n",
       "- **First Grade**: 69 (0.06%)\n",
       "- **Unknown**: 4,845 (4.49%)\n",
       "- **First Year of College**: 3,464 (3.21%)\n",
       "- **Second Year of College**: 3,807 (3.53%)\n",
       "- **Third Year of College**: 442 (0.41%)\n",
       "- **Fourth Year of College**: 1,405 (1.3%)\n",
       "- **First Year of Grad School**: 63 (0.06%)\n",
       "- **Second Year of Grad School**: 151 (0.14%)\n",
       "- **Third Year of Grad School**: 22 (0.02%)\n",
       "- **Fourth or More Years of Grad School**: 86 (0.08%)\n",
       "\n",
       "### Visualization of Educational Attainment\n",
       "\n",
       "The following visualization illustrates the highest grade completed by individuals, represented by cumulative percentage and categorized by educational tier. This bar chart provides insights into the distribution of educational attainment among the population.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Higest_Grade_Completed_by_Cumulative_Percentage_and_Educational_Tier.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Insights from the Visualization\n",
       "\n",
       "1. **Cumulative Percentage**: The cumulative percentage indicates the proportion of individuals who have completed a certain level of education or lower. For instance, by the time individuals reach the Twelfth Grade, approximately 45.63% of the population has completed that level or lower.\n",
       "\n",
       "2. **Educational Tiers**: The educational tiers are color-coded in the visualization, allowing for easy differentiation between Primary School, High School, College, and Grad School levels. The majority of individuals fall within the High School tier, with a significant drop-off in the College and Grad School tiers.\n",
       "\n",
       "3. **Data Quality Considerations**: The presence of the \"Unknown\" category (4,845 individuals) suggests that there may be gaps in the data collection process. This could impact the overall analysis and understanding of educational attainment within the population. It is essential to consider this limitation when interpreting the results.\n",
       "\n",
       "4. **Potential Research Directions**: Researchers may want to explore the implications of educational attainment on various outcomes, such as employment opportunities, recidivism rates, and social integration. The data can serve as a foundation for further studies on the relationship between education and other socio-economic factors.\n",
       "\n",
       "This visualization and the accompanying data provide a comprehensive view of the educational landscape among the incarcerated and supervised persons in Florida, highlighting both achievements and areas for potential improvement.\n",
       "\n",
       "## Dates\n",
       "\n",
       "### Context\n",
       "The Criminal Justice Data Transparency (CJDT) initiative began in 2020, aimed at enhancing the electronic data transmission capabilities of state and local agencies to the Florida Department of Law Enforcement (FDLE). The records available in this dataset date back to the inception of the initiative in 2018. However, it is important to note that the dataset may not include all individuals who have been under the jurisdiction of the Florida Department of Corrections since that time. Instead, it likely reflects only those who are currently or have recently been incarcerated or under supervision. This limitation could lead to a misleading perception of an increase in recent records, as the removal of older records may create the false impression of a rise in current numbers.\n",
       "\n",
       "### Dataset Variables\n",
       "The dataset includes the following key variables:\n",
       "\n",
       "- **CUSTODY_ADMISSION_DATE**: This variable records the date of admission to custody. It contains 112,894 non-null entries, with the oldest record dating back to January 19, 1960, and the most recent on June 4, 2024.\n",
       "  \n",
       "- **SUPERVISION_BEGIN_DATE**: This variable indicates the date supervision began, if applicable. It has 3,665 non-null entries, with the oldest record from April 27, 2006, and the most recent on May 14, 2024.\n",
       "\n",
       "### Visualization\n",
       "The following visualization presents the counts of custody admissions and supervision starts from January 2021 to December 2023. \n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Counts_of_Custody_Admissions_And_Supervison_Starts,_2021_To_Present.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Explanation of the Visualization\n",
       "The line chart illustrates two distinct types of events: **Custody Admission** and **Supervision Begin**. \n",
       "\n",
       "- **Custody Admission**: The data shows a significant increase in custody admissions from January 2021, starting with 771 admissions, peaking at 2,685 in March 2022, and then fluctuating over the subsequent months. The most recent data point in December 2023 indicates 1,665 custody admissions. This trend may suggest a growing number of individuals entering custody, but it is essential to consider the context of data collection and the potential exclusion of older records.\n",
       "\n",
       "- **Supervision Begin**: In contrast, the counts for supervision starts are considerably lower. The data begins with only 4 supervision starts in January 2021, with a gradual increase over time, reaching a peak of 331 in December 2023. This indicates a slower growth rate compared to custody admissions, which may reflect the nature of supervision programs and their implementation.\n",
       "\n",
       "### Insights\n",
       "The disparity between the counts of custody admissions and supervision starts raises questions about the dynamics of the criminal justice system in Florida. The significant increase in custody admissions could be indicative of various factors, including changes in law enforcement practices, policy shifts, or societal trends. Conversely, the relatively low and gradual increase in supervision starts may suggest challenges in the transition from custody to supervision or differences in the criteria for supervision eligibility.\n",
       "\n",
       "### Data Quality Concerns\n",
       "It is crucial to acknowledge potential data quality concerns, such as the incomplete representation of historical records and the implications of only including recent data. This limitation may skew the understanding of trends over time and could mislead policymakers and researchers regarding the effectiveness of interventions or changes in the criminal justice system.\n",
       "\n",
       "## Reasons\n",
       "\n",
       "### Overview\n",
       "This section presents the reasons for admission to corrections and the reasons for release from custody. The data includes two key categorical variables: `CORRECTION_ADMISSION_REASON_DESC` and `CUSTODY_RELEASE_REASON_DESC`. \n",
       "\n",
       "- **CORRECTION_ADMISSION_REASON_DESC**: This variable contains 112,894 non-null entries and categorizes the reasons for admission to corrections. The breakdown of reasons is as follows:\n",
       "  - New Conviction: 95,010 (84.2%)\n",
       "  - Violation of Probation - New Law Violation: 9,900 (8.8%)\n",
       "  - Violation of Probation - Technical: 4,655 (4.1%)\n",
       "  - Violation of Community Control - New Law Violation: 1,641 (1.5%)\n",
       "  - Violation of Community Control - Technical: 1,612 (1.4%)\n",
       "  - Violation of Post-Prison Supervision/Parole - New Law Violation: 56 (0.05%)\n",
       "  - Violation of Post-Prison Supervision/Parole - Technical: 20 (0.02%)\n",
       "\n",
       "- **CUSTODY_RELEASE_REASON_DESC**: This variable has 25,310 non-null entries and categorizes the reasons for release from custody. The breakdown is as follows:\n",
       "  - Released: 20,070 (79.3%)\n",
       "  - Paroled/Probation: 4,527 (17.9%)\n",
       "  - Discharged/Expiration: 689 (2.7%)\n",
       "  - Paroled: 24 (0.1%)\n",
       "\n",
       "### Visualizations\n",
       "The visualizations compare the reasons for admission to corrections against the reasons for release from custody. Each pie chart represents the distribution of the respective categories.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Correction_Admission_Reasons_Vs_Custody_Release_Reasons.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Insights\n",
       "1. **Admission Reasons**: The predominant reason for admission is \"New Conviction,\" which accounts for a significant majority (84.2%) of the total admissions. This suggests that new criminal activities are the primary driver for individuals entering the corrections system.\n",
       "\n",
       "2. **Release Reasons**: The majority of releases are categorized as \"Released\" (79.3%), indicating that a large portion of individuals complete their time or are otherwise released without further supervision. The relatively small percentages for \"Paroled/Probation\" and \"Discharged/Expiration\" suggest that fewer individuals are released under supervision.\n",
       "\n",
       "### Data Quality Considerations\n",
       "- The `CORRECTION_ADMISSION_REASON_DESC` variable has a high number of non-null entries, indicating good data completeness for admission reasons. However, the `CUSTODY_RELEASE_REASON_DESC` has fewer entries, which may suggest that not all release reasons are consistently recorded or that some individuals may not have a recorded release reason.\n",
       "- The categories for both variables are well-defined, but the small counts for some categories (e.g., \"Violation of Post-Prison Supervision/Parole - Technical\") may indicate that these are less common reasons, which could affect the overall analysis and insights drawn from the data. \n",
       "\n",
       "This detailed breakdown provides a comprehensive view of the reasons for admission and release, which can inform policymakers and researchers about trends and areas for potential reform in the corrections system.\n",
       "\n",
       "## Indicators:\n",
       "\n",
       "This section presents key indicators related to the metadata subset from the Florida Department of Corrections. The indicators provide insights into various aspects of the incarcerated and supervised persons within the dataset.\n",
       "\n",
       "### Indicator Variables:\n",
       "\n",
       "1. **PRIOR_INCARCERATION_IND**:\n",
       "   - **Description**: This boolean indicator signifies whether an individual has a history of prior incarceration.\n",
       "   - **Data**: \n",
       "     - **True**: 47,352 (41.9%)\n",
       "     - **False**: 65,542 (58.1%)\n",
       "   - **Non-null Count**: 112,894\n",
       "\n",
       "2. **INCARC_PROG_PARTICIPATION_IND**:\n",
       "   - **Description**: This boolean indicator shows whether an individual participated in incarceration programs.\n",
       "   - **Data**: \n",
       "     - **True**: 59,011 (52.3%)\n",
       "     - **False**: 53,883 (47.7%)\n",
       "   - **Non-null Count**: 112,894\n",
       "\n",
       "3. **SEXUAL_OFFENDER_IND**:\n",
       "   - **Description**: This boolean indicator identifies individuals who are classified as sexual offenders.\n",
       "   - **Data**: \n",
       "     - **True**: 20,735 (18.4%)\n",
       "     - **False**: 92,159 (81.6%)\n",
       "   - **Non-null Count**: 112,894\n",
       "\n",
       "4. **GANG_AFFILIATION_IND**:\n",
       "   - **Description**: This boolean indicator indicates whether an individual has gang affiliation.\n",
       "   - **Data**: \n",
       "     - **True**: 19,669 (17.4%)\n",
       "     - **False**: 93,225 (82.6%)\n",
       "   - **Non-null Count**: 112,894\n",
       "\n",
       "### Visualization:\n",
       "\n",
       "The following visualizations provide a graphical representation of the above indicators, allowing for a clearer understanding of the distribution of these characteristics among the incarcerated and supervised persons.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Combined_Pie_Carts_For_bools.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Insights from Visualizations:\n",
       "\n",
       "- **PRIOR_INCARCERATION_IND**: The pie chart indicates that a significant majority (58.1%) of individuals in the dataset do not have a history of prior incarceration, while 41.9% do. This could suggest a focus on rehabilitation for those with prior histories.\n",
       "  \n",
       "- **INCARC_PROG_PARTICIPATION_IND**: The participation in incarceration programs is relatively balanced, with a slight majority (52.3%) having participated. This may reflect the effectiveness of programs aimed at reducing recidivism.\n",
       "\n",
       "- **SEXUAL_OFFENDER_IND**: A small proportion (18.4%) of the population is classified as sexual offenders, which may have implications for policy and resource allocation in managing this group.\n",
       "\n",
       "- **GANG_AFFILIATION_IND**: Similar to the sexual offender status, gang affiliation is also relatively low at 17.4%. This could indicate a need for targeted interventions for those with gang ties.\n",
       "\n",
       "### Data Quality Considerations:\n",
       "\n",
       "- The dataset contains a total of 112,894 non-null entries for each indicator, which suggests a comprehensive collection of data. However, it is essential to consider that the boolean nature of these indicators may not capture the full complexity of individual circumstances.\n",
       "- The percentages are derived from the counts provided, and while they offer a clear view of the distribution, they should be interpreted with caution, especially in the context of policy-making and resource allocation.\n",
       "\n",
       "## Institutional Information\n",
       "\n",
       "### Overview\n",
       "This section presents data related to the custody levels of incarcerated persons and their corresponding supervision categories. The dataset includes two primary variables: **INCARCERATION_CUSTODY_LEVEL_TYPE_DESC** and **SUPERVISION_CATEGORY_DESC**. \n",
       "\n",
       "### Dataset Variables\n",
       "- **INCARCERATION_CUSTODY_LEVEL_TYPE_DESC**: This variable describes the custody level type of incarcerated persons. It contains 78,637 non-null entries and is categorized into the following levels:\n",
       "  - **Close**: 33,335 (42.39%)\n",
       "  - **Medium**: 26,318 (33.47%)\n",
       "  - **Minimum**: 13,509 (17.18%)\n",
       "  - **Community**: 5,347 (6.80%)\n",
       "  - **Maximum**: 128 (0.16%)\n",
       "\n",
       "- **SUPERVISION_CATEGORY_DESC**: This variable indicates the category of supervision applicable to the incarcerated persons. It has 3,665 non-null entries and includes:\n",
       "  - **Probation**: 2,051 (55.96%)\n",
       "  - **Post-Prison Supervision/Parole**: 1,271 (34.68%)\n",
       "  - **Community Control**: 343 (9.36%)\n",
       "\n",
       "### Visualizations\n",
       "The visualizations provide insights into the distribution of custody levels and supervision categories among incarcerated persons. \n",
       "\n",
       "1. **Incarceration Custody Level**: The pie chart illustrates the proportion of each custody level type. The **Close** custody level represents the largest segment, indicating that a significant number of incarcerated persons are held under close supervision. The **Maximum** custody level, however, accounts for a very small fraction, suggesting that only a limited number of individuals are in the highest security classification.\n",
       "\n",
       "2. **Supervision Categories**: The second pie chart displays the distribution of supervision categories. The majority of individuals are under **Probation**, which may reflect a trend towards community-based supervision rather than incarceration. The relatively small percentage of individuals under **Community Control** indicates that this form of supervision is less common.\n",
       "\n",
       "### Potential Insights\n",
       "- The dominance of the **Close** custody level suggests a need for further investigation into the factors leading to such high numbers in this category. \n",
       "- The high percentage of individuals on **Probation** may indicate effective rehabilitation programs that allow for supervised release rather than incarceration.\n",
       "- The low count in the **Maximum** custody level raises questions about the criteria for such classifications and whether they are being applied consistently.\n",
       "\n",
       "### Data Quality Considerations\n",
       "- The **INCARCERATION_CUSTODY_LEVEL_TYPE_DESC** variable has a high number of non-null entries, indicating good data quality. However, the **SUPERVISION_CATEGORY_DESC** variable has significantly fewer non-null entries, which may suggest incomplete data or underreporting in this category.\n",
       "- The small number of individuals classified under **Maximum** custody may warrant further scrutiny to ensure that the data accurately reflects the population.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Incarceration_Custody_Level_Vs_Supervision_Categories.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "## Locations\n",
       "\n",
       "### Overview of the Data\n",
       "The dataset provides a comprehensive overview of various institutions within the Florida Department of Corrections, detailing the number of incarcerated persons at each institution. The key variables in this dataset include:\n",
       "\n",
       "- **CURRENT_INSTITUTION_ORI_TYPE_DESC**: This categorical variable represents the name of the current institution, with a total of 120 unique values.\n",
       "- **COUNTY_DESCRIPTION**: This categorical variable indicates the county in which the institution is located, with 52 unique values.\n",
       "\n",
       "As of July 17, 2024, there are notable discrepancies between the reported capacities of certain institutions and the data available. For instance, the Central Florida Reception Center has a reported capacity of 3,066 persons according to Wikipedia, while the Florida Department of Corrections lists the capacity of the Reception and Medical Center at 1,503 persons, and the South Florida Reception Center at 1,315 persons. The reasons for these discrepancies remain unclear and warrant further investigation.\n",
       "\n",
       "### Visualization of Institutions by Count\n",
       "The following visualization illustrates the number of incarcerated persons at various institutions. The data is represented in a bar chart format, where the x-axis indicates the count of incarcerated persons, and the y-axis lists the institution types. Each bar is color-coded to represent different institutions, and the count of incarcerated persons is displayed on the bars for clarity.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Institutions_by_Count.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Insights from the Visualization\n",
       "1. **Institution Capacity**: The bar chart reveals that the **CENTRAL FLORIDA RECEPTION CENTER MAIN** has the highest count of incarcerated persons at **14,753**, followed by the **RECEPTION AND MEDICAL CENTER MAIN UNIT** with **8,982**. This indicates a significant concentration of incarcerated persons in these facilities.\n",
       "\n",
       "2. **Distribution Across Institutions**: The data shows a wide range of counts across different institutions, with some facilities housing over 10,000 persons while others, such as the **RECEPTION AND MEDICAL CENTER WORK CAMP**, have only **1**. This disparity raises questions about resource allocation and the management of incarcerated persons across the state.\n",
       "\n",
       "3. **Potential Data Quality Concerns**: The discrepancies in reported capacities versus actual counts, particularly for major institutions, suggest potential data quality issues. It is essential to verify the accuracy of the data and understand the reasons behind these differences to ensure effective policy-making and resource management.\n",
       "\n",
       "### Categorical Variable Values\n",
       "For the data scientist's reference, the following are the categorical variable values for **CURRENT_INSTITUTION_ORI_TYPE_DESC**:\n",
       "\n",
       "- CENTRAL FLORIDA RECEPTION CENTER MAIN\n",
       "- RECEPTION AND MEDICAL CENTER MAIN UNIT\n",
       "- SOUTH FLORIDA RECEPTION CENTER\n",
       "- FLORIDA WOMENS RECEPTION CENTER\n",
       "- NORTHWEST FLORIDA RECEPTION CENTER ANNEX\n",
       "- BLACKWATER CORRECTIONAL FACILITY\n",
       "- DEPARTMENT OF CORRECTIONS - HEADQUARTERS\n",
       "- GRACEVILLE CORRECTIONAL FACILITY\n",
       "- SOUTH BAY CORRECTIONAL FACILITY\n",
       "- GULF CORRECTIONAL INSTITUTION\n",
       "- COLUMBIA CORRECTIONAL INSTITUTION\n",
       "- OKEECHOBEE CORRECTIONAL INSTITUTION\n",
       "- EVERGLADES CORRECTIONAL INSTITUTION\n",
       "- POLK CORRECTIONAL INSTITUTION\n",
       "- COLUMBIA CORRECTIONAL INSTITUTION ANNEX\n",
       "- CENTRAL FLORIDA RECEPTION CENTER EAST\n",
       "- DESOTO CORRECTIONAL INSTITUTION ANNEX\n",
       "- WAKULLA CORRECTIONAL INSTITUTION\n",
       "- CENTURY CORRECTIONAL INSTITUTION\n",
       "- MARTIN CORRECTIONAL INSTITUTION\n",
       "- TAYLOR CORRECTIONAL INSTITUTION\n",
       "- MARION CORRECTIONAL INSTITUTION\n",
       "- LIBERTY CORRECTIONAL INSTITUTION\n",
       "- CALHOUN CORRECTIONAL INSTITUTION\n",
       "- HARDEE CORRECTIONAL INSTITUTION\n",
       "- SUMTER CORRECTIONAL INSTITUTION\n",
       "- DADE CORRECTIONAL INSTITUTION\n",
       "- WALTON CORRECTIONAL INSTITUTION\n",
       "- HAMILTON CORRECTIONAL INSTITUTION ANNEX\n",
       "- GADSDEN CORRECTIONAL FACILITY\n",
       "- SANTA ROSA CORRECTIONAL INSTITUTION\n",
       "- HOLMES CORRECTIONAL INSTITUTION\n",
       "- SANTA ROSA CORRECTIONAL INSTITUTION ANNEX\n",
       "- JEFFERSON CORRECTIONAL INSTITUTION\n",
       "- LOWELL CORRECTIONAL INSTITUTION ANNEX\n",
       "- FLORIDA STATE PRISON\n",
       "- MADISON CORRECTIONAL INSTITUTION\n",
       "- BAY CORRECTIONAL FACILITY\n",
       "- UNION CORRECTIONAL INSTITUTION\n",
       "- SUWANNEE CORRECTIONAL INSTITUTION ANNEX\n",
       "- MOORE HAVEN CORRECTIONAL FACILITY\n",
       "- CHARLOTTE CORRECTIONAL INSTITUTION\n",
       "- AVON PARK CORRECTIONAL INSTITUTION\n",
       "- TOMOKA CORRECTIONAL INSTITUTION\n",
       "- APALACHEE CORRECTIONAL INSTITUTION EAST UNIT\n",
       "- CROSS CITY CORRECTIONAL INSTITUTION\n",
       "- LAKE CITY CORRECTIONAL FACILITY\n",
       "- MAYO CORRECTIONAL INSTITUTION ANNEX\n",
       "- JACKSON CORRECTIONAL INSTITUTION\n",
       "- FRANKLIN CORRECTIONAL INSTITUTION\n",
       "- OKALOOSA CORRECTIONAL INSTITUTION\n",
       "- NORTHWEST FLORIDA RECEPTION CENTER MAIN UNIT\n",
       "- WAKULLA CORRECTIONAL INSTITUTION ANNEX\n",
       "- LAWTEY CORRECTIONAL INSTITUTION\n",
       "- RECEPTION AND MEDICAL CENTER WEST UNIT\n",
       "- LOWELL CORRECTIONAL INSTITUTION\n",
       "- SUWANNEE CORRECTIONAL INSTITUTION\n",
       "- ZEPHYRHILLS CORRECTIONAL INSTITUTION\n",
       "- HAMILTON CORRECTIONAL INSTITUTION\n",
       "- APALACHEE CORRECTIONAL INSTITUTION WEST UNIT\n",
       "- SOUTH FLORIDA RECEPTION CENTER SOUTH UNIT\n",
       "- LANCASTER CORRECTIONAL INSTITUTION\n",
       "- PUTNAM CORRECTIONAL INSTITUTION\n",
       "- AVON PARK WORK CAMP\n",
       "- BAKER RE-ENTRY CENTER\n",
       "- LAKE CORRECTIONAL INSTITUTION\n",
       "- GADSDEN RE-ENTRY CENTER\n",
       "- CROSS CITY EAST UNIT\n",
       "- EVERGLADES RE-ENTRY CENTER\n",
       "- NEW RIVER WORK CAMP\n",
       "- HERNANDO CORRECTIONAL INSTITUTION\n",
       "- HOMESTEAD CORRECTIONAL INSTITUTION\n",
       "- SAGO PALM RE-ENTRY CENTER\n",
       "- QUINCY CORRECTIONAL INSTITUTION ANNEX\n",
       "- LANCASTER WORK CAMP\n",
       "- POLK WORK CAMP\n",
       "- HARDEE WORK CAMP\n",
       "- SUNCOAST COMMUNITY RELEASE CENTER\n",
       "- OKALOOSA WORK CAMP\n",
       "- DESOTO WORK CAMP\n",
       "- MARTIN WORK CAMP\n",
       "- LOWELL WORK CAMP\n",
       "- SUMTER WORK CAMP\n",
       "- MARION WORK CAMP\n",
       "- BRIDGES OF LAKE CITY\n",
       "- TURNING POINT COMMUNITY RELEASE CENTER\n",
       "- ST. PETE COMMUNITY RELEASE CENTER\n",
       "- ORLANDO BRIDGE\n",
       "- THE TRANSITION HOUSE OF KISSIMMEE\n",
       "- BRIDGES OF ORLANDO\n",
       "- REALITY HOUSE COMMUNITY RELEASE CENTER\n",
       "- BRADENTON BRIDGE\n",
       "- THE TRANSITION HOUSE OF DINSMORE\n",
       "- KISSIMMEE COMMUNITY RELEASE CENTER\n",
       "- THE TRANSITION HOUSE OF TARPON SPRING\n",
       "- BRIDGES OF JACKSONVILLE\n",
       "- TALLAHASSEE COMMUNITY RELEASE CENTER\n",
       "- RE-ENTRY CENTER OF OCALA\n",
       "- WALTON WORK CAMP\n",
       "- THE TRANSITION HOUSE OF BARTOW\n",
       "- TOMOKA WORK CAMP\n",
       "- HOLMES WORK CAMP\n",
       "- CENTRAL FLORIDA RECEPTION CENTER SOUTH\n",
       "- BRIDGES OF COCOA\n",
       "- BRIDGES OF SANTA FE COMMUNITY RELEASE CENTER\n",
       "- HOLLYWOOD COMMUNITY RELEASE CENTER\n",
       "- JACKSONVILLE BRIDGE WORK RELEASE FACILITY\n",
       "- PENSACOLA COMMUNITY RELEASE CENTER\n",
       "- TOMOKA COMMUNITY RELEASE CENTER 290\n",
       "- LARGO ROAD PRISON\n",
       "- MADISON WORK CAMP\n",
       "- LOXAHATCHEE ROAD PRISON\n",
       "- SHISA HOUSE WEST\n",
       "- CENTURY WORK CAMP\n",
       "- CROSS CITY WORK CAMP\n",
       "- ORLANDO COMMUNITY RELEASE CENTER\n",
       "- WEST PALM BEACH COMMUNITY RELEASE CENTER\n",
       "- OPA LOCKA COMMUNITY RELEASE CENTER\n",
       "- ATLANTIC COMMUNITY RELEASE CENTER\n",
       "- RECEPTION AND MEDICAL CENTER WORK CAMP\n",
       "\n",
       "This detailed breakdown of the dataset and its insights can assist both the public and policymakers in understanding the current state of institutions within the Florida Department of Corrections. \n",
       " </span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating first AI Presentation\n",
    "system = \"\"\"You are a member of a data presentation team.\n",
    "The data you will present is a subset of metadata from a Florida Department of Law Enforcement file containing Florida Department of Corrections incarceration and supervision data. The main audience includes the public, researchers, and policymakers. This data has been downloaded in CSV format, cleaned, and used to create several visualizations. The purpose of the presentation is to make the information more accessible to the public.\n",
    "\n",
    "Key principles include objectivity, transparency, acknowledgment of data limitations, and accessibility. \n",
    "\n",
    "You will also have a secondary audience: a data scientist with access to the loaded data. During your presentation, highlight critical information for the data scientist so they become familiar with the dataset variable names and data structures. Clearly identify dataset variables and specify categorical variable values precisely, maintaining case. This does not apply to calculated visualization variables like ‘count’ since they are not a concern for the data scientist who will be working with the dataset later.\n",
    "\n",
    "When you receive data in JSON, Markdown, and text format:\n",
    "- The JSON data represents Altair visualizations.\n",
    "- The text includes:\n",
    "    - The subject of the metadata subset\n",
    "    - Additional context\n",
    "    - One html file paths, which correspond to the Altair plot visualization file paths.\n",
    "    \n",
    "You will:\n",
    "\n",
    "1. Use markdown formatting to enhance readability:\n",
    "    - Use the header ## to return the subject of the data, i.e., ## Demographics:\n",
    "    - Use the lower-level headers ### for subsections of your response.\n",
    "    \n",
    "2. For the html file path include a centered iframe tag in your markdown output to display the associated html file. Use the following format:\n",
    "\n",
    "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
    "\n",
    "<iframe src=\"html_file_name.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
    "\n",
    "</div>\n",
    "\n",
    "Use iframe only for the tag. Do not use img and do not use markdown tagging.\n",
    " \n",
    "3. Present all numerical data in context.\n",
    "4. Explain all visualizations, including potential insights.\n",
    "5. Do not conclude with a summary or conclusion.\n",
    "6. Unless instructed to be succinct, aim for lengthy and very detailed responses.\n",
    "7. Only include one iframe tag in each response.\n",
    "8. Do not refer to incarcerated or supervised persons as 'inmates'\n",
    " or 'offenders'. They are 'incarcerated' or 'supervised' persons.\n",
    "9. Address all unexpected data results and potential data quality concerns.\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system),\n",
    "    ('human', \"{data_str}\")\n",
    "])\n",
    "llm_1 = ChatOpenAI(openai_api_key=secret_value_0, temperature = 0.0, model = model) \n",
    "llm_chain_1 = prompt_template | llm_1\n",
    "\n",
    "demographic_columns = [\"INCARCERATION_SUPERVISION_ID\", \"RACE_CODE\",\"SEX_CODE\", \"ETHNICITY_CODE\", \"INMATE_AGE\"]\n",
    "demographic_rows = extract_rows(df_root_content, demographic_columns)\n",
    "education_columns = [\"HIGHEST_EDUCATION_LEVEL\"]\n",
    "education_rows = extract_rows(df_root_content, education_columns)\n",
    "dates_columns = ['CUSTODY_ADMISSION_DATE', 'SUPERVISION_BEGIN_DATE']\n",
    "dates_rows = extract_rows(df_root_content, dates_columns)\n",
    "reasons_columns = ['CORRECTION_ADMISSION_REASON_DESC', 'CUSTODY_RELEASE_REASON_DESC']\n",
    "reasons_rows = extract_rows(df_root_content, reasons_columns)\n",
    "tags_columns = ['PRIOR_INCARCERATION_IND', 'INCARC_PROG_PARTICIPATION_IND', 'SEXUAL_OFFENDER_IND', 'GANG_AFFILIATION_IND']\n",
    "tags_rows = extract_rows(df_root_content, tags_columns)\n",
    "institutional_columns = ['INCARCERATION_CUSTODY_LEVEL_TYPE_DESC', 'SUPERVISION_CATEGORY_DESC']\n",
    "institutional_rows = extract_rows(df_root_content, institutional_columns)\n",
    "location_columns = ['CURRENT_INSTITUTION_ORI_TYPE_DESC', 'COUNTY_DESCRIPTION']\n",
    "location_rows = extract_rows(df_root_content, location_columns)\n",
    "\n",
    "demographic_context = demographic_rows\n",
    "education_context = education_rows\n",
    "dates_context = \"\"\"Context: The Criminal Justice Data Transparency data collection process began in 2020 upon establishing state and local system capabilities that allow electronic data transmission from the contributor agencies to FDLE. CJDT records go only as far back as the inception of the initiative in 2018. However, if individual agencies choose to provide older records as part of their submission process, they will be included in the publicly available datasets.\" It is not clear if the records in the dataset are for those currently in custody or under supervision, or if they include everyone who has been under the jurisdiction of the Florida Department of Corrections since that time. The author posits that any observed 'increase' in recent data is likely an indication that the the former is the case, that only those who are currently or have recently been incarcerated or under supervision are included - that the removal of older records can create the false impression that there is a current rise in the recent number of records. <<Contect for AI only: The json data you are being passed is filtered to the last three years. This is different from the user-visible visualization, which is pannable back to earlier dates.>>\"\"\" + dates_rows\n",
    "reasons_context = reasons_rows\n",
    "tags_context = tags_rows\n",
    "institutional_context = institutional_rows\n",
    "location_context = location_rows + 'Critical Additional Context (please include in your response!): As of 2024-07-17, Wikipedia lists the capactiy of Central Florida Reception Center at 3066 persons, The Florida Department of Corrections lists the capacity of the Reception and Medical Center at 1,503 persons, Wikipedia lists the capactiy of South Florida Reception Center at 1,315 persons. The reason/reasons for the disparity between reality and the data are so far unknown.(please include this information in your response!)'\n",
    "\n",
    "# Getting AI Responses\n",
    "demographic_response = llm_chain_1.invoke(\n",
    "    {'data_str': \"Subject : Demographics  html filepath : 'Demographic_Age_and_Race_Distribution_by_Sex.html' \" + demographic_context + pyramid_chart.to_json()  + \"Important Instruction: Include only one iframe tag in this response.\"})\n",
    "education_response = llm_chain_1.invoke(\n",
    "    {'data_str': 'Subject : Education ' + education_context + eduction_chart.to_json()  + \"html filepath: 'Higest_Grade_Completed_by_Cumulative_Percentage_and_Educational_Tier' \" + 'Context: The visual represents a transformation of the underlying data. The raw data simply records the highest completed grade for each individual.'})\n",
    "dates_response = llm_chain_1.invoke(\n",
    "    {'data_str': 'Subject : Dates' + dates_context + view2.to_json()  + \"File path: 'Counts_of_Custody_Admissions_And_Supervison_Starts,_2021_To_Present.html' \"})\n",
    "reasons_response = llm_chain_1.invoke(\n",
    "    {'data_str': \"Subject : Reasons', File path: 'Correction_Admission_Reasons_Vs_Custody_Release_Reasons.html'\" + reasons_context + reasons_chart.to_json() + ' Important Instruction: Only include one iframe tag in this response.'})\n",
    "tags_response = llm_chain_1.invoke({'data_str':  \"Subject : Indicators File path: 'Combined_Pie_Carts_For_bools.html'\" + tags_context + combined_pie_chart.to_json() + ' Important Instruction: Only include one iframe tag in this response.'})\n",
    "institutional_response = llm_chain_1.invoke({'data_str': \"Subject : Institutional Information File path: 'Incarceration_Custody_Level_Vs_Supervision_Categories.html'\" + institutional_context + cats_chart.to_json() +' Important Instruction: Only include one iframe tag in this response.'})\n",
    "location_response = llm_chain_1.invoke({'data_str': \"Subject : Locations File path: 'Institutions_by_Count.html'\" + location_context + institutions_chart.to_json()})\n",
    "\n",
    "display(Markdown('<span style=\"color: red;\"> \\n\\n# AI Generated Presentation of `IncarcerationSupervision_00000` and Visualizations\\n' + demographic_response.content + '\\n\\n' + education_response.content + '\\n\\n' + dates_response.content + '\\n\\n' + reasons_response.content + '\\n\\n' + tags_response.content + '\\n\\n' + institutional_response.content + '\\n\\n' + location_response.content + ' \\n </span>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e0482",
   "metadata": {
    "papermill": {
     "duration": 0.01678,
     "end_time": "2024-07-27T18:42:05.117862",
     "exception": false,
     "start_time": "2024-07-27T18:42:05.101082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IncarcerationSupervisionCharge_00000 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84bd5258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:42:05.152777Z",
     "iopub.status.busy": "2024-07-27T18:42:05.152425Z",
     "iopub.status.idle": "2024-07-27T18:42:05.205739Z",
     "shell.execute_reply": "2024-07-27T18:42:05.204558Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.074443,
     "end_time": "2024-07-27T18:42:05.208753",
     "exception": false,
     "start_time": "2024-07-27T18:42:05.134310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## IncarcerationSupervisionCharge_00000 Data Information:\n",
       "- **Rows**: 998\n",
       "- **Columns**: 18\n",
       "- **Memory Usage**: 85.94 KB\n",
       "### Data Details:\n",
       "| Column | Non-Null Count | Dtype | Description | Value Distribution |\n",
       "|--------|----------------|-------|-------------|---------------------|\n",
       "| INCARCERATION_SUPERVISION_ID | 998 non-null | int64 | Anonymized unique identifier | 731 unique values |\n",
       "| CONCURRENT_SENTENCES_SERVED_DAYS | 998 non-null | int64 | Days served for concurrent sentences | Min: 0.00, Max: 3336.00, Median: 0.00 |\n",
       "| CONSECUTIVE_SENTENCES_SERVED_DAYS | 998 non-null | int64 | Days served for consecutive sentences | Min: 0.00, Max: 935.00, Median: 0.00 |\n",
       "| SENTENCE_SERVED_DAYS | 998 non-null | int64 | Total days served for the sentence | Min: 0.00, Max: 10847.00, Median: 0.00 |\n",
       "| SUP_ASSIGNED_TERM_DURATION_DAYS | 998 non-null | int64 | Assigned duration of supervision term in days | Min: 0.00, Max: 32873.00, Median: 759.00 |\n",
       "| GAIN_TIME_EARNED | 101 non-null | float64 | Amount of time earned for good behavior | Min: 0.00, Max: 6102.00, Median: 242.00 |\n",
       "| STATUTE | 998 non-null | category | Legal statute related to the charge | 52 unique values |\n",
       "| MAXIMUM_TERM_DURATION_DAYS | 998 non-null | int64 | Maximum sentence duration in days | Min: 0.00, Max: 10958.00, Median: 0.00 |\n",
       "| HABITUAL_OFNDR_IND | 998 non-null | bool | Indicator for habitual offender status | False: 998 |\n",
       "| HABITUAL_VIOL_FELONY_OFNDR_IND | 998 non-null | bool | Indicator for habitual violent felony offender | False: 998 |\n",
       "| PRISON_RELEASEE_REOFNDR_IND | 998 non-null | bool | Indicator for prison releasee reoffender | False: 998 |\n",
       "| VIOLENT_CAREER_CRIM_IND | 998 non-null | bool | Indicator for violent career criminal | False: 998 |\n",
       "| SUPERVISION_SERVED_DAYS | 998 non-null | int64 | Days served under supervision | Min: 0.00, Max: 32873.00, Median: 759.00 |\n",
       "| DRUG_TYPE_DESC | 4 non-null | category | Description of drug type involved (if applicable) |  Cocaine: 4 |\n",
       "| OFFENSE_FCIC_TYPE_DESC | 998 non-null | category | Description of offense type | Larceny: 446, Cocaine-Possess: 113, Fraud-Insuff Funds Check: 104, Dangerous Drugs: 53, Cocaine-Sell: 49, Failure To Appear: 32, Marijuana-Sell: 27, Fraud-Illeg Use Credit Cards: 26, Public Order Crimes: 26, Marijuana-Possess: 23, Hallucinogen: 19, Heroin-Sell: 12, Fraud: 12, Possess Forged: 11, Synth Narcotic-Sell: 6, Barbiturate-Sell: 5, Hit And Run: 5, Aggravated Assault - Weapon: 4, Cocaine-Smuggle: 4, Barbiturate-Possess: 4, Weapon Offense: 2, Heroin-Possess: 2, Robbery: 2, Amphetamine-Sell: 1, Barbiturate: 1, Drug Equip-Possess: 1, Forgery  : 1, Opium Or Derivative-Possess: 1, Marijuana-Smuggle: 1, Marijuana-Producing: 1, Opium Or Derivative-Sell: 1, Synth Narcotic-Possess: 1, Traffic Offense: 1, Trespassing: 1 |\n",
       "| SENTENCE_STATUS | 998 non-null | category | Status of the sentence | Not Applicable: 578, Concurrent: 335, Consecutive: 70, Coterminous/Concurrent: 15 |\n",
       "| County_of_Conviction | 995 non-null | category | County where the conviction occurred | 43 unique values |\n",
       "| Degree_Level | 998 non-null | category | Degree and level of the charge (e.g., First Degree Felony) | Third Degree Felony: 846, Second Degree Felony: 76, Misdemeanor: 55, First Degree Felony: 13, Not Applicable: 8 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dropping redundant columns from the charges dataset\n",
    "charges_to_drop = ['FCIC_CODE', 'SUP_ASSIGNED_MAXIMUM_TERM_CODE', 'MAXIMUM_TERM_CODE', 'STATUTE_CHAPTER_CODE', 'STATUTE_SECTION', 'STATUTE_SUBSECTION', 'SUPERVISION_REVOCATION_REASON', 'SENTENCE_STATUS_CODE', 'MINIMUM_TERM_DURATION_DAYS', 'SENTENCE_PROBATION_DURATION_DAYS']\n",
    "df_charges = df_charges.drop(columns = charges_to_drop)\n",
    "\n",
    "# Defining a mapping dictionary for county codes to county names\n",
    "county_code_mapper = {6.0: 'BROWARD', 58.0: 'SARASOTA', 41.0: 'MANATEE', 4.0: 'BRADFORD', 51.0: 'PASCO', 32.0: 'JACKSON', 3.0: 'BAY', 30.0: 'HOLMES', 29.0: 'HILLSBOROUGH', 11.0: 'COLLIER', 49.0: 'OSCEOLA', 17.0: 'ESCAMBIA', 50.0: 'PALM BEACH', 12.0: 'COLUMBIA', 13.0: 'MIAMI-DADE', 5.0: 'BREVARD', 52.0: 'PINELLAS', 1.0: 'ALACHUA', 53.0: 'POLK', 47.0: 'OKEECHOBEE', 36.0: 'LEE', 48.0: 'ORANGE', 16.0: 'DUVAL', 64.0: 'VOLUSIA', 59.0: 'SEMINOLE', 54.0: 'PUTNAM', 8.0: 'CHARLOTTE', 55.0: 'ST. JOHNS', 38.0: 'LEVY', 56.0: 'ST. LUCIE', 14.0: 'DESOTO', 23.0: 'GULF', 40.0: 'MADISON', 43.0: 'MARTIN', 63.0: 'UNION', 31.0: 'INDIAN RIVER', 21.0: 'GILCHRIST', 18.0: 'FLAGLER', 61.0: 'SUWANNEE', 20.0: 'GADSDEN', 44.0: 'MONROE', 65.0: 'WAKULLA', 57.0: 'SANTA ROSA', 66.0: 'WALTON', 45.0: 'NASSAU', 2.0: 'BAKER', 62.0: 'TAYLOR', 24.0: 'HAMILTON', 46.0: 'OKALOOSA', 67.0: 'WASHINGTON', 39.0: 'LIBERTY', 7.0: 'CALHOUN', 26.0: 'HENDRY', 15.0: 'DIXIE', 25.0: 'HARDEE', 19.0: 'FRANKLIN', 60.0: 'SUMTER', 22.0: 'GLADES', 34.0: 'LAFAYETTE', 42.0: 'MARION', 37.0: 'LEON', 28.0: 'HIGHLANDS', 10.0: 'CLAY', 33.0: 'JEFFERSON'}\n",
    "\n",
    "# Function to apply mapping and drop original column\n",
    "def apply_mapping_and_drop(df, old_col, new_col, mapping_dict):\n",
    "    df[new_col] = [mapping_dict.get(val, None) for val in df[old_col]]\n",
    "    df.drop(columns=[old_col], inplace=True)\n",
    "    return df            \n",
    "\n",
    "# Apply county mapping and drop original column\n",
    "df_charges = apply_mapping_and_drop(df_charges, 'CONVICTION_COUNTY', 'County_of_Conviction', county_code_mapper)\n",
    "\n",
    "# Combine 'CHARGE_DEGREE' and 'CHARGE_LEVEL' into a new 'Degree_Level' column\n",
    "df_charges['Degree_Level'] = df_charges['CHARGE_DEGREE'] + ' ' + df_charges['CHARGE_LEVEL']\n",
    "df_charges['Degree_Level'] = df_charges['Degree_Level'].replace({'Not Applicable Misdemeanor': 'Misdemeanor', 'Not Applicable Not Applicable': 'Not Applicable'})\n",
    "df_charges = df_charges.drop(columns = ['CHARGE_DEGREE', 'CHARGE_LEVEL'])\n",
    "\n",
    "# Convert specified columns to categorical type for memory efficiency\n",
    "categorical_columns = ['STATUTE', 'DRUG_TYPE_DESC', 'OFFENSE_FCIC_TYPE_DESC', 'SENTENCE_STATUS', 'County_of_Conviction']\n",
    "for col in categorical_columns:\n",
    "    df_charges[col] = df_charges[col].astype('category')\n",
    "\n",
    "# Define the order of degree levels and convert 'Degree_Level' to an ordered categorical type\n",
    "degree_Level_order = ['Not Applicable', 'Misdemeanor', 'Third Degree Felony', 'Second Degree Felony', 'First Degree Felony']\n",
    "df_charges['Degree_Level'] = pd.Categorical(\n",
    "    df_charges['Degree_Level'],\n",
    "    categories=degree_Level_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Define descriptions for each column in df_charges\n",
    "descriptions_charges = [\n",
    "    \"Anonymized unique identifier\",\n",
    "    \"Days served for concurrent sentences\",\n",
    "    \"Days served for consecutive sentences\",\n",
    "    \"Total days served for the sentence\",\n",
    "    \"Assigned duration of supervision term in days\",\n",
    "    \"Amount of time earned for good behavior\",\n",
    "    \"Legal statute related to the charge\",\n",
    "    \"Maximum sentence duration in days\",\n",
    "    \"Indicator for habitual offender status\",\n",
    "    \"Indicator for habitual violent felony offender\",\n",
    "    \"Indicator for prison releasee reoffender\",\n",
    "    \"Indicator for violent career criminal\",\n",
    "    \"Days served under supervision\",\n",
    "    \"Description of drug type involved (if applicable)\",\n",
    "    \"Description of offense type\",\n",
    "    \"Status of the sentence\",\n",
    "    \"County where the conviction occurred\",\n",
    "    \"Degree and level of the charge (e.g., First Degree Felony)\"\n",
    "]\n",
    "\n",
    "# Function to generate a Markdown table with DataFrame information for df_charges\n",
    "def df_charges_info_markdown(df, descriptions=None, display_output=True):\n",
    "    # Get basic DataFrame info\n",
    "    rows, cols = df.shape\n",
    "    memory_usage = df.memory_usage(deep=True).sum()\n",
    "    memory_usage_str = f\"{memory_usage / 1024**2:.2f} MB\" if memory_usage > 1024**2 else f\"{memory_usage / 1024:.2f} KB\"\n",
    "    \n",
    "    # Construct the Markdown content\n",
    "    content = f\"\"\"\n",
    "## IncarcerationSupervisionCharge_00000 Data Information:\n",
    "- **Rows**: {rows}\n",
    "- **Columns**: {cols}\n",
    "- **Memory Usage**: {memory_usage_str}\n",
    "### Data Details:\n",
    "| Column | Non-Null Count | Dtype | Description | Value Distribution |\n",
    "|--------|----------------|-------|-------------|---------------------|\n",
    "\"\"\"\n",
    "    # Columns that require min, max, median\n",
    "    numeric_columns = [\n",
    "        \"CONCURRENT_SENTENCES_SERVED_DAYS\", \"CONSECUTIVE_SENTENCES_SERVED_DAYS\",\n",
    "        \"SENTENCE_SERVED_DAYS\", \"SUP_ASSIGNED_TERM_DURATION_DAYS\", \"GAIN_TIME_EARNED\", \"MAXIMUM_TERM_DURATION_DAYS\", \"SUPERVISION_SERVED_DAYS\"\n",
    "    ]\n",
    "    \n",
    "    # Columns that require value counts\n",
    "    value_count_columns = [\n",
    "        \"DRUG_TYPE_DESC\", \"OFFENSE_FCIC_TYPE_DESC\", \"SENTENCE_STATUS\", \"Degree_Level\",\n",
    "        \"HABITUAL_OFNDR_IND\", \"HABITUAL_VIOL_FELONY_OFNDR_IND\", \n",
    "        \"PRISON_RELEASEE_REOFNDR_IND\", \"VIOLENT_CAREER_CRIM_IND\"\n",
    "    ]\n",
    "    \n",
    "    # Iterate through columns to add their details to the Markdown table\n",
    "    for i, col in enumerate(df.columns):\n",
    "        dtype = df[col].dtype\n",
    "        non_null = df[col].count()\n",
    "        description = descriptions[i] if descriptions and i < len(descriptions) else \"\"\n",
    "        \n",
    "        # Determine value distribution based on column type\n",
    "        if col in numeric_columns:\n",
    "            min_val = df[col].min()\n",
    "            max_val = df[col].max()\n",
    "            median_val = df[col].median()\n",
    "            value_dist_str = f\"Min: {min_val:.2f}, Max: {max_val:.2f}, Median: {median_val:.2f}\"\n",
    "        elif col in value_count_columns or pd.api.types.is_bool_dtype(df[col]):\n",
    "            value_dist = df[col].value_counts().to_dict()\n",
    "            value_dist_str = \", \".join([f\"{k}: {v}\" for k, v in value_dist.items()])\n",
    "        else:\n",
    "            value_dist_str = f\"{df[col].nunique()} unique values\"\n",
    "        \n",
    "        content += f\"| {col} | {non_null} non-null | {dtype} | {description} | {value_dist_str} |\\n\"\n",
    "    \n",
    "    # Display the Markdown if display_output is True\n",
    "    if display_output:\n",
    "        display(Markdown(content))\n",
    "    \n",
    "    # Return the Markdown content as a string\n",
    "    return content\n",
    "\n",
    "# Generate the Markdown content for df_charges\n",
    "df_charges_content = df_charges_info_markdown(df_charges, descriptions_charges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9435274e",
   "metadata": {
    "papermill": {
     "duration": 0.02204,
     "end_time": "2024-07-27T18:42:05.251807",
     "exception": false,
     "start_time": "2024-07-27T18:42:05.229767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Code to Generate Visualizations for the IncarcerationSupervisionCharge_00000 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8bf9bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:42:05.287870Z",
     "iopub.status.busy": "2024-07-27T18:42:05.287550Z",
     "iopub.status.idle": "2024-07-27T18:42:12.744842Z",
     "shell.execute_reply": "2024-07-27T18:42:12.743830Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 7.478755,
     "end_time": "2024-07-27T18:42:12.747420",
     "exception": false,
     "start_time": "2024-07-27T18:42:05.268665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Size Comparison/Overlap Plot\n",
    "### Determine the sizes\n",
    "size_large = len(df_root)\n",
    "size_small = len(df_charges['INCARCERATION_SUPERVISION_ID'].unique())\n",
    "\n",
    "# Dataset names for passing\n",
    "large_dataset_name = \"IncarcerationSupervision_00000\"\n",
    "small_dataset_name = \"IncarcerationSupervisionCharge_00000\"\n",
    "\n",
    "# Find the overlap\n",
    "key_column = 'INCARCERATION_SUPERVISION_ID'\n",
    "overlap = df_charges[df_charges[key_column].isin(df_root[key_column])].shape[0]\n",
    "\n",
    "radius_small = 1\n",
    "radius_large = math.sqrt(size_large / size_small)\n",
    "\n",
    "# Calculate the distance between circle centers based on overlap\n",
    "overlap_ratio = overlap / size_small\n",
    "distance = radius_large + radius_small - (overlap_ratio * 2 * radius_small)\n",
    "\n",
    "# Adjust this factor to bring circles closer together or further apart\n",
    "distance_factor = 0.5  # Experiment with this value\n",
    "\n",
    "# Create a dataframe for our visualization\n",
    "viz_data = pd.DataFrame({\n",
    "    'x': [distance * distance_factor, 0],\n",
    "    'y': [0, 0],\n",
    "    'size': [size_large, size_small],\n",
    "    'radius': [radius_large, radius_small],\n",
    "    'dataset': [large_dataset_name, small_dataset_name],\n",
    "    'overlap': [overlap, overlap]\n",
    "})\n",
    "\n",
    "# Calculate the domain for x and y axes\n",
    "max_radius = max(radius_large, radius_small)\n",
    "x_domain = [-max_radius, (distance * distance_factor) + max_radius]\n",
    "y_domain = [-max_radius, max_radius]\n",
    "\n",
    "# Create the base chart\n",
    "base = alt.Chart(viz_data).encode(\n",
    "    x=alt.X('x:Q', scale=alt.Scale(domain=x_domain), axis=None),\n",
    "    y=alt.Y('y:Q', scale=alt.Scale(domain=y_domain), axis=None)\n",
    ")\n",
    "\n",
    "# Create circles representing dataset sizes\n",
    "circles = base.mark_circle(opacity=0.5).encode(\n",
    "    size=alt.Size('radius:Q', scale=alt.Scale(range=[0, 40000]), legend=None),\n",
    "    color=alt.Color('dataset:N', \n",
    "                    scale=alt.Scale(domain=[large_dataset_name, small_dataset_name], \n",
    "                                    range=['blue', 'red']),\n",
    "                    legend=alt.Legend(title=\"Datasets\", labelLimit=0)),\n",
    "    tooltip=['dataset', 'size', 'overlap']\n",
    ")\n",
    "\n",
    "# Combine all elements\n",
    "size_comparison_chart = circles.properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title=f\"Dataset Size Comparison (Overlap: {overlap} persons)\"\n",
    ").configure_view(\n",
    "    strokeWidth=0\n",
    ").configure_legend(\n",
    "    labelLimit=0,  # Ensures full names are shown in legend\n",
    "    orient='bottom',  # Positions legend at the bottom\n",
    "    columns=1,  # Stacks legend entries vertically\n",
    "    titleFontSize=14,\n",
    "    labelFontSize=12\n",
    ")\n",
    "size_comparison_chart.save('Dataset_Size_Comparison.html')\n",
    "\n",
    "# Sentencing Metrics Explorer: 7 Variables at a Glance development\n",
    "\"\"\"This interactive visualization presents seven histograms, each representing a different variable related to sentencing and supervision. For each variable:\n",
    "The top chart shows the full distribution of all data. You can click and drag on any top chart to select a specific range of days you're interested in. When you do this, the bottom chart for that variable will update to show only the data within your selected range, automatically adjusting its scale to fit this subset of data. This feature lets you zoom in on particular parts of the distribution for each variable, making it easier to examine patterns or details that might be hard to see in the full dataset. You can adjust your selection at any time to explore different ranges, or click outside the selection to reset and view the full distribution again. Each variable can be explored independently, allowing for comparison across all seven measures simultaneously.\"\"\"\n",
    "\n",
    "variables = [\n",
    "    'CONCURRENT_SENTENCES_SERVED_DAYS',\n",
    "    'CONSECUTIVE_SENTENCES_SERVED_DAYS',\n",
    "    'SENTENCE_SERVED_DAYS',\n",
    "    'SUP_ASSIGNED_TERM_DURATION_DAYS',\n",
    "    'GAIN_TIME_EARNED',\n",
    "    'MAXIMUM_TERM_DURATION_DAYS',\n",
    "    'SUPERVISION_SERVED_DAYS'\n",
    "]\n",
    "# Function to create a single histogram\n",
    "def create_histogram(variable):\n",
    "    selection = alt.selection_interval(encodings=['x'])\n",
    "    \n",
    "    base = alt.Chart(df_charges).mark_bar().encode(\n",
    "        alt.X(variable, bin=alt.Bin(maxbins=20), title=''),\n",
    "        alt.Y('count()', title=''),\n",
    "        tooltip=[variable, 'count()']\n",
    "    ).properties(\n",
    "        width=100,\n",
    "        height=100\n",
    "    )\n",
    "    \n",
    "    upper = base.encode(\n",
    "        opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n",
    "    ).add_params(selection).properties(\n",
    "        title=alt.TitleParams(text=variable, anchor='middle', fontSize=8)\n",
    "    )\n",
    "    \n",
    "    lower = base.transform_filter(selection)\n",
    "    \n",
    "    return (upper & lower).resolve_scale(y='independent')\n",
    "\n",
    "# Create all histograms\n",
    "histograms = [create_histogram(var) for var in variables]\n",
    "\n",
    "# Combine all histograms into a single chart\n",
    "sept_chart = alt.hconcat(*histograms).resolve_scale(\n",
    "    x='independent',\n",
    "    y='independent'\n",
    ").configure_axis(\n",
    "    labelFontSize=6,\n",
    "    titleFontSize=8\n",
    ").configure_title(\n",
    "    fontSize=10\n",
    ")\n",
    "\n",
    "# save the chart\n",
    "sept_chart.save('Sentencing_Metrics_Explorer:_7_Variables_at_a_Glance.html')\n",
    "\n",
    "# Pie charts for df_charges indicators\n",
    "columns = ['HABITUAL_OFNDR_IND', 'HABITUAL_VIOL_FELONY_OFNDR_IND', \n",
    "           'PRISON_RELEASEE_REOFNDR_IND', 'VIOLENT_CAREER_CRIM_IND']\n",
    "\n",
    "# Function to create a pie chart for a single column\n",
    "def create_pie_chart(df, column):\n",
    "    count_data = df[column].value_counts().reset_index()\n",
    "    count_data.columns = ['value', 'count']\n",
    "    \n",
    "    pie = alt.Chart(count_data).mark_arc().encode(\n",
    "        theta='count:Q',\n",
    "        color='value:N',\n",
    "        tooltip=['value:N', 'count:Q']\n",
    "    ).properties(\n",
    "        title=column,\n",
    "        width=200,\n",
    "        height=200\n",
    "    )\n",
    "    \n",
    "    return pie\n",
    "\n",
    "# Create pie charts for all columns\n",
    "charts = [create_pie_chart(df_charges, col) for col in columns]\n",
    "\n",
    "# Combine all charts into a single figure\n",
    "indicators_chart = alt.vconcat(\n",
    "    alt.hconcat(charts[0], charts[1]),\n",
    "    alt.hconcat(charts[2], charts[3])\n",
    ")\n",
    "\n",
    "# Saving the chart\n",
    "indicators_chart.save('Charges_Indicators.html')\n",
    "\n",
    "#Creating Pie chart for Drug type Descriptions\n",
    "def create_drug_type_pie_chart(df, column='DRUG_TYPE_DESC'):\n",
    "    # Calculate the counts and percentages\n",
    "    count_data = df[column].value_counts().reset_index()\n",
    "    count_data.columns = ['Drug Type', 'Count']\n",
    "    count_data['Percentage'] = count_data['Count'] / count_data['Count'].sum() * 100\n",
    "    \n",
    "    # Sort the data by count in descending order\n",
    "    count_data = count_data.sort_values('Count', ascending=False)\n",
    "    \n",
    "    # Calculate the cumulative percentages for positioning\n",
    "    count_data['cumulative_percentage'] = count_data['Percentage'].cumsum() - count_data['Percentage'] / 2\n",
    "    \n",
    "    # Create the base chart\n",
    "    base = alt.Chart(count_data).encode(\n",
    "        theta=alt.Theta('Count:Q', stack=True),\n",
    "        color=alt.Color('Drug Type:N', scale=alt.Scale(scheme='category20')),\n",
    "        tooltip=['Drug Type:N', 'Count:Q', alt.Tooltip('Percentage:Q', format='.1f')]\n",
    "    )\n",
    "\n",
    "    # Create the pie chart\n",
    "    pie = base.mark_arc(outerRadius=120)\n",
    "    \n",
    "    # Create text labels\n",
    "    text = base.mark_text(radius=150, align='center', baseline='middle').encode(\n",
    "        text='Drug Type:N',\n",
    "        x=alt.X('Drug Type:N', axis=None),\n",
    "        y=alt.Y('cumulative_percentage:Q', axis=None, scale=alt.Scale(range=[0, 360])),\n",
    "    )\n",
    "    \n",
    "    # Combine the pie and text charts\n",
    "    chart = (pie + text).properties(\n",
    "        title='Distribution of Drug Types',\n",
    "        width=400,\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return chart\n",
    "\n",
    "# Create and save the chart\n",
    "drug_type_chart = create_drug_type_pie_chart(df_charges)\n",
    "drug_type_chart.save('Drug_type_descriptions.html')\n",
    "\n",
    "# Developing the AI-Statute Classifier and makeing waffle chart\n",
    "unique_statutes = df_charges['STATUTE'].unique()\n",
    "FL_CRIME_CATEGORIES = [\n",
    "    \"Violent Crimes\", \"Property Crimes\", \"Drug Offenses\", \"Sex Offenses\", \"White Collar Crimes\",\n",
    "    \"Cybercrime\", \"Traffic Offenses\", \"Domestic Offenses\", \"Public Order Crimes\", \"Weapons Offenses\", \"Environmental Crimes\", \"Regulatory Offenses\", \"Procedural Crimes\",\n",
    "    \"Organized Crime\", \"Hate Crimes\", \"Financial Crimes\", \"Animal-Related Crimes\",\n",
    "    \"Public Integrity Offenses\", \"Miscellaneous Crimes\", \"Law Enforcement-Appended Crimes\", \"DUI\", \"Murder\", \"Crimes Against Children\", \"Rape\"\n",
    "]\n",
    "statutes_str = \"\\n\".join(unique_statutes)\n",
    "classifications_str = \"\\n\".join(FL_CRIME_CATEGORIES)\n",
    "llm_statute_classifier = ChatOpenAI(openai_api_key=secret_value_0, model = 'gpt-4o-mini')\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', \"\"\"\n",
    "    You are a legal expert tasked with classifying Florida Statutes. Given the following list of statutes and potential classifications, create a mapping between each Florida statute and its most appropriate classification.\n",
    "    Please provide your response as a json object. Do not include the json object in code delimiters\"\"\"),\n",
    "    ('human',\"Classify the Florida statutes {input_string}\")\n",
    "])\n",
    "# Create the LLMChain\n",
    "llm_chain =  prompt_template | llm_statute_classifier\n",
    "# Prepare the input\n",
    "statutes_str = \"\\n\".join(unique_statutes)\n",
    "classifications_str = \"\\n\".join(FL_CRIME_CATEGORIES)\n",
    "# Invoke the chain\n",
    "response = llm_chain.invoke({\n",
    "\"input_string\": statutes_str + ' ' + classifications_str\n",
    "})\n",
    "response_dict = json.loads(response.content)\n",
    "df_charges['Statue Category'] = df_charges['STATUTE'].map(response_dict)\n",
    "\n",
    "value_counts = df_charges['Statue Category'].value_counts()\n",
    "\n",
    "# Convert the value_counts to a DataFrame\n",
    "df = pd.DataFrame({'category': value_counts.index, 'count': value_counts.values})\n",
    "\n",
    "# Calculate the percentage for each category\n",
    "df['percentage'] = df['count'] / df['count'].sum() * 100\n",
    "\n",
    "# Set up the dimensions of the waffle chart\n",
    "waffle_size = 100  # Total number of squares\n",
    "rows, cols = 10, 10  # 10x10 grid\n",
    "\n",
    "# Calculate the number of squares for each category\n",
    "df['squares'] = (df['percentage'] / 100 * waffle_size).round().astype(int)\n",
    "\n",
    "# Create a new dataframe for the waffle chart\n",
    "waffle_data = []\n",
    "current_category = 0\n",
    "current_square = 0\n",
    "\n",
    "for row in range(rows):\n",
    "    for col in range(cols):\n",
    "        if current_square >= df['squares'].iloc[current_category]:\n",
    "            current_category += 1\n",
    "            current_square = 0\n",
    "            if current_category >= len(df):\n",
    "                break\n",
    "        \n",
    "        waffle_data.append({\n",
    "            'row': row,\n",
    "            'col': col,\n",
    "            'category': df['category'].iloc[current_category],\n",
    "            'count': df['count'].iloc[current_category],\n",
    "            'percentage': df['percentage'].iloc[current_category]\n",
    "        })\n",
    "        current_square += 1\n",
    "    \n",
    "    if current_category >= len(df):\n",
    "        break\n",
    "\n",
    "waffle_df = pd.DataFrame(waffle_data)\n",
    "\n",
    "# Create the base waffle chart\n",
    "base = alt.Chart(waffle_df).encode(\n",
    "    x=alt.X('col:O', axis=None),\n",
    "    y=alt.Y('row:O', axis=None, sort='descending')\n",
    ")\n",
    "\n",
    "# Create the colored squares\n",
    "squares = base.mark_rect(stroke='white', strokeWidth=2).encode(\n",
    "    color=alt.Color('category:N', legend=alt.Legend(title=\"Statute Category\")),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('category:N', title='Statute Category'),\n",
    "        alt.Tooltip('count:Q', title='Count'),\n",
    "        alt.Tooltip('percentage:Q', title='Percentage', format='.2f')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the grid\n",
    "grid = base.mark_rect(fill='none', stroke='lightgray').encode()\n",
    "\n",
    "# Combine the layers\n",
    "waffle_chart = (grid + squares).properties(\n",
    "    title=\"Distribution of Statute Categories (Waffle Chart)\",\n",
    "    width=400,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Save the chart\n",
    "waffle_chart.save('Distribution_of_Statute_Categories(Waffle_Chart).html')\n",
    "\n",
    "# Create the FCIC Classification, Degree Level Chart\n",
    "offense_counts = df_charges['OFFENSE_FCIC_TYPE_DESC'].value_counts().reset_index()\n",
    "offense_counts.columns = ['OFFENSE_FCIC_TYPE_DESC', 'count']\n",
    "\n",
    "# Merge with the original DataFrame to get the Statue Category for each offense\n",
    "merged_df = pd.merge(offense_counts, df_charges[['OFFENSE_FCIC_TYPE_DESC', 'Degree_Level']].drop_duplicates(), \n",
    "                     on='OFFENSE_FCIC_TYPE_DESC', how='left')\n",
    "\n",
    "# Calculate the height based on the number of offense types\n",
    "row_height = 20  # Height per row in pixels\n",
    "total_height = row_height * len(offense_counts)\n",
    "\n",
    "# Create the stacked bar chart\n",
    "offense_statute = alt.Chart(merged_df).mark_bar().encode(\n",
    "    y=alt.Y('OFFENSE_FCIC_TYPE_DESC:N', sort='-x', title='Offense Type'),\n",
    "    x=alt.X('count:Q', title='Count'),\n",
    "    color=alt.Color('Degree_Level:N', scale=alt.Scale(scheme='category20b'), \n",
    "                    legend=alt.Legend(title='Degree_Level')),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('OFFENSE_FCIC_TYPE_DESC', title='Offense Type'),\n",
    "        alt.Tooltip('Degree_Level', title='Degree_Level'),\n",
    "        alt.Tooltip('count', title='Count')\n",
    "    ]\n",
    ").properties(\n",
    "    title='Offense Types by Count and Degree_Level',\n",
    "    width=600,\n",
    "    height=total_height  # Use the calculated total height\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "offense_statute.save('Offense_Types_by_Count_and_Degree_Level.html')\n",
    "\n",
    "sentence_status_counts = df_charges['SENTENCE_STATUS'].value_counts().reset_index()\n",
    "sentence_status_counts.columns = ['SENTENCE_STATUS', 'count']\n",
    "\n",
    "# Calculate the percentage for each status\n",
    "sentence_status_counts['percentage'] = sentence_status_counts['count'] / sentence_status_counts['count'].sum() * 100\n",
    "\n",
    "# Create the pie chart\n",
    "sentence_status_pie_chart = alt.Chart(sentence_status_counts).mark_arc().encode(\n",
    "    theta=alt.Theta(field=\"count\", type=\"quantitative\"),\n",
    "    color=alt.Color(field=\"SENTENCE_STATUS\", type=\"nominal\", legend=alt.Legend(title=\"Sentence Status\")),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"SENTENCE_STATUS\", title=\"Sentence Status\"),\n",
    "        alt.Tooltip(\"count\", title=\"Count\"),\n",
    "        alt.Tooltip(\"percentage\", title=\"Percentage\", format=\".2f\")\n",
    "    ]\n",
    ").properties(\n",
    "    title=\"Distribution of Sentence Statuses\",\n",
    "    width=400,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "sentence_status_pie_chart.save('Distribution_of_Sentece_Statuses.html')\n",
    "\n",
    "gdf = gpd.read_file('/kaggle/input/geojson-data/florida_geojson_file.geojson')\n",
    "\n",
    "florida_county_mapping = {\n",
    "    'ALACHUA': 'Alachua',\n",
    "    'BAKER': 'Baker',\n",
    "    'BAY': 'Bay',\n",
    "    'BRADFORD': 'Bradford',\n",
    "    'BREVARD': 'Brevard',\n",
    "    'BROWARD': 'Broward',\n",
    "    'CALHOUN': 'Calhoun',\n",
    "    'CHARLOTTE': 'Charlotte',\n",
    "    'CITRUS': 'Citrus',\n",
    "    'CLAY': 'Clay',\n",
    "    'COLLIER': 'Collier',\n",
    "    'COLUMBIA': 'Columbia',\n",
    "    'DESOTO': 'DeSoto',\n",
    "    'DE SOTO': 'DeSoto',\n",
    "    'DIXIE': 'Dixie',\n",
    "    'DUVAL': 'Duval',\n",
    "    'ESCAMBIA': 'Escambia',\n",
    "    'FLAGLER': 'Flagler',\n",
    "    'FRANKLIN': 'Franklin',\n",
    "    'GADSDEN': 'Gadsden',\n",
    "    'GILCHRIST': 'Gilchrist',\n",
    "    'GLADES': 'Glades',\n",
    "    'GULF': 'Gulf',\n",
    "    'HAMILTON': 'Hamilton',\n",
    "    'HARDEE': 'Hardee',\n",
    "    'HENDRY': 'Hendry',\n",
    "    'HERNANDO': 'Hernando',\n",
    "    'HIGHLANDS': 'Highlands',\n",
    "    'HILLSBOROUGH': 'Hillsborough',\n",
    "    'HOLMES': 'Holmes',\n",
    "    'INDIAN RIVER': 'Indian River',\n",
    "    'JACKSON': 'Jackson',\n",
    "    'JEFFERSON': 'Jefferson',\n",
    "    'LAFAYETTE': 'Lafayette',\n",
    "    'LAKE': 'Lake',\n",
    "    'LEE': 'Lee',\n",
    "    'LEON': 'Leon',\n",
    "    'LEVY': 'Levy',\n",
    "    'LIBERTY': 'Liberty',\n",
    "    'MADISON': 'Madison',\n",
    "    'MANATEE': 'Manatee',\n",
    "    'MARION': 'Marion',\n",
    "    'MARTIN': 'Martin',\n",
    "    'MIAMI-DADE': 'Miami-Dade',\n",
    "    'MIAMI DADE': 'Miami-Dade',\n",
    "    'DADE': 'Miami-Dade',\n",
    "    'MONROE': 'Monroe',\n",
    "    'NASSAU': 'Nassau',\n",
    "    'OKALOOSA': 'Okaloosa',\n",
    "    'OKEECHOBEE': 'Okeechobee',\n",
    "    'ORANGE': 'Orange',\n",
    "    'OSCEOLA': 'Osceola',\n",
    "    'PALM BEACH': 'Palm Beach',\n",
    "    'PASCO': 'Pasco',\n",
    "    'PINELLAS': 'Pinellas',\n",
    "    'POLK': 'Polk',\n",
    "    'PUTNAM': 'Putnam',\n",
    "    'ST. JOHNS': 'St. Johns',\n",
    "    'SAINT JOHNS': 'St. Johns',\n",
    "    'ST JOHNS': 'St. Johns',\n",
    "    'SANTA ROSA': 'Santa Rosa',\n",
    "    'SARASOTA': 'Sarasota',\n",
    "    'SEMINOLE': 'Seminole',\n",
    "    'ST. LUCIE': 'St. Lucie',\n",
    "    'SAINT LUCIE': 'St. Lucie',\n",
    "    'ST LUCIE': 'St. Lucie',\n",
    "    'SUMTER': 'Sumter',\n",
    "    'SUWANNEE': 'Suwannee',\n",
    "    'TAYLOR': 'Taylor',\n",
    "    'UNION': 'Union',\n",
    "    'VOLUSIA': 'Volusia',\n",
    "    'WAKULLA': 'Wakulla',\n",
    "    'WALTON': 'Walton',\n",
    "    'WASHINGTON': 'Washington'\n",
    "}\n",
    "df_charges['County of Conviction'] = df_charges['County_of_Conviction'].map(florida_county_mapping)\n",
    "df_county_convictions = df_charges['County of Conviction'].value_counts().reset_index()\n",
    "df_county_convictions.columns = ['NAME', 'count']\n",
    "for_chloropleth = pd.merge(gdf, df_county_convictions, on = 'NAME')\n",
    "# Reproject the data to a projected CRS (e.g., EPSG:3857 - Web Mercator)\n",
    "for_chloropleth = for_chloropleth.to_crs(epsg=3857)\n",
    "\n",
    "# Calculate the centroid in the projected CRS\n",
    "centroid = for_chloropleth.geometry.centroid.to_crs(epsg=4326)\n",
    "\n",
    "# Create a base map\n",
    "m = folium.Map(location=[centroid.y.mean(), centroid.x.mean()], \n",
    "               zoom_start=6)\n",
    "\n",
    "# Create a colormap\n",
    "colormap = cm.LinearColormap(colors=['yellow', 'orange', 'red'], \n",
    "                             vmin=for_chloropleth['count'].min(), \n",
    "                             vmax=for_chloropleth['count'].max())\n",
    "\n",
    "# Add the choropleth layer\n",
    "folium.GeoJson(\n",
    "    for_chloropleth.to_crs(epsg=4326),  # Convert back to WGS84 for Folium\n",
    "    name='choropleth',\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': colormap(feature['properties']['count']),\n",
    "        'color': 'black',\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.7,\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(fields=['NAME', 'count'],\n",
    "                                  aliases=['County', 'Count'],\n",
    "                                  style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\"))\n",
    ").add_to(m)\n",
    "\n",
    "# Add the colormap to the map\n",
    "colormap.add_to(m)\n",
    "\n",
    "# Save the map\n",
    "m.save('florida_counties_choropleth.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dfadf9",
   "metadata": {
    "papermill": {
     "duration": 0.016474,
     "end_time": "2024-07-27T18:42:12.781038",
     "exception": false,
     "start_time": "2024-07-27T18:42:12.764564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AI Presentation of the IncarcerationSupervisionCharge_00000 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62165595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:42:12.816519Z",
     "iopub.status.busy": "2024-07-27T18:42:12.816166Z",
     "iopub.status.idle": "2024-07-27T18:43:11.574990Z",
     "shell.execute_reply": "2024-07-27T18:43:11.574100Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 58.797219,
     "end_time": "2024-07-27T18:43:11.594941",
     "exception": false,
     "start_time": "2024-07-27T18:42:12.797722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: red;\"> \n",
       "\n",
       "# AI Generated Presentation of `IncarcerationSupervisionCharge_00000` and Visualizations\n",
       "\n",
       "## Relative Data Sizes and Overlap:\n",
       "\n",
       "### Overview\n",
       "This visualization compares the sizes of two datasets: `IncarcerationSupervision_00000` and `IncarcerationSupervisionCharge_00000`. It also highlights the number of common entries based on the `INCARCERATION_SUPERVISION_ID` column, which serves as a unique anonymized identifier for the datasets.\n",
       "\n",
       "### Dataset Details\n",
       "- **IncarcerationSupervision_00000**:\n",
       "  - **Size**: 112,894 entries\n",
       "  - **Overlap**: 15 common entries with the other dataset\n",
       "  - **Radius**: 12.43 (indicative of its size in the visualization)\n",
       "\n",
       "- **IncarcerationSupervisionCharge_00000**:\n",
       "  - **Size**: 731 entries\n",
       "  - **Overlap**: 15 common entries with the other dataset\n",
       "  - **Radius**: 1.0 (indicative of its size in the visualization)\n",
       "\n",
       "### Visualization Insights\n",
       "The plot visually represents the relative sizes of the two datasets, with the larger dataset (`IncarcerationSupervision_00000`) depicted in blue and the smaller dataset (`IncarcerationSupervisionCharge_00000`) in red. The overlap of 15 entries indicates that there are some shared records between the two datasets, but the overall size disparity raises questions about the reasons for the limited number of entries in `IncarcerationSupervisionCharge_00000`.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Dataset_Size_Comparison.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "## Sentence Metrics:\n",
       "\n",
       "### Overview of Variables\n",
       "The dataset includes several key metrics related to sentencing and supervision, with the following variables:\n",
       "\n",
       "- **CONCURRENT_SENTENCES_SERVED_DAYS**: Represents the days served for concurrent sentences.\n",
       "  - Non-null count: 998\n",
       "  - Data type: int64\n",
       "  - Range: Min: 0.00, Max: 3336.00, Median: 0.00\n",
       "\n",
       "- **CONSECUTIVE_SENTENCES_SERVED_DAYS**: Represents the days served for consecutive sentences.\n",
       "  - Non-null count: 998\n",
       "  - Data type: int64\n",
       "  - Range: Min: 0.00, Max: 935.00, Median: 0.00\n",
       "\n",
       "- **SENTENCE_SERVED_DAYS**: Total days served for the sentence.\n",
       "  - Non-null count: 998\n",
       "  - Data type: int64\n",
       "  - Range: Min: 0.00, Max: 10847.00, Median: 0.00\n",
       "\n",
       "- **SUP_ASSIGNED_TERM_DURATION_DAYS**: Assigned duration of supervision term in days.\n",
       "  - Non-null count: 998\n",
       "  - Data type: int64\n",
       "  - Range: Min: 0.00, Max: 32873.00, Median: 759.00\n",
       "\n",
       "- **GAIN_TIME_EARNED**: Amount of time earned for good behavior.\n",
       "  - Non-null count: 101\n",
       "  - Data type: float64\n",
       "  - Range: Min: 0.00, Max: 6102.00, Median: 242.00\n",
       "\n",
       "- **MAXIMUM_TERM_DURATION_DAYS**: Maximum sentence duration in days.\n",
       "  - Non-null count: 998\n",
       "  - Data type: int64\n",
       "  - Range: Min: 0.00, Max: 10958.00, Median: 0.00\n",
       "\n",
       "- **SUPERVISION_SERVED_DAYS**: Days served under supervision.\n",
       "  - Non-null count: 998\n",
       "  - Data type: int64\n",
       "  - Range: Min: 0.00, Max: 32873.00, Median: 759.00\n",
       "\n",
       "### Visualization Insights\n",
       "The interactive visualization presents seven histograms, each corresponding to one of the variables listed above. The top charts display the full distribution of data, allowing users to click and drag to select specific ranges. This feature enables a detailed examination of the data, particularly useful for identifying patterns or anomalies within the distributions.\n",
       "\n",
       "One notable observation is that the most common entry among the few non-null values is 0, indicating a potential issue with data quality. The presence of many zero values may suggest that the data does not accurately reflect the experiences of all incarcerated or supervised persons. This could be due to incomplete records or reporting inconsistencies.\n",
       "\n",
       "### Data Quality Concerns\n",
       "The limited non-null values for **GAIN_TIME_EARNED** (only 101 non-null entries) raises concerns about the completeness of this variable. Additionally, the high frequency of zero values across several metrics may indicate that the dataset does not capture the full scope of sentencing and supervision experiences.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Sentencing_Metrics_Explorer:_7_Variables_at_a_Glance.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "## Indicators:\n",
       "\n",
       "### Overview of Indicator Variables\n",
       "The dataset includes several boolean indicator variables that provide insights into the habitual and violent offender status of incarcerated or supervised persons. Each variable has 998 non-null entries, all indicating a value of `False`. The variables are as follows:\n",
       "\n",
       "- **HABITUAL_OFNDR_IND**: Indicator for habitual offender status.\n",
       "- **HABITUAL_VIOL_FELONY_OFNDR_IND**: Indicator for habitual violent felony offender.\n",
       "- **PRISON_RELEASEE_REOFNDR_IND**: Indicator for prison releasee reoffender.\n",
       "- **VIOLENT_CAREER_CRIM_IND**: Indicator for violent career criminal.\n",
       "\n",
       "### Data Quality Concerns\n",
       "The uniformity of the `False` values across all 998 entries raises potential data quality concerns. This could indicate a lack of diversity in the dataset or issues with data collection and reporting. It is essential to investigate whether this reflects the actual population or if there are gaps in the data collection process.\n",
       "\n",
       "### Visualization\n",
       "The following visualizations represent the indicator variables. Each pie chart illustrates the distribution of the boolean values for the respective indicators. Given that all values are `False`, the visualizations will predominantly show a single segment.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Charges_Indicators.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Insights from Visualizations\n",
       "The visualizations confirm that there are no recorded instances of habitual offenders, habitual violent felony offenders, prison releasee reoffenders, or violent career criminals within this dataset. This lack of representation may suggest a need for further data collection or a review of the criteria used to classify individuals under these indicators.\n",
       "\n",
       "## Drug Type\n",
       "\n",
       "### Data Quality Concern\n",
       "The dataset contains only 4 non-null entries for the variable `DRUG_TYPE_DESC`, which indicates a significant limitation in the data quality. The only drug type represented is \"Cocaine,\" which accounts for 100% of the entries. This raises concerns about the comprehensiveness and reliability of the data, as it does not reflect a diverse range of drug types that may be involved in incarceration or supervision cases.\n",
       "\n",
       "### Visualization Explanation\n",
       "The visualization titled \"Distribution of Drug Types\" is a pie chart that illustrates the distribution of drug types based on the available data. Given that there is only one drug type represented, the chart will show a single segment for \"Cocaine,\" with a count of 4 and a percentage of 100%. \n",
       "\n",
       "This visualization does not provide meaningful insights due to the lack of variety in the data. The cumulative percentage is also shown, but with only one category, it does not add additional value. \n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Drug_type_descriptions.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "## Statutes:\n",
       "\n",
       "### Overview\n",
       "The dataset contains a total of **998 non-null** entries in the **STATUTE** variable, which represents legal statutes related to various charges. There are **52 unique values** in this variable, indicating a diverse range of legal statutes that can be mapped to different offense categories.\n",
       "\n",
       "### Insights on Statute Categories\n",
       "To provide meaningful insights from the many unique statute categories, an AI mapping process can be employed. This process will translate raw statute chapter numbers, such as '817.62.1', into broader offense categories. This categorization can help in understanding the nature of the charges and the legal implications associated with them.\n",
       "\n",
       "### Visualization\n",
       "The following visualization presents the distribution of statute categories using a waffle chart. This type of chart is particularly effective for displaying categorical data and allows for an intuitive understanding of the proportions of different categories.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Distribution_of_Statute_Categories(Waffle_Chart).html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Explanation of the Visualization\n",
       "The waffle chart visually represents the distribution of different statute categories. Each square in the chart corresponds to a certain number of cases, allowing for a quick visual assessment of the prevalence of each category. \n",
       "\n",
       "- **Property Crimes** dominate the chart, accounting for **45.18%** of the total cases, with a count of **450**.\n",
       "- **Drug Offenses** follow, comprising **33.73%** of the cases, totaling **336**.\n",
       "- **Public Order Crimes** make up **13.45%** with **134** cases.\n",
       "- Other categories, such as **White Collar Crimes** (3.61%), **Traffic Offenses** (1.71%), **DUI** (0.80%), and **Procedural Crimes** (0.50%), represent smaller proportions of the dataset.\n",
       "\n",
       "### Data Quality Considerations\n",
       "While the dataset provides a comprehensive overview of statute categories, it is essential to acknowledge potential data quality concerns. The unique values in the **STATUTE** variable may not be exhaustive or may contain inconsistencies in naming conventions. Additionally, the mapping process from raw statute numbers to offense categories may introduce biases if not carefully managed. Researchers and policymakers should consider these limitations when interpreting the data.\n",
       "\n",
       "## Sentence Statuses:\n",
       "\n",
       "### Overview\n",
       "The dataset provides insights into the various statuses of sentences for incarcerated persons in Florida. The variable of interest is **SENTENCE_STATUS**, which categorizes the type of sentence each individual is serving. The dataset contains 998 non-null entries, indicating a comprehensive representation of the sentence statuses.\n",
       "\n",
       "### Sentence Status Categories\n",
       "The **SENTENCE_STATUS** variable includes the following categories:\n",
       "- **Not Applicable**: 578 (57.92%)\n",
       "- **Concurrent**: 335 (33.57%)\n",
       "- **Consecutive**: 70 (7.01%)\n",
       "- **Coterminous/Concurrent**: 15 (1.50%)\n",
       "\n",
       "### Explanation of Categories\n",
       "- **Not Applicable**: This category represents cases where the sentence does not fall into the concurrent or consecutive classifications. This could include various legal circumstances or types of sentences that do not require a specific classification.\n",
       "  \n",
       "- **Concurrent**: Concurrent sentences allow for overlapping terms, meaning that time served for one offense counts towards the other. This is common in cases where multiple offenses are linked to the same criminal event.\n",
       "\n",
       "- **Consecutive**: In contrast, consecutive sentences require that one term be completed before the next begins. This means that the time served for one offense does not count towards the other.\n",
       "\n",
       "- **Coterminous/Concurrent**: This category indicates sentences that are both coterminous and concurrent, suggesting a unique legal situation where the terms may overlap in a specific manner.\n",
       "\n",
       "### Visualization\n",
       "The following visualization illustrates the distribution of sentence statuses among the incarcerated persons. Each segment of the chart represents the proportion of each sentence status category, providing a clear visual representation of how these statuses are distributed.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Distribution_of_Sentece_Statuses.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Insights from the Visualization\n",
       "From the visualization, it is evident that the majority of sentences fall under the **Not Applicable** category, accounting for over half of the dataset. This could suggest a need for further investigation into the types of sentences that are classified as not applicable and the reasons behind this classification.\n",
       "\n",
       "The **Concurrent** category, while significant, is less than half of the **Not Applicable** category, indicating that a substantial number of sentences do not overlap. The relatively small percentages for **Consecutive** and **Coterminous/Concurrent** suggest that these types of sentences are less common in the dataset.\n",
       "\n",
       "### Data Quality Considerations\n",
       "While the dataset appears comprehensive, the high percentage of **Not Applicable** statuses raises questions about the nature of these cases. It may be beneficial to explore the reasons behind this classification further, as it could impact the understanding of sentencing practices in Florida. Additionally, ensuring that the definitions of each category are consistently applied across the dataset is crucial for maintaining data integrity.\n",
       "\n",
       "## FCIC Sentence Offences Categories by Degree Type\n",
       "\n",
       "### Overview\n",
       "This dataset provides insights into the types of offenses categorized by their degree level as recorded by the Florida Crime Information Center (FCIC). The dataset includes a total of 998 non-null entries, detailing various offense types and their corresponding degree levels. \n",
       "\n",
       "### Dataset Variables\n",
       "- **OFFENSE_FCIC_TYPE_DESC**: Description of the offense type (e.g., Larceny, Cocaine-Possess).\n",
       "- **Degree_Level**: The degree and level of the charge (e.g., First Degree Felony, Third Degree Felony).\n",
       "- **count**: The number of occurrences for each offense type and degree level combination.\n",
       "\n",
       "### Offense Types and Counts\n",
       "The following are the most common offense types along with their counts:\n",
       "- **Larceny**: 446 occurrences\n",
       "- **Cocaine-Possess**: 113 occurrences\n",
       "- **Fraud-Insuff Funds Check**: 104 occurrences\n",
       "- **Dangerous Drugs**: 53 occurrences\n",
       "- **Cocaine-Sell**: 49 occurrences\n",
       "- **Failure To Appear**: 32 occurrences\n",
       "- **Marijuana-Sell**: 27 occurrences\n",
       "- **Fraud-Illeg Use Credit Cards**: 26 occurrences\n",
       "- **Public Order Crimes**: 26 occurrences\n",
       "- **Marijuana-Possess**: 23 occurrences\n",
       "\n",
       "### Degree Levels and Counts\n",
       "The degree levels of the offenses are categorized as follows:\n",
       "- **Third Degree Felony**: 846 occurrences\n",
       "- **Second Degree Felony**: 76 occurrences\n",
       "- **Misdemeanor**: 55 occurrences\n",
       "- **First Degree Felony**: 13 occurrences\n",
       "- **Not Applicable**: 8 occurrences\n",
       "\n",
       "### Visualization\n",
       "The following bar chart visualizes the counts of different offense types categorized by their degree levels. This visualization allows for a quick comparison of how frequently each offense type occurs across different degree levels.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Offense_Types_by_Count_and_Degree_Level.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Insights from the Visualization\n",
       "- The bar chart clearly shows that **Larceny** is the most prevalent offense type, with a significant number of occurrences across various degree levels, predominantly as a **Third Degree Felony**.\n",
       "- **Cocaine-Possess** and **Fraud-Insuff Funds Check** also show high counts, indicating these offenses are common in the dataset.\n",
       "- The **Third Degree Felony** category dominates the counts, suggesting that many offenses recorded are of a lesser degree, which may reflect trends in law enforcement or judicial processing.\n",
       "\n",
       "### Data Quality Considerations\n",
       "- The dataset contains a total of 998 non-null entries, which suggests that there may be some missing data or unrecorded offenses. It is essential to consider this limitation when interpreting the results.\n",
       "- The \"Not Applicable\" category in the degree level may indicate cases where the degree of the offense was not assigned or is not relevant, which could skew the understanding of the severity of offenses.\n",
       "\n",
       "This detailed breakdown provides a comprehensive view of the offense types and their classifications, aiding researchers, policymakers, and the public in understanding crime trends in Florida.\n",
       "\n",
       "## County of Conviction\n",
       "\n",
       "### Overview\n",
       "The dataset provides a breakdown of the number of convictions by county in Florida. This information is crucial for understanding the geographical distribution of convictions across the state. The data highlights the counties with the highest and lowest numbers of convictions, which can inform policymakers and researchers about regional trends in criminal justice.\n",
       "\n",
       "### Data Insights\n",
       "The following are the conviction counts by county:\n",
       "\n",
       "- **Pinellas**: 337\n",
       "- **Miami-Dade**: 150\n",
       "- **Broward**: 128\n",
       "- **Bay**: 43\n",
       "- **Pasco**: 41\n",
       "- **Monroe**: 37\n",
       "- **Escambia**: 31\n",
       "- **Leon**: 30\n",
       "- **Brevard**: 25\n",
       "- **Palm Beach**: 21\n",
       "- **Polk**: 17\n",
       "- **Hillsborough**: 16\n",
       "- **Duval**: 13\n",
       "- **Orange**: 11\n",
       "- **Volusia**: 8\n",
       "- **St. Lucie**: 7\n",
       "- **Indian River**: 7\n",
       "- **Sarasota**: 7\n",
       "- **Clay**: 6\n",
       "- **Gadsden**: 6\n",
       "- **Osceola**: 5\n",
       "- **Marion**: 5\n",
       "- **Manatee**: 5\n",
       "- **Hardee**: 4\n",
       "- **Alachua**: 3\n",
       "- **Collier**: 3\n",
       "- **DeSoto**: 3\n",
       "- **Flagler**: 3\n",
       "- **St. Johns**: 3\n",
       "- **Seminole**: 3\n",
       "- **Charlotte**: 2\n",
       "- **Lee**: 2\n",
       "- **Nassau**: 2\n",
       "- **Martin**: 2\n",
       "- **Dixie**: 1\n",
       "- **Jefferson**: 1\n",
       "- **Liberty**: 1\n",
       "- **Highlands**: 1\n",
       "- **Jackson**: 1\n",
       "- **Hendry**: 1\n",
       "- **Okeechobee**: 1\n",
       "- **Okaloosa**: 1\n",
       "- **Putnam**: 1\n",
       "\n",
       "### Visualization\n",
       "The visualization associated with this dataset is a choropleth map that illustrates the number of convictions by county. This type of map is particularly effective for displaying data that varies across geographical areas, allowing for quick visual assessment of which counties have higher or lower conviction rates.\n",
       "\n",
       "The map can also highlight the lack of reporting in many counties, indicating that the data primarily reflects which counties are actively submitting their conviction data. This limitation is crucial to acknowledge, as it may skew perceptions of crime rates in counties that do not report data.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"florida_counties_choropleth.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Data Quality Concerns\n",
       "It is important to note that the absence of data from certain counties may lead to an incomplete understanding of the overall conviction landscape in Florida. The map's effectiveness is contingent upon the participation of all counties in reporting their data. Policymakers and researchers should consider this limitation when interpreting the results, as it may not accurately reflect the true distribution of convictions across the state. \n",
       "\n",
       "### Categorical Variables\n",
       "For the data scientist, the key categorical variable in this dataset is the county name, which includes values such as \"Pinellas,\" \"Miami-Dade,\" \"Broward,\" and so forth. Each county's corresponding conviction count is a numerical variable that can be analyzed further for trends and patterns. \n",
       "\n",
       " </span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparing Data for AI\n",
    "\n",
    "# Overlap\n",
    "overlap_data = 'Dataset_Size_Comparison.html' + \"Additional Context: This plot shows the relative sizes of the two datasets `IncarcerationSupervision_00000` and `IncarcerationSupervisionCharges_00000`, as well as the number of common entries in the `INCARCERATION_SUPERVISION_ID` column, which serves as a common unique anonymized identifier. \" + size_comparison_chart.to_json()\n",
    "\n",
    "# Days Data\n",
    "days_variables = [\n",
    "    'CONCURRENT_SENTENCES_SERVED_DAYS',\n",
    "    'CONSECUTIVE_SENTENCES_SERVED_DAYS',\n",
    "    'SENTENCE_SERVED_DAYS',\n",
    "    'SUP_ASSIGNED_TERM_DURATION_DAYS',\n",
    "    'GAIN_TIME_EARNED',\n",
    "    'MAXIMUM_TERM_DURATION_DAYS',\n",
    "    'SUPERVISION_SERVED_DAYS'\n",
    "]\n",
    "days_rows = extract_rows(df_charges_content, days_variables)\n",
    "days_context = days_rows + 'Sentencing_Metrics_Explorer:_7_Variables_at_a_Glance.html' + \"\"\"This interactive visualization presents seven histograms, each representing a different variable related to sentencing and supervision. For each variable:\n",
    "The top chart shows the full distribution of all data. You can click and drag on any top chart to select a specific range of days you're interested in. When you do this, the bottom chart for that variable will update to show only the data within your selected range, automatically adjusting its scale to fit this subset of data. This feature lets you zoom in on particular parts of the distribution for each variable, making it easier to examine patterns or details that might be hard to see in the full dataset. You can adjust your selection at any time to explore different ranges, or click outside the selection to reset and view the full distribution again. Each variable can be explored independently, allowing for comparison across all seven measures simultaneously.\"\"\" + \" Additional Context: The most common entry among the few non-null values is 0. These column variables do not appear to represent well-kept data.\"\n",
    "\n",
    "# Indicators\n",
    "indicators_columns = ['HABITUAL_OFNDR_IND', 'HABITUAL_VIOL_FELONY_OFNDR_IND', \n",
    "           'PRISON_RELEASEE_REOFNDR_IND', 'VIOLENT_CAREER_CRIM_IND']\n",
    "indicators_rows = extract_rows(df_charges_content, indicators_columns)\n",
    "indicators_context = indicators_rows + 'Charges_Indicators.html'  + indicators_chart.to_json() + \" Additional Context: These column variables do not appear to represent well-kept data.\"\n",
    "\n",
    "# Drug Type\n",
    "drug_type_rows = extract_rows(df_charges_content, ['DRUG_TYPE_DESC'])\n",
    "drug_type_context = drug_type_rows + 'Drug_type_descriptions.html' + drug_type_chart.to_json()\n",
    "\n",
    "# Statutes\n",
    "statute_rows = extract_rows(df_charges_content, ['STATUTE'])\n",
    "statute_context = statute_rows  + 'Distribution_of_Statute_Categories(Waffle_Chart).html'  +  \"Please inform the user of the number of unique values in STATUTE. In an effort to take the many unique statute categories listed, like '817.62.1', into meaningful information, AI mapping from raw statute chapter numbers to offence categories.\" + waffle_chart.to_json()\n",
    "\n",
    "# Sentence Status\n",
    "status_rows = extract_rows(df_charges_content, ['SENTENCE_STATUS'])\n",
    "sentence_status_context = status_rows  + 'Distribution_of_Sentece_Statuses.html'  + \"Additional Context: Concurrent sentences are sentences that overlap for sentences on other offenses which are considered part of the same criminal event. This means that one day served counts as a day served for both of those two linked-crimes. On the other hand, consecutive sentences are sentences where one must first complete one term before starting the next; they do not overlap. 'Not applicable' just means that the sentences are neither concurrent nor consecutive.\" + sentence_status_pie_chart.to_json()\n",
    "\n",
    "# Offense Type\n",
    "offence_rows = extract_rows(df_charges_content, ['OFFENSE_FCIC_TYPE_DESC', 'Degree_Level'])\n",
    "offense_context = offence_rows + 'Offense_Types_by_Count_and_Degree_Level.html'  + \"Additional Context: These crime categories are determined by the FCIC.\" + offense_statute.to_json()\n",
    "\n",
    "\n",
    "# Chloropleth\n",
    "county_conviction_context =  df_charges['County of Conviction'].value_counts().to_json() + 'florida_counties_choropleth.html' + \" Additional context: The lack of reporting in many counties shows that the value of this map mainly indicates which counties submit data and which do not.\"\n",
    "\n",
    "charges_overlap_response = llm_chain_1.invoke({'data_str': 'Subject: Relative Data Sizes and Overlap, Additional Context: This visual compares the size of the dataset of current discussion, IncarcerationSupervisionCharge_00000,  with the dataset presentted just previously, IncarcerationSupervisionCharge_00000. The reasons why there are so few entries in IncarcerationSupervisionCharge_00000 compared to IncarcerationSupervisionCharge_00000, as well as why there are so few common entries, are unknown. Do not offer a data interpretation of the radii for this response. Be succinct with this response.' + overlap_data})\n",
    "days_response = llm_chain_1.invoke({'data_str':  'Subject: Sentence Metrics. Be succinct with this response.' + days_context})\n",
    "indicators_response = llm_chain_1.invoke({'data_str': 'Subject: Indicators, Be succint with this response.' + indicators_context})\n",
    "drug_type_response = llm_chain_1.invoke({'data_str': 'Subject: Drug Type, Data Quality Concern: The plot does not appear to represent well-kept data. Be very succint with this response.' + drug_type_context})\n",
    "statute_response = llm_chain_1.invoke({'data_str': 'Subject: Statues' +  statute_context})\n",
    "sentence_status_response = llm_chain_1.invoke({'data_str': \"Subject: Sentence Statuses\" + sentence_status_context })\n",
    "offence_response = llm_chain_1.invoke({'data_str': 'Subject: FCIC Sentence Offences Categories by Degree Type' + offense_context})\n",
    "county_conviction_response = llm_chain_1.invoke({'data_str': 'Subject: County of Conviction' + county_conviction_context})\n",
    "\n",
    "display(Markdown('<span style=\"color: red;\"> \\n\\n# AI Generated Presentation of `IncarcerationSupervisionCharge_00000` and Visualizations\\n\\n' + charges_overlap_response.content + '\\n\\n' + days_response.content + '\\n\\n'+ indicators_response.content + '\\n\\n' + drug_type_response.content + '\\n\\n' + statute_response.content + '\\n\\n' + sentence_status_response.content + '\\n\\n' + offence_response.content + '\\n\\n' + county_conviction_response.content + ' \\n\\n </span>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92ca0e",
   "metadata": {
    "papermill": {
     "duration": 0.018974,
     "end_time": "2024-07-27T18:43:11.631035",
     "exception": false,
     "start_time": "2024-07-27T18:43:11.612061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IncarcerationSupervisionDisciplinary_00000 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d132a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:43:11.667630Z",
     "iopub.status.busy": "2024-07-27T18:43:11.666749Z",
     "iopub.status.idle": "2024-07-27T18:43:11.893605Z",
     "shell.execute_reply": "2024-07-27T18:43:11.892711Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.24801,
     "end_time": "2024-07-27T18:43:11.896053",
     "exception": false,
     "start_time": "2024-07-27T18:43:11.648043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## IncarcerationSupervisionDisciplinary_00000 Data Information:\n",
       "- **Rows**: 378632\n",
       "- **Columns**: 4\n",
       "- **Memory Usage**: 6.52 MB\n",
       "### Data Details:\n",
       "| Column | Non-Null Count | Dtype | Description | Value Distribution |\n",
       "|--------|----------------|-------|-------------|---------------------|\n",
       "| INCARCERATION_SUPERVISION_ID | 378632 non-null | int64 | Anonymized unique identifier | 46910 unique values |\n",
       "| INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC | 378632 non-null | category | Description of the type of disciplinary action taken | Disciplinary Confinement: 202840, Loss of Gain Time: 77972, Cashless Canteen Denial: 34823, Privilege Suspension - Other: 14780, Verbal Reprimand: 12873, Loss of Future Gain Time: 10365, Disciplinary Squad: 8756, Extra Duty: 7956, Restitution Payment: 5643, Alternative Housing: 1325, Privilege Suspension - Mail, Visitation: 543, Privilege Suspension - Visitation: 531, Privilege Suspension - Mail: 152, Restricted Labor Squad: 49, Disciplinary Confinement Part Time: 24 |\n",
       "| INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC | 378632 non-null | category | Description of the type of disciplinary violation | 104 unique values |\n",
       "| INCAR_SUPERV_CREATED_DATE | 378632 non-null | datetime64[ns] | Date when the incarceration/supervision record was created | Earliest: 2022-02-25, Latest: 2024-07-01 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of columns to drop from the df_dis DataFrame\n",
    "disc_cols_to_drop = ['INCAR_DISCIPLINARY_VIOL_CODE', 'INCAR_DISCIPLINARY_ACTION_CODE', 'UNIQUE_CORRELATION_ID', 'CORRELATION_ID']\n",
    "# Drop the specified columns\n",
    "df_dis = df_dis.drop(columns = disc_cols_to_drop)\n",
    "\n",
    "# Convert specified columns to categorical type for memory efficiency\n",
    "categorical_columns = ['INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC', 'INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC']\n",
    "for col in categorical_columns:\n",
    "    df_dis[col] = df_dis[col].astype('category')\n",
    "\n",
    "# Convert the 'INCAR_SUPERV_CREATED_DATE' column to datetime type    \n",
    "df_dis['INCAR_SUPERV_CREATED_DATE'] = pd.to_datetime(df_dis['INCAR_SUPERV_CREATED_DATE'])\n",
    "\n",
    "# Define descriptions for each column in df_dis\n",
    "descriptions_dis = [\n",
    "    \"Anonymized unique identifier\",\n",
    "    \"Description of the type of disciplinary action taken\",\n",
    "    \"Description of the type of disciplinary violation\",\n",
    "    \"Date when the incarceration/supervision record was created\"\n",
    "]\n",
    "\n",
    "# Function to generate a Markdown table with DataFrame information for df_dis\n",
    "def df_dis_info_markdown(df, descriptions=None, display_output=True):\n",
    "    # Get basic DataFrame info\n",
    "    rows, cols = df.shape\n",
    "    memory_usage = df.memory_usage(deep=True).sum()\n",
    "    memory_usage_str = f\"{memory_usage / 1024**2:.2f} MB\" if memory_usage > 1024**2 else f\"{memory_usage / 1024:.2f} KB\"\n",
    "    \n",
    "    # Construct the Markdown content\n",
    "    content = f\"\"\"\n",
    "## IncarcerationSupervisionDisciplinary_00000 Data Information:\n",
    "- **Rows**: {rows}\n",
    "- **Columns**: {cols}\n",
    "- **Memory Usage**: {memory_usage_str}\n",
    "### Data Details:\n",
    "| Column | Non-Null Count | Dtype | Description | Value Distribution |\n",
    "|--------|----------------|-------|-------------|---------------------|\n",
    "\"\"\"\n",
    "    # Iterate through columns to add their details to the Markdown table\n",
    "    for i, col in enumerate(df.columns):\n",
    "        dtype = df[col].dtype\n",
    "        non_null = df[col].count()\n",
    "        description = descriptions[i] if descriptions and i < len(descriptions) else \"\"\n",
    "        \n",
    "        # Determine value distribution based on column type\n",
    "        if col == \"INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC\":\n",
    "            value_dist = df[col].value_counts().to_dict()\n",
    "            value_dist_str = \", \".join([f\"{k}: {v}\" for k, v in value_dist.items()])\n",
    "        elif col == \"INCAR_SUPERV_CREATED_DATE\":\n",
    "            earliest = df[col].min().strftime('%Y-%m-%d')\n",
    "            latest = df[col].max().strftime('%Y-%m-%d')\n",
    "            value_dist_str = f\"Earliest: {earliest}, Latest: {latest}\"\n",
    "        else:\n",
    "            value_dist_str = f\"{df[col].nunique()} unique values\"\n",
    "        \n",
    "        content += f\"| {col} | {non_null} non-null | {dtype} | {description} | {value_dist_str} |\\n\"\n",
    "    \n",
    "    # Display the Markdown if display_output is True\n",
    "    if display_output:\n",
    "        display(Markdown(content))\n",
    "    \n",
    "    # Return the Markdown content as a string\n",
    "    return content\n",
    "\n",
    "# Generate the Markdown content for df_dis\n",
    "df_dis_content = df_dis_info_markdown(df_dis, descriptions_dis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea14b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:43:11.934805Z",
     "iopub.status.busy": "2024-07-27T18:43:11.934503Z",
     "iopub.status.idle": "2024-07-27T18:43:28.683099Z",
     "shell.execute_reply": "2024-07-27T18:43:28.682363Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 16.76988,
     "end_time": "2024-07-27T18:43:28.685524",
     "exception": false,
     "start_time": "2024-07-27T18:43:11.915644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generating Visualizations for Disciplinary dataset\n",
    "# Size Comparison/Overlap Plot\n",
    "### Determine the sizes\n",
    "size_large = len(df_root)\n",
    "size_small = len(df_dis['INCARCERATION_SUPERVISION_ID'].unique())\n",
    "\n",
    "# Dataset names for passing\n",
    "large_dataset_name = \"IncarcerationSupervision_00000\"\n",
    "small_dataset_name = \"IncarcerationSupervisionDisciplinary_00000\"\n",
    "\n",
    "# Find the overlap\n",
    "key_column = 'INCARCERATION_SUPERVISION_ID'\n",
    "unique_ids_in_df_dis = df_dis[key_column].unique()\n",
    "overlap = df_root[df_root[key_column].isin(unique_ids_in_df_dis)].shape[0]\n",
    "\n",
    "radius_small = 1\n",
    "radius_large = math.sqrt(size_large / size_small)\n",
    "\n",
    "# Calculate the distance between circle centers based on overlap\n",
    "overlap_ratio = overlap / size_small\n",
    "distance = radius_large + radius_small - (overlap_ratio * 2 * radius_small)\n",
    "\n",
    "# Adjust this factor to bring circles closer together or further apart\n",
    "distance_factor = 0.25  # Experiment with this value\n",
    "\n",
    "# Create a dataframe for our visualization\n",
    "viz_data = pd.DataFrame({\n",
    "    'x': [distance * distance_factor, 0],\n",
    "    'y': [0, 0],\n",
    "    'size': [size_large, size_small],\n",
    "    'radius': [radius_large, radius_small],\n",
    "    'dataset': [large_dataset_name, small_dataset_name],\n",
    "    'overlap': [overlap, overlap]\n",
    "})\n",
    "\n",
    "# Calculate the domain for x and y axes\n",
    "max_radius = max(radius_large, radius_small)\n",
    "x_domain = [-max_radius, (distance * distance_factor) + max_radius]\n",
    "y_domain = [-max_radius, max_radius]\n",
    "\n",
    "# Create the base chart\n",
    "base = alt.Chart(viz_data).encode(\n",
    "    x=alt.X('x:Q', scale=alt.Scale(domain=x_domain), axis=None),\n",
    "    y=alt.Y('y:Q', scale=alt.Scale(domain=y_domain), axis=None)\n",
    ")\n",
    "\n",
    "# Create circles representing dataset sizes\n",
    "circles = base.mark_circle(opacity=0.5).encode(\n",
    "    size=alt.Size('radius:Q', scale=alt.Scale(range=[0, 40000]), legend=None),\n",
    "    color=alt.Color('dataset:N', \n",
    "                    scale=alt.Scale(domain=[large_dataset_name, small_dataset_name], \n",
    "                                    range=['blue', 'red']),\n",
    "                    legend=alt.Legend(title=\"Datasets\", labelLimit=0)),\n",
    "    tooltip=['dataset', 'size', 'overlap']\n",
    ")\n",
    "\n",
    "# Combine all elements\n",
    "size_comparison_chart2 = circles.properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title=f\"Dataset Size Comparison (Overlap: {overlap} persons)\"\n",
    ").configure_view(\n",
    "    strokeWidth=0\n",
    ").configure_legend(\n",
    "    labelLimit=0,  # Ensures full names are shown in legend\n",
    "    orient='bottom',  # Positions legend at the bottom\n",
    "    columns=1,  # Stacks legend entries vertically\n",
    "    titleFontSize=14,\n",
    "    labelFontSize=12\n",
    ")\n",
    "size_comparison_chart2.save('Dataset_Size_Comparison2.html')\n",
    "\n",
    "# Time series of disciplinary records creation\n",
    "df_dis['INCAR_SUPERV_CREATED_DATE'] = pd.to_datetime(df_dis['INCAR_SUPERV_CREATED_DATE'])\n",
    "\n",
    "# Group by month and count\n",
    "monthly_counts = df_dis.groupby(df_dis['INCAR_SUPERV_CREATED_DATE'].dt.to_period('M')).size().reset_index(name='count')\n",
    "monthly_counts['INCAR_SUPERV_CREATED_DATE'] = monthly_counts['INCAR_SUPERV_CREATED_DATE'].dt.start_time\n",
    "\n",
    "# Create the Altair chart\n",
    "dis_record_creation_chart = alt.Chart(monthly_counts).mark_line().encode(\n",
    "    x=alt.X('INCAR_SUPERV_CREATED_DATE:T', title='Date'),\n",
    "    y=alt.Y('count:Q', title='Count'),\n",
    "    tooltip=['INCAR_SUPERV_CREATED_DATE:T', 'count:Q']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title='Time Series of Disciplinary Record Creation by Month'\n",
    ")\n",
    "dis_record_creation_chart.save('Time_Series_of_Disciplinary_Record_Creation_by_Month.html')\n",
    "\n",
    "infractions = df_dis['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].unique()\n",
    "\n",
    "system = \"\"\"You are a Research Coordinator. You will be given a very long list of alleged rule violations by incarcerated or supervised persons under the jurisdiction of the Florida Department of Corrections.\n",
    "You will:\n",
    "1. Use the list to compile a list of 10 mutually exclusive categories. Ensure the categories are informative to a broad range of stakeholders.\n",
    "2. Return ONLY a dictionary mapping the initial items to the categories you have compiled. Do not comment. Do not open and do not conclude. You will provide the dictionary only.\n",
    "3. Do not enclose your dictionary in code delimiters. Do not use newline characters '\\n'.\n",
    "4. Do not supply any additional response. \n",
    "Your response should be directly parseable as a Python dictionary.\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', system),\n",
    "    ('human', \"{data_str}\")\n",
    "])\n",
    "llm_2 = ChatOpenAI(openai_api_key=secret_value_0, temperature = 0, model = model) \n",
    "llm_chain_2 = prompt_template | llm_2\n",
    "infractions_response = llm_chain_2.invoke(\n",
    "    {'data_str': infractions.tolist()})\n",
    "\n",
    "dict_string = infractions_response.content.replace(\"'\", '\"')\n",
    "infractions_dictionary = json.loads(dict_string)\n",
    "df_dis['alleged_violation_category'] = df_dis['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].map(infractions_dictionary)\n",
    "df_dis['alleged_violation_category'].value_counts()\n",
    "\n",
    "violation_counts = df_dis['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].value_counts().reset_index()\n",
    "violation_counts.columns = ['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC', 'count']\n",
    "\n",
    "action_violation_counts = df_dis.groupby(['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC', 'INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC'], observed=True).size().reset_index(name='count')\n",
    "\n",
    "category_counts = df_dis['alleged_violation_category'].value_counts().reset_index()\n",
    "category_counts.columns = ['alleged_violation_category', 'count']\n",
    "\n",
    "category_action_counts = df_dis.groupby(['alleged_violation_category', 'INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC'], observed=True).size().reset_index(name='count')\n",
    "\n",
    "# Get top 50 violations\n",
    "top_50_violations = violation_counts.nlargest(50, 'count')['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].tolist()\n",
    "\n",
    "# Calculate the total number of unique violations\n",
    "total_unique_violations = df_dis['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].nunique()\n",
    "\n",
    "# Define an extended, more accessible color scheme\n",
    "color_scheme = alt.Scale(range=[\n",
    "    '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n",
    "    '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',\n",
    "    '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5',\n",
    "    '#c49c94', '#f7b6d2', '#c7c7c7', '#dbdb8d', '#9edae5'\n",
    "])\n",
    "\n",
    "# First subfigure: Top 50 violations\n",
    "violations_chart = (\n",
    "    alt.Chart(action_violation_counts[action_violation_counts['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].isin(top_50_violations)])\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        y=alt.Y('INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC:N', \n",
    "                sort='-x', \n",
    "                title='Violation Type'),\n",
    "        x=alt.X('sum(count):Q', title='Count'),\n",
    "        color=alt.Color('INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC:N', \n",
    "                        scale=color_scheme,\n",
    "                        legend=alt.Legend(title='Action Type', orient='bottom', columns=3)),\n",
    "        tooltip=['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC', \n",
    "                 'INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC', \n",
    "                 'sum(count)']\n",
    "    )\n",
    "    .properties(\n",
    "        title=f'Top 50 of {total_unique_violations} Disciplinary Violations',\n",
    "        width=800,\n",
    "        height=600\n",
    "    )\n",
    ")\n",
    "\n",
    "# Second subfigure: Violation categories\n",
    "categories_chart = (\n",
    "    alt.Chart(category_action_counts)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X('alleged_violation_category:N', \n",
    "                sort='-y', \n",
    "                axis=alt.Axis(labelAngle=-45), \n",
    "                title='Violation Category'),\n",
    "        y=alt.Y('sum(count):Q', title='Count'),\n",
    "        color=alt.Color('INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC:N', \n",
    "                        scale=color_scheme,\n",
    "                        legend=None),\n",
    "        tooltip=['alleged_violation_category', \n",
    "                 'INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC', \n",
    "                 'sum(count)']\n",
    "    )\n",
    "    .properties(\n",
    "        title='Disciplinary Violations by Category',\n",
    "        width=800,\n",
    "        height=400\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine the two charts vertically\n",
    "violations_by_actions_chart = alt.vconcat(violations_chart, categories_chart)\n",
    "\n",
    "# Save the chart\n",
    "violations_by_actions_chart.save('Composite_Violations_by_Outcome_Top_50_and_Categorized.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbd2c09",
   "metadata": {
    "papermill": {
     "duration": 0.016992,
     "end_time": "2024-07-27T18:43:28.720327",
     "exception": false,
     "start_time": "2024-07-27T18:43:28.703335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AI Presentation of the IncarcerationSupervisionDisciplinary_00000 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a80a4d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:43:28.757294Z",
     "iopub.status.busy": "2024-07-27T18:43:28.756438Z",
     "iopub.status.idle": "2024-07-27T18:43:48.876081Z",
     "shell.execute_reply": "2024-07-27T18:43:48.875091Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 20.140442,
     "end_time": "2024-07-27T18:43:48.878102",
     "exception": false,
     "start_time": "2024-07-27T18:43:28.737660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color: red;\"> \n",
       "\n",
       "# AI Generated Presentation of `IncarcerationSupervisionDisciplinary_00000` and Visualizations\n",
       "\n",
       "\n",
       "\n",
       "## Overlap with First Dataset:\n",
       "\n",
       "### Visualization Overview\n",
       "The visualization titled \"Dataset Size Comparison (Overlap: 46324 persons)\" illustrates the relative size comparison between two datasets: `IncarcerationSupervision_00000` and `IncarcerationSupervisionDisciplinary_00000`. The shared area between the circles represents the overlap of 46,324 persons between these datasets. \n",
       "\n",
       "### Dataset Variables\n",
       "- **Dataset Names**:\n",
       "  - `IncarcerationSupervision_00000`\n",
       "  - `IncarcerationSupervisionDisciplinary_00000`\n",
       "- **Overlap**: 46,324 (the number of persons common to both datasets)\n",
       "- **Size**:\n",
       "  - `IncarcerationSupervision_00000`: 112,894\n",
       "  - `IncarcerationSupervisionDisciplinary_00000`: 46,910\n",
       "\n",
       "### Insights\n",
       "The visualization indicates that while both datasets share a significant number of persons (46,324), the total sizes of the datasets differ considerably. The first dataset is notably larger, which may suggest a broader scope of data collection or different criteria for inclusion.\n",
       "\n",
       "### Data Quality Considerations\n",
       "The approximation of the overlap area may not accurately reflect the true intersection due to the complexity of visualizing overlapping circles. This could lead to misinterpretations regarding the extent of shared data.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Dataset_Size_Comparison2.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "## Disciplinary Record Creation Dates\n",
       "\n",
       "### Overview\n",
       "This section presents a time series analysis of the creation dates of disciplinary records associated with incarcerated and supervised persons in Florida. The dataset captures the number of records created each month from February 2022 through July 2024. The variable of interest is `INCAR_SUPERV_CREATED_DATE`, which indicates the date when each record was created.\n",
       "\n",
       "### Data Insights\n",
       "The dataset contains a total of **378,632** records, with the earliest record creation date being **February 25, 2022**, and the latest being **July 1, 2024**. The following insights can be drawn from the data:\n",
       "\n",
       "- **Monthly Trends**: The number of disciplinary records created varies significantly from month to month. For instance, there is a notable spike in record creation in **July 2023**, with **225,754** records created, which is an outlier compared to other months. This could indicate a specific event or policy change that led to an increase in disciplinary actions during that period.\n",
       "  \n",
       "- **Fluctuations**: After the peak in July 2023, the number of records created drops sharply to **220** in August 2023, followed by a gradual increase in subsequent months, suggesting a return to more typical levels of record creation.\n",
       "\n",
       "- **Seasonal Patterns**: The data may exhibit seasonal patterns, with certain months consistently showing higher or lower counts. For example, the months of **May 2023** and **July 2023** stand out with significantly higher counts compared to other months.\n",
       "\n",
       "### Visualization\n",
       "The following line chart visualizes the time series of disciplinary record creation by month, allowing for a clearer understanding of trends over time.\n",
       "\n",
       "<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Time_Series_of_Disciplinary_Record_Creation_by_Month.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Data Quality Considerations\n",
       "- **Outliers**: The extreme value in July 2023 should be investigated further to understand the underlying causes. It is essential to determine whether this spike is due to a genuine increase in disciplinary actions or if it reflects data entry errors or changes in reporting practices.\n",
       "\n",
       "- **Missing Data**: While the dataset appears to be comprehensive, it is crucial to verify if there are any missing months or anomalies in the data collection process that could affect the analysis.\n",
       "\n",
       "### Variable Information for Data Scientists\n",
       "- **INCAR_SUPERV_CREATED_DATE**: This variable is of type `datetime64[ns]` and represents the date when the incarceration/supervision record was created. It is essential for time-based analyses and understanding trends over time.\n",
       "- **Count**: This is a calculated variable representing the number of records created in each month, which is crucial for visualizations and trend analysis.\n",
       "\n",
       "This detailed examination of the disciplinary record creation dates provides valuable insights into the patterns and trends of disciplinary actions within the Florida Department of Corrections.\n",
       "\n",
       "## Alleged Disciplinary Infractions and Outcomes\n",
       "\n",
       "### Overview\n",
       "This dataset provides insights into the disciplinary actions taken against incarcerated persons within the Florida Department of Corrections. It includes a breakdown of the types of disciplinary actions and the corresponding violations that led to these actions. The data consists of 378,632 non-null entries, indicating a comprehensive record of disciplinary incidents.\n",
       "\n",
       "### Disciplinary Action Types\n",
       "The variable `INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC` categorizes the types of disciplinary actions taken. Here are the most common actions recorded:\n",
       "\n",
       "- **Disciplinary Confinement**: 202,840 instances\n",
       "- **Loss of Gain Time**: 77,972 instances\n",
       "- **Cashless Canteen Denial**: 34,823 instances\n",
       "- **Privilege Suspension - Other**: 14,780 instances\n",
       "- **Verbal Reprimand**: 12,873 instances\n",
       "- **Loss of Future Gain Time**: 10,365 instances\n",
       "- **Disciplinary Squad**: 8,756 instances\n",
       "- **Extra Duty**: 7,956 instances\n",
       "- **Restitution Payment**: 5,643 instances\n",
       "- **Alternative Housing**: 1,325 instances\n",
       "\n",
       "These actions reflect the various consequences that can be imposed for rule violations, with \"Disciplinary Confinement\" being the most frequently applied measure.\n",
       "\n",
       "### Types of Disciplinary Violations\n",
       "The variable `INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC` describes the types of violations that lead to disciplinary actions. The following are the most prevalent categories of alleged violations:\n",
       "\n",
       "- **Disrespect and defiance**: 71,219 instances\n",
       "- **Drug-related offenses**: 38,177 instances\n",
       "- **Disorderly behavior**: 27,513 instances\n",
       "- **Communication violations**: 24,411 instances\n",
       "- **Violence offenses**: 20,411 instances\n",
       "- **Unauthorized access**: 18,818 instances\n",
       "- **Weapon-related offenses**: 16,000 instances\n",
       "- **Contraband offenses**: 15,939 instances\n",
       "- **Threatening behavior**: 13,783 instances\n",
       "- **Sexual misconduct**: 13,269 instances\n",
       "\n",
       "The data reveals a significant prevalence of disrespect and defiance as the leading cause of disciplinary actions, followed by drug-related offenses and disorderly behavior. This insight may inform policymakers about the behavioral issues that are most common within the correctional environment.\n",
       "\n",
       "### Visualization\n",
       "The following visualization illustrates the top 50 disciplinary violations and their outcomes, providing a clear representation of the data discussed above.\n",
       "\n",
       "<div style=\"width: 1000px; height: 1500px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
       "\n",
       "<iframe src=\"Composite_Violations_by_Outcome_Top_50_and_Categorized.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
       "\n",
       "</div>\n",
       "\n",
       "### Data Quality and Limitations\n",
       "While the dataset is extensive, it is important to acknowledge potential limitations. The categorization of violations through AI mapping may introduce biases or inaccuracies if the mapping does not fully capture the nuances of each violation. Additionally, the dataset may not account for all disciplinary actions taken, as it is based on recorded incidents. Researchers and policymakers should consider these factors when interpreting the data.\n",
       "\n",
       "### Insights for Data Scientists\n",
       "For data scientists working with this dataset, the key variables to focus on include:\n",
       "- `INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC`: Categorical variable detailing the type of disciplinary action.\n",
       "- `INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC`: Categorical variable detailing the type of violation.\n",
       "- `alleged_violation_category`: This variable can be used to analyze the frequency of specific violation categories.\n",
       "\n",
       "Understanding these variables will be crucial for any further analysis or modeling efforts. \n",
       "\n",
       " </span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating context for AI Presentation:\n",
    "overlap2_context = \"Subject: Overlap with first dataset, html file path: 'Dataset_Size_Comparison2.html', This visualization shows the relative size comparison between the current dataset, `IncarcerationSupervisionDisciplinary_00000`, and the initially presented dataset, `IncarcerationSupervision_00000`. at this time the depicted shared area between the circles only approximates the overlap between datasets, given the complexity of finding the area shared between two overlapping circles.\" + size_comparison_chart2.to_json()\n",
    "\n",
    "record_creation_date_row = extract_rows(df_dis_content, ['INCAR_SUPERV_CREATED_DATE']) \n",
    "record_creation_date_context = \"Subject: Disciplinary Record Creation Dates, html file path: 'Time_Series_of_Disciplinary_Record_Creation_by_Month.html'\" + dis_record_creation_chart.to_json() + record_creation_date_row\n",
    "\n",
    "infractions_actions_columns = ['INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC', 'INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC']\n",
    "infractions_actions_rows = extract_rows(df_dis_content, infractions_actions_columns)\n",
    "infractions_actions_context = \"\"\"Subject: Alleged Disciplinary Infactions and Outcomes, html file path: 'Composite_Violations_by_Outcome_Top_50_and_Categorized.html' **Please allow this figure a height of 1500 and a width of 1000, example: <div style=\"width: 1000px; height: 1500px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">**\"\"\" + infractions_actions_rows + df_dis['alleged_violation_category'].value_counts().to_markdown() + \"\"\"Context: Given the large number of unique rule violation categories in the Florida Department of Corrections data, AI mapping from the raw rule values into categories has been employed. <<context for AI only: It would add appeal to your response if you inform the user that the AI chatbot embedded at the end of this document has been trained to let users specify their own categories of rule infractions for review.>>\"\"\"\n",
    "\n",
    "# Generating AI Presentation:\n",
    "overlap2_response = llm_chain_1.invoke({'data_str': overlap2_context + \"Additional Instruction: The radii of the circles are not informative in this context; please do not comment on them. Please be succinct with this response.\"})\n",
    "record_creation_date_response = llm_chain_1.invoke({'data_str': record_creation_date_context})\n",
    "infractions_actions_response = llm_chain_1.invoke({'data_str': infractions_actions_context})\n",
    "\n",
    "display(Markdown('<span style=\"color: red;\"> \\n\\n# AI Generated Presentation of `IncarcerationSupervisionDisciplinary_00000` and Visualizations\\n\\n' + '\\n\\n' + overlap2_response.content + '\\n\\n' +  record_creation_date_response.content + '\\n\\n' + infractions_actions_response.content + ' \\n\\n </span>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e66ccd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:43:48.916307Z",
     "iopub.status.busy": "2024-07-27T18:43:48.915666Z",
     "iopub.status.idle": "2024-07-27T18:43:48.954140Z",
     "shell.execute_reply": "2024-07-27T18:43:48.953387Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.059605,
     "end_time": "2024-07-27T18:43:48.956352",
     "exception": false,
     "start_time": "2024-07-27T18:43:48.896747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Prepare categorical columns\n",
    "categorical_columns = ['RACE_CODE', 'SEX_CODE', 'ETHNICITY_CODE', 'CORRECTION_ADMISSION_REASON_DESC', \n",
    "                       'CURRENT_INSTITUTION_ORI_TYPE_DESC', 'CUSTODY_RELEASE_REASON_DESC', \n",
    "                       'SUPERVISION_CATEGORY_DESC', 'COUNTY_DESCRIPTION', 'HIGHEST_EDUCATION_LEVEL',\n",
    "                       'INCARCERATION_CUSTODY_LEVEL_TYPE_DESC']\n",
    "\n",
    "# 3. Add new categories and fill nulls for all relevant columns\n",
    "new_categories = {\n",
    "    'CUSTODY_RELEASE_REASON_DESC': 'Not Released',\n",
    "    'INCARCERATION_CUSTODY_LEVEL_TYPE_DESC': 'Unknown',\n",
    "    'SUPERVISION_CATEGORY_DESC': 'Not Under Supervision',\n",
    "    'HIGHEST_EDUCATION_LEVEL': 'Missing'\n",
    "}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in new_categories:\n",
    "        # If the column is already categorical, add the new category\n",
    "        if df_root[col].dtype.name == 'category':\n",
    "            df_root[col] = df_root[col].cat.add_categories([new_categories[col]])\n",
    "        # Fill null values with the new category\n",
    "        df_root[col] = df_root[col].fillna(new_categories[col])\n",
    "    else:\n",
    "        # For other categorical columns, use 'Missing' as the fill value\n",
    "        if df_root[col].dtype.name == 'category':\n",
    "            df_root[col] = df_root[col].cat.add_categories(['Missing'])\n",
    "        df_root[col] = df_root[col].fillna('Missing')\n",
    "    \n",
    "    # Ensure the column is of categorical type\n",
    "    df_root[col] = df_root[col].astype('category')\n",
    "\n",
    "\n",
    "# 5. Ensure 'race_ethnicity' is categorical\n",
    "df_root['race_ethnicity'] = df_root['race_ethnicity'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf8674eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:43:48.994489Z",
     "iopub.status.busy": "2024-07-27T18:43:48.993683Z",
     "iopub.status.idle": "2024-07-27T18:43:49.075275Z",
     "shell.execute_reply": "2024-07-27T18:43:49.074401Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.102975,
     "end_time": "2024-07-27T18:43:49.077677",
     "exception": false,
     "start_time": "2024-07-27T18:43:48.974702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simplify_text(text):\n",
    "    # Remove iframe tags\n",
    "    text = re.sub(r'<div[^>]*>.*?<iframe[^>]*>.*?</iframe>.*?</div>', '', text, flags=re.DOTALL)\n",
    "    \n",
    "    # Simplify headers\n",
    "    text = re.sub(r'#{1,6}\\s*', '', text)\n",
    "    \n",
    "    # Remove bold markdown\n",
    "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)\n",
    "    \n",
    "    # Remove unnecessary newlines and spaces\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = re.sub(r' {2,}', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "df_root_presentation = demographic_response.content + '\\n\\n' + education_response.content + '\\n\\n' + dates_response.content + '\\n\\n' + reasons_response.content + '\\n\\n' + tags_response.content + '\\n\\n' + institutional_response.content + '\\n\\n' + location_response.content\n",
    "df_charges_presentation = charges_overlap_response.content + '\\n\\n' + days_response.content + '\\n\\n'+ indicators_response.content + '\\n\\n' + drug_type_response.content + '\\n\\n' + statute_response.content + '\\n\\n' + sentence_status_response.content + '\\n\\n' + offence_response.content + '\\n\\n' + county_conviction_response.content\n",
    "df_dis_presentation = overlap2_response.content + '\\n\\n' +  record_creation_date_response.content + '\\n\\n' + infractions_actions_response.content\n",
    "\n",
    "df_root_presentation_cleaned = simplify_text(df_root_presentation)\n",
    "df_charges_presentation_cleaned = simplify_text(df_charges_presentation)\n",
    "df_dis_presentation_cleaned = simplify_text(df_dis_presentation)\n",
    "\n",
    "buffer = io.StringIO()\n",
    "with redirect_stdout(buffer):\n",
    "    df_root.info()\n",
    "df_root_info_string = buffer.getvalue()\n",
    "with redirect_stdout(buffer):\n",
    "    df_charges.info()\n",
    "df_charges_info_string = buffer.getvalue()\n",
    "with redirect_stdout(buffer):\n",
    "    df_dis.info()\n",
    "df_dis_info_string = buffer.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c14fd4",
   "metadata": {
    "papermill": {
     "duration": 0.017472,
     "end_time": "2024-07-27T18:43:49.114061",
     "exception": false,
     "start_time": "2024-07-27T18:43:49.096589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Current Experimental Version AI Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c8478ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:43:49.151245Z",
     "iopub.status.busy": "2024-07-27T18:43:49.150855Z",
     "iopub.status.idle": "2024-07-27T18:43:49.166675Z",
     "shell.execute_reply": "2024-07-27T18:43:49.165801Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.036841,
     "end_time": "2024-07-27T18:43:49.168545",
     "exception": false,
     "start_time": "2024-07-27T18:43:49.131704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CodingAgent:\n",
    "    def __init__(self, model: str = model, max_error_length: int = 500):\n",
    "        self.model = model\n",
    "        self.llm = ChatOpenAI(openai_api_key=secret_value_0, temperature=0, model=self.model)\n",
    "        self.max_error_length = max_error_length\n",
    "\n",
    "    def generate_step_by_step_plan(self, user_plan: str, context: str) -> str:\n",
    "        system = f\"\"\"You are the project manager for a Python data analytics project. The structure of the project is as follows: A user generates a query for an agent. The agent will then develop a broad plan to accomplish the query task. Next, the agent will pass the broad plan to you, along with the user's query.\n",
    "Your role is to take the broad plan and the context to generate a psudocode step-by-step coding plan, which you will then return. Your response will be delivered directly to the coding agent to write the code. You will not write any Python code yourself. As project manager, your role is to develop a detailed sequential psudocode plan for the coding agent. Use the exact and precise variables and variable category values from the data available to you. For visualizations, always plan to use Altair, not Matplotlib or Seaborn. Ensure the visualization is published by saving the Altair plot object as an html file, and also print the file path where the file will be saved. You will not provide any additional comments or invitations to continue the conversation; you will provide the psudocode step-by-step plan for the coding agent only. You will not wrap your response in code delimiters because you will not write code, you will produce a psudocode step-by-step plan only. The datasets InacerationSupervision_00000, InacerationSupervisionCharge_00000, and InacerationSupervisiondisciplinary_00000 are currently loaded in the coding environment as df_root, df_charges, and df_dis, respectively. The current structures are InacerationSupervision_00000: {df_root_info_string}, InacerationSupervisionCharge_00000: {df_charges_info_string}, and InacerationSupervisiondisciplinary_00000: {df_dis_info_string}. For additional context, here is a presentation of each dataset: InacerationSupervision_00000 (df_root): {df_root_presentation_cleaned}, InacerationSupervisionCharge_00000 (df_charges): {df_charges_presentation_cleaned}, and InacerationSupervisiondisciplinary_00000 (df_dis): {df_dis_presentation_cleaned}.\"\"\"\n",
    "        \n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            ('system', system),\n",
    "            ('human', f\"Context: {context}, user's plan: {user_plan}\")\n",
    "        ])\n",
    "        \n",
    "        llm_chain = prompt_template | self.llm\n",
    "        response = llm_chain.invoke({'context': context, 'user_plan': user_plan})\n",
    "        return response.content\n",
    "\n",
    "    def generate_code(self, step_by_step_plan: str) -> str:\n",
    "        system = f\"\"\"Based on the provided step-by-step plan, generate the appropriate Python code to execute these steps.\n",
    "\n",
    "The datasets InacerationSupervision_00000, InacerationSupervisionCharge_00000, and InacerationSupervisiondisciplinary_00000 are currently loaded in the coding environment as `df_root`, `df_charges`, and `df_dis`, respectively. The current structures are:\n",
    "\n",
    "- InacerationSupervision_00000 (`df_root`): `{df_root_info_string}`\n",
    "- InacerationSupervisionCharge_00000 (`df_charges`): `{df_charges_info_string}`\n",
    "- InacerationSupervisiondisciplinary_00000 (`df_dis`): `{df_dis_info_string}`.\n",
    "\n",
    "If you use the `.groupby()` function, pass the argument `observed=True` to it, for example: `groupby('grouping_variable', observed=True)`.\n",
    "\n",
    "**Return only the code, without any explanations.**\n",
    "\n",
    "**Do not wrap the code in triple backticks**, the string you provide should be directly executable when passed to `exec()`.\n",
    "\n",
    "Ensure you include a `print()` statement to capture any textual code outputs.\n",
    "\n",
    "For visualizations, always use Altair, not Matplotlib or Seaborn.\n",
    "\n",
    "Ensure the visualization is published by saving the Altair plot object using the `.save()` method, and also print the file path where you saved the file.\n",
    "\n",
    "- For an Altair plot titled 'Pie Chart', for example, you will save the Altair plot object as `plot.save('Pie_Chart.html')` and `print('Altair plot saved to \"Pie_Chart.html\"')`.\n",
    "\n",
    "If the plan you receive for a visualization conflicts with these instructions, you should ignore those aspects of the plan.\n",
    "\n",
    "Altair plot objects should be saved as HTML files, not PNG or other formats, and the filepath should be printed for image publication.\n",
    "DO NOT WRAP YOUR CODE IN TRIPLE BACKTICKS!\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            ('system', system),\n",
    "            ('human', f\"Step-by-step plan: {step_by_step_plan}\")\n",
    "        ])\n",
    "        \n",
    "        llm_chain = prompt_template | self.llm\n",
    "        response = llm_chain.invoke({'step_by_step_plan': step_by_step_plan})\n",
    "        return response.content\n",
    "\n",
    "    def truncate_error(self, error_message: str) -> str:\n",
    "        if len(error_message) > self.max_error_length:\n",
    "            return error_message[:self.max_error_length] + \"... (truncated)\"\n",
    "        return error_message\n",
    "\n",
    "    def execute_code(self, code: str) -> Dict[str, Any]:\n",
    "        old_stdout = sys.stdout\n",
    "        redirected_output = sys.stdout = StringIO()\n",
    "        try:\n",
    "            exec(code, globals())\n",
    "            output = redirected_output.getvalue()\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"output\": self.truncate_error(output)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error_message\": self.truncate_error(str(e)),\n",
    "                \"problematic_code\": code\n",
    "            }\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "\n",
    "    def process_request(self, user_plan: str, context: str) -> Dict[str, Any]:\n",
    "        step_by_step_plan = self.generate_step_by_step_plan(user_plan, context)\n",
    "        generated_code = self.generate_code(step_by_step_plan)\n",
    "        execution_result = self.execute_code(generated_code)\n",
    "        \n",
    "        return {\n",
    "            \"step_by_step_plan\": step_by_step_plan,\n",
    "            \"generated_code\": generated_code,\n",
    "            \"execution_result\": execution_result\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acb7c509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:43:49.205959Z",
     "iopub.status.busy": "2024-07-27T18:43:49.205642Z",
     "iopub.status.idle": "2024-07-27T18:43:49.226766Z",
     "shell.execute_reply": "2024-07-27T18:43:49.225885Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.042344,
     "end_time": "2024-07-27T18:43:49.228767",
     "exception": false,
     "start_time": "2024-07-27T18:43:49.186423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chat_with_bot(user_input, llm, memory, coding_agent):\n",
    "    # Add the user's message to the memory\n",
    "    memory.chat_memory.add_user_message(user_input)\n",
    "    \n",
    "    # Create a list of messages\n",
    "    messages = memory.chat_memory.messages\n",
    "    \n",
    "    # Check if the system message is already present\n",
    "    system_message_present = any(isinstance(msg, SystemMessage) for msg in messages)\n",
    "    \n",
    "    # If the system message is not present, add it\n",
    "    if not system_message_present:\n",
    "        agent_instructions = f\"\"\"You are a data project manager, helping users explore data loaded into the current coding environment. Your primary role is to assist users by directing projects which analyze and visualize the datasets InacerationSupervision_00000, InacerationSupervisionCharge_00000, and InacerationSupervisiondisciplinary_00000, which are currently loaded in the coding environment as df_root, df_charges, and df_dis, respectively.\n",
    "\n",
    "Instructions:\n",
    "1. When a user's query requires code execution or data manipulation, you will manage the project by first verifying you have the necessary data. Then, create a broad plain language plan that includes which variables to use and how to use them. You have the autonomy to execute any plan by passing it to the coding agent, who will handle all code planning and coding. Do NOT micromanage the coding agent. Just ensure you have the variables needed to answer the user's query and provide the coding agent with a general plain language plan outlining which variables will be used and how. As project manager you do not know how to code, you will only approve plans where all the data needed is present, but you will not handle anything beyond passing the coding agent a broad plan on which variables will me used and in which way. Use the exact and precise variables and variable category values from the data available to you.\n",
    "2. Use the [EXECUTE] ... [/EXECUTE] format to pass the plain language plan to the coding agent. Do not pass json data to the coding agent.\n",
    "3. Always alert users that plan execution may take a few moments after passing the plan to the coding agent.\n",
    "4. If plan execution fails, explain the issue, reassess project feasability, and try again if you can succeed with a modified plan.\n",
    "5. If unable to answer a query, throughly explain why.\n",
    "7. Explain all coding agent results in context of all available information. Present the reasoning of the coding agent in plain language before the results.\n",
    "8. Always display all Altair plots inline with your response using the format: [ALTAIR_PLOT:filename.html].\n",
    "\n",
    "Dataset Information:\n",
    "- Dataset names: IncarcerationSupervision_00000, InacerationSupervisionCharge_00000, InacerationSupervisiondisciplinary_00000\n",
    "- Loaded as: df_root, df_charges, df_dis\n",
    "- Columns: df_root: {df_root.columns}, df_charges: {df_charges.columns}, df_dis{df_dis.columns}\n",
    "\n",
    "Presentation of the datasets (extended context):\n",
    "{df_root_presentation_cleaned}, {df_charges_presentation_cleaned}, {df_dis_presentation_cleaned}\n",
    "\n",
    "Remember, your role is to guide any potential analysis and explain the data, NOT to execute code directly. Always provide clear, context-rich explanations and be prepared to adjust your approach based on user feedback or failed execution attempts.\"\"\"\n",
    "        messages.insert(1, SystemMessage(content=agent_instructions))\n",
    "    \n",
    "    # Create a widget to display the streaming output\n",
    "    output_widget = widgets.Output()\n",
    "    display(output_widget)\n",
    "    \n",
    "    # Function to display Altair plots\n",
    "    def display_plot(filename):\n",
    "        iframe_html = f'''\n",
    "        <div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
    "        <iframe src=\"{filename}\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n",
    "        </div>\n",
    "        '''\n",
    "        display(HTML(iframe_html))\n",
    "\n",
    "    # Function to update the output widget\n",
    "    def update_output(new_text):\n",
    "        output_widget.clear_output(wait=True)\n",
    "        with output_widget:\n",
    "            # Split the text into parts\n",
    "            parts = re.split(r'(\\[ALTAIR_PLOT:[^\\]]+\\])', new_text)\n",
    "            for part in parts:\n",
    "                if part.startswith('[ALTAIR_PLOT:'):\n",
    "                    # Extract filename and display plot\n",
    "                    filename = part[13:-1]  # Remove [ALTAIR_PLOT: and ]\n",
    "                    try:\n",
    "                        display_plot(filename)\n",
    "                    except FileNotFoundError:\n",
    "                        print(f'[Error: Plot file {filename} not found]')\n",
    "                else:\n",
    "                    # Display text in red\n",
    "                    display(HTML(f'<div style=\"color: red;\">{markdown(part)}</div>'))\n",
    "    \n",
    "    # Generate a streaming response from the AI\n",
    "    full_response = \"\"\n",
    "    for chunk in llm.stream(messages):\n",
    "        if chunk.content is not None:\n",
    "            full_response += chunk.content\n",
    "            update_output(full_response)\n",
    "            time.sleep(0.05)  # Add a small delay for smoother streaming\n",
    "    \n",
    "    # Check if the AI wants to execute a plan\n",
    "    if \"[EXECUTE]\" in full_response:\n",
    "        plan_start = full_response.index(\"[EXECUTE]\") + len(\"[EXECUTE]\")\n",
    "        plan_end = full_response.index(\"[/EXECUTE]\")\n",
    "        plan = full_response[plan_start:plan_end].strip()\n",
    "        \n",
    "        try:\n",
    "            agent_result = coding_agent.process_request(user_plan=plan, context=user_input)\n",
    "            if agent_result['execution_result']['status'] == 'error':\n",
    "                error_message = f\"Error in code execution: {agent_result['execution_result']['error_message']}\"\n",
    "                if 'fixed_code' in agent_result['execution_result']:\n",
    "                    error_message += f\"\\nAttempted fix:\\n{agent_result['execution_result']['fixed_code']}\"\n",
    "                messages.append(SystemMessage(content=error_message))\n",
    "            else:\n",
    "                # Truncate the agent result for the message\n",
    "                truncated_result = {\n",
    "                    \"step_by_step_plan\": agent_result[\"step_by_step_plan\"],\n",
    "                    \"generated_code\": agent_result[\"generated_code\"],\n",
    "                    \"execution_result\": {\n",
    "                        \"status\": agent_result[\"execution_result\"][\"status\"],\n",
    "                        \"output\": coding_agent.truncate_error(agent_result[\"execution_result\"][\"output\"])\n",
    "                    }\n",
    "                }\n",
    "                messages.append(SystemMessage(content=f\"Coding Agent Result: {truncated_result}\"))\n",
    "        except Exception as e:\n",
    "            messages.append(SystemMessage(content=f\"Error in Coding Agent: {coding_agent.truncate_error(str(e))}\"))\n",
    "        \n",
    "        # Stream the new response\n",
    "        new_response = \"\"\n",
    "        for chunk in llm.stream(messages):\n",
    "            if chunk.content is not None:\n",
    "                new_response += chunk.content\n",
    "                update_output(new_response)\n",
    "                time.sleep(0.05)\n",
    "        \n",
    "        full_response = new_response\n",
    "    \n",
    "    # Add the AI's response to the memory\n",
    "    memory.chat_memory.add_ai_message(full_response)\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "def run_interactive_chat_v3():\n",
    "    llm = ChatOpenAI(openai_api_key=secret_value_0, model=model, streaming=True)\n",
    "    memory = ConversationBufferWindowMemory(k=5)\n",
    "    coding_agent = CodingAgent(max_error_length=500)  # Set max error length to 500 characters\n",
    "    \n",
    "    buffer = StringIO()\n",
    "    df_root.info(buf=buffer)\n",
    "    df_root_info_str = buffer.getvalue()\n",
    "    \n",
    "    print(\"Welcome to the AI Chatbot! Type 'quit' to exit.\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Thanks for chatting! Goodbye.\")\n",
    "            break\n",
    "        \n",
    "        response = chat_with_bot(user_input, llm, memory, coding_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0274f5fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T18:43:49.266599Z",
     "iopub.status.busy": "2024-07-27T18:43:49.265934Z",
     "iopub.status.idle": "2024-07-27T18:43:49.270041Z",
     "shell.execute_reply": "2024-07-27T18:43:49.269216Z"
    },
    "papermill": {
     "duration": 0.02494,
     "end_time": "2024-07-27T18:43:49.272074",
     "exception": false,
     "start_time": "2024-07-27T18:43:49.247134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run_interactive_chat_v3()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5350921,
     "sourceId": 8900748,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5420963,
     "sourceId": 8999259,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 281.867748,
   "end_time": "2024-07-27T18:43:50.109551",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-27T18:39:08.241803",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
