{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8900748,"sourceType":"datasetVersion","datasetId":5350921},{"sourceId":8999259,"sourceType":"datasetVersion","datasetId":5420963}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install markdown2\n!pip install openai\n!pip install langchain_core\n!pip install langchain-openai\n!pip install -U langchain-community\n!pip install langchain\n!pip install langgraph","metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<style>\n    .custom-header {\n        color: #4a77d4;\n        border-bottom: 2px solid #4a77d4;\n        padding-bottom: 5px;\n    }\n    .custom-text {\n        font-family: Arial, sans-serif;\n        line-height: 1.6;\n    }\n</style>\n\n<h1 class=\"custom-header\">Exploration of Florida Corrections Data with AI</h1>\n\n<h3 class=\"custom-header\">Abstract</h3>\n\n<div style=\"background-color: #FFA07A; padding: 10px; border-radius: 5px;\">\n    This notebook project uses artificial intelligence to interactively present data provided by the Florida Department of Law Enforcement. After downloading and cleaning the dataset on Florida Department of Corrections incarceration and supervision data, I embedded AI to present the data along with interactive visualizations to represent the data's condition and contents. After the AI presentations, a chatbot has been integrated, allowing users to ask questions, request customizations/adjustments of visualizations or novel ones, or discuss potential insights.\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Table of Contents\n\n1. [Introduction](#Introduction)\n   - [Project Overview](#Project-Overview)\n2. [Data Sources](#Data-Sources)\n   - [Data Origin and Access](#Data-Origin-and-Access)\n   - [Data Updates and Scope](#Data-Updates-and-Scope)\n   - Code Importing Libraries, Datasets, and API Keys\n3. [Preprocessing, Data Dictionaries, and AI Presentations](#Preprocessing,-Data-Dictionaries,-and-AI-Presentations )\n   - [Incarcerationsupervision_00000 File](#Incarcerationsupervision_00000-File)\n     - Code: Import, Cleaning, and Data Dictionary Generation\n     - Output: df_root Data Dictionary\n     - Code: Generating Visualizations\n     - Code: Embedding AI for Data Presentaion of Incarcerationsupervision_00000 dataset\n     - AI Presentation: Incarcerationsupervision_00000 file and Visualizations\n   - [IncarcerationSupervisionCharge_00000 File](#IncarcerationSupervisionCharge_00000-File)\n     - Code: Import, Cleaning, and Data Dictionary Generation\n     - Output: Data Dictionary\n     - Code: Generating Visualizations\n     - Code: Embedding AI for Data Presentaion of IncarcerationSupervisionCharge_00000 dataset\n     - AI Presentation: IncarcerationSupervisionCharge_00000 file and Visualizations\n   - [IncarcerationSupervisionDisciplinary_00000 File](#IncarcerationSupervisionDisciplinary_00000-File)\n     - Code: Import, Cleaning, and Data Dictionary Generation\n     - Output: Data Dictionary\n     - Code: Generating Visualizations\n     - Code: Embedding AI for Data Presentaion of IncarcerationsupervisionDisciplinary_00000 dataset\n     - AI Presentation: IncarcerationsupervisionDisciplinary_00000 file and Visualizations\n4. [AI Chatbot](#Exploratory-Data-Analysis-EDA)\n  ","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n## Project Overview\n# Florida Department of Corrections Data Access Project\n\n## Project Overview\n\nThis initiative aims to enhance public access to Florida Department of Corrections (FDOC) data, as made available by the Florida Department of Law Enforcement (FDLE). The project seeks to transform technically available but practically inaccessible public data into a truly accessible and understandable resource.\n\n## Author Background\n\nThe project lead brings a unique perspective to this work:\n\n- Spent nearly 19 years in the FDOC system\n- Earned a degree in data science post-incarceration\n- Currently works as a data annotator\n- Planning to pursue a master's degree in information and data science\n\nThe author's experience of incarceration provides valuable context for understanding the data and its importance. However, the author has found that this experience can make the objective presentation of incarceration data difficult.\n\n## Project Goals\n\n1. Clean and organize FDOC data that FDLE is legally required to make public\n2. Create a more accessible portal for this data, addressing limitations of the current FDLE public dashboard\n3. Provide a platform for public, researchers, and policymakers to explore and analyze the data independently\n4. Integrate AI assistance to enhance data navigation and comprehension (experimental approach)\n\n## Key Principles\n\n- **Objectivity**: The project aims to present data as objectively as possible, without drawing conclusions about the correctional or criminal legal systems\n- **Transparency**: By improving access to information, the project seeks to facilitate more informed discussions about Florida's correctional system\n- **Data Limitations**: Acknowledge and highlight gaps or unclear areas in current reporting\n- **Accessibility**: Transform technically available but difficult-to-use public data into a truly accessible and understandable resource\n\n## Expected Impact\n\nThis project has the potential to:\n- Empower researchers, policymakers, and the public with better access to critical information\n- Highlight areas where data collection or reporting could be improved\n- Foster more informed discussions and decision-making regarding Florida's correctional system\n- Demonstrate innovative approaches to making public data more accessible and useful\n\n# Data Sources\n\nThe data used in this project is sourced from the Florida Department of Law Enforcement (FDLE) as part of the Criminal Justice Data Transparency (CJDT) initiative. This initiative was established by the Florida Legislature through Florida Statutes §900.05 and §943.6871 to increase public visibility of criminal justice processes throughout the state and provide policymakers with information for informed decision-making. As per the CJDT data specifications it should include the records of juveniles treated as adults and the records of adults only.\n\n\n### Data Origin and Access\n\nThe raw data is available through the [FDC Incarceration and Supervision Reports](https://www.fdle.state.fl.us/CJAB/CJDT/FDC-IS-Reports) page on the FDLE website.\n\nFor a description of the CJDT initiative and the data it encompasses, please refer to the [Criminal Justice Data Transparency](https://www.fdle.state.fl.us/CJAB/CJDT) page.\n\nIn this project, we are specifically working with the Incarceration and Supervision Reports from the Florida Department of Corrections, which form a subset of the larger FDLE CJDT initiative.\n\n**The following context from the first of the two previous links is of critical importance:**\n\n<div style=\"background-color: #f0f0f0; padding: 10px; border-radius: 5px;\">\n\n\"The CJDT data collection process began in 2020 upon establishing state and local system capabilities that allow electronic data transmission from the contributor agencies to FDLE. CJDT records go only as far back as the inception of the initiative in 2018. However, if individual agencies choose to provide older records as part of their submission process, they will be included in the publicly available datasets.\"</div>\n\nIt is **not clear** if the records in the dataset are for those currently in custody or under supervision, or if they include everyone who has been under the jurisdiction of the Florida Department of Corrections since that time.\n\n### Data Updates\n\nWhile the FDLE updates the CJDT data daily, this project operates on a monthly update cycle. The data used in this analysis is manually retrieved and updated on a monthly basis. The project may eventually be updated to establish a live connection to the data source.\n\nThe most recent data download used in this analysis was performed on 2024-07-07.\n\nThis notebook is designed to dynamically update its analysis when new data is provided. To update the data:\n\n1. Download and unzip the latest data file from the FDLE website. This single file contains all three required datasets.\n2. Upload the new file to this notebook's environment.\n3. Update the filepath in the notebook to point to the new file.\n4. Run the notebook to automatically incorporate the new data into the analysis.","metadata":{}},{"cell_type":"code","source":"# Working with files from:\nupdate_path = 'fdle-fl-data-2024-07'\n\n# Picking an AI model\nmodel = \"gpt-4o-mini\"\n\n# Libraries \nimport os\nimport re\nimport sys\nimport json\nimport time\nimport math\nimport folium\nimport altair as alt\nimport datetime\nimport pandas as pd\nimport numpy as np\nimport geopandas as gpd\nimport openai\nimport ipywidgets as widgets\nfrom io import StringIO\nimport io\nfrom contextlib import redirect_stdout\nfrom IPython.display import display, Markdown, HTML\nfrom markdown2 import markdown\nfrom typing import Union, Tuple, Dict, Any\nfrom folium.plugins import MarkerCluster\nfrom kaggle_secrets import UserSecretsClient\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.memory import ConversationBufferWindowMemory\nfrom langchain_core.tools import tool, Tool\nfrom langchain.schema import SystemMessage, HumanMessage, AIMessage\nfrom langgraph.prebuilt import create_react_agent\nimport branca.colormap as cm\n\n\n\n# Datasets\ndf_charges = pd.read_csv('/kaggle/input/' + update_path + '/IncarcerationSupervisionCharge_00000.csv')\ndf_dis = pd.read_csv('/kaggle/input/' + update_path + '/IncarcerationSupervisionDisciplinary_00000.csv')\ndf_root = pd.read_csv('/kaggle/input/' + update_path + '/Incarcerationsupervision_00000.csv')\n\n# Bringing in API Keys\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"OpenAIKey\")\nsecret_value_1 = user_secrets.get_secret(\"tracker API\")\n\n# Connecting to Langsmith for Model Traces\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\nos.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\nos.environ[\"LANGCHAIN_API_KEY\"] = secret_value_1\nos.environ[\"LANGCHAIN_PROJECT\"] = \"fdle-fdoc-data\"\n\n# Function for parsing markdown metadata\ndef extract_rows(markdown_string, column_names):\n    results = []\n    \n    for column_name in column_names:\n        # Pattern to match the entire row\n        pattern = rf\"\\| *{re.escape(column_name)} *\\|.*?(?=\\n\\||\\Z)\"\n        \n        # Search for the pattern in the markdown string\n        match = re.search(pattern, markdown_string, re.DOTALL)\n        \n        if match:\n            # Add the matched row to the results, stripping any leading/trailing whitespace\n            results.append(match.group().strip())\n        else:\n            results.append(f\"Column '{column_name}' not found in the markdown string.\")\n    \n    # Join all results into a single string, separated by newlines\n    return '\\n'.join(results)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:19:31.419496Z","iopub.execute_input":"2024-07-27T16:19:31.419975Z","iopub.status.idle":"2024-07-27T16:19:39.359249Z","shell.execute_reply.started":"2024-07-27T16:19:31.419933Z","shell.execute_reply":"2024-07-27T16:19:39.357639Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Import, Preprocessing, and Data Dictionaries","metadata":{}},{"cell_type":"markdown","source":"## Incarcerationsupervision_00000 Dataset","metadata":{}},{"cell_type":"code","source":"# List of columns to drop from the df_root DataFrame\nroot_to_drop = ['STATE', 'UNIQUE_CORRELATION_ID', 'OWNER_ORI', 'PERSON_ID', 'MDM_PERSON_ID', 'CURRENT_INSTITUTION_ORI_TYP_CODE', 'INCAR_CUSTODY_LEVEL_TYPE_CODE', 'CORRECTION_ADMISSION_REASON_CODE', 'SUPERVISION_CATEGORY_CODE', 'AGENCY_NAME', 'CUSTODY_RELEASE_REASON_CODE']\n# Drop the specified columns\ndf_root = df_root.drop(columns = root_to_drop)\n\n# Convert 'INMATE_AGE' column to unsigned 8-bit integer type\nint_columns = ['INMATE_AGE']\nfor col in df_root[int_columns]:\n        df_root[col] = df_root[col].astype('uint8')        \n\n# Convert specified columns to categorical type\ncategorical_columns = ['RACE_CODE', 'SEX_CODE', 'ETHNICITY_CODE', 'CORRECTION_ADMISSION_REASON_DESC', \n                       'CURRENT_INSTITUTION_ORI_TYPE_DESC', 'CUSTODY_RELEASE_REASON_DESC', 'SUPERVISION_CATEGORY_DESC', 'COUNTY_DESCRIPTION']\nfor col in categorical_columns:\n    df_root[col] = df_root[col].astype('category')\n\n# Convert date columns to datetime type\ndatetime_columns = ['CUSTODY_ADMISSION_DATE', 'SUPERVISION_BEGIN_DATE']\nfor col in datetime_columns:\n    df_root[col] = pd.to_datetime(df_root[col])\n\n# Define the order of education levels\neducation_order = [\n    'Unknown', 'First Grade', 'Second Grade', 'Third Grade', 'Fourth Grade', 'Fifth Grade',\n    'Six Grade', 'Seventh Grade', 'Eighth Grade', 'Ninth Grade', 'Tenth Grade',\n    'Eleventh Grade', 'Twelfth Grade', 'First Year of College', 'Second Year of College',\n    'Third Year of College', 'Fourth Year of College', 'First Year of Grad School',\n    'Second Year of Grad School', 'Third Year of Grad School', 'Fourth or More Years of Grad School'\n    \n]\n\n# Convert 'HIGHEST_EDUCATION_LEVEL' to an ordered categorical type\ndf_root['HIGHEST_EDUCATION_LEVEL'] = pd.Categorical(\n    df_root['HIGHEST_EDUCATION_LEVEL'],\n    categories=education_order,\n    ordered=True\n)\n\n# Define the order of custody levels\ncustody_level_order = ['Community', 'Minimum', 'Medium', 'Close', 'Maximum']\n# Convert 'INCARCERATION_CUSTODY_LEVEL_TYPE_DESC' to an ordered categorical type\ndf_root['INCARCERATION_CUSTODY_LEVEL_TYPE_DESC'] = pd.Categorical(\n    df_root['INCARCERATION_CUSTODY_LEVEL_TYPE_DESC'],\n    categories=custody_level_order,\n    ordered=True\n)\n\n# Define descriptions for each column in df_root\ndescriptions = [\n    \"Anonymized unique identifier\",\n    \"Race of the incarcerated/supervised person\",\n    \"Sex of the incarcerated/supervised person\",\n    \"Ethnicity of the incarcerated/supervised person\",\n    \"Date of admission to custody\",\n    \"Date supervision began (if applicable)\",\n    \"Indicator for prior incarceration\",\n    \"Indicator for participation in incarceration programs\",\n    \"Highest level of education attained\",\n    \"Indicator for sexual offense status\",\n    \"Indicator for gang affiliation\",\n    \"Age of the incarcerated/supervised person\",\n    \"Reason for admission to corrections\",\n    \"Name of Current institution\",\n    \"Reason for release from custody (if applicable)\",\n    \"Custody level type\",\n    \"Category of supervision (if applicable)\",\n    \"County of the institution\"\n]\n\n# Function to generate a Markdown table with DataFrame information\ndef df_info_markdown(df, descriptions=None, display_output=True):\n    # Get basic DataFrame info\n    rows, cols = df.shape\n    memory_usage = df.memory_usage(deep=True).sum()\n    memory_usage_str = f\"{memory_usage / 1024**2:.2f} MB\" if memory_usage > 1024**2 else f\"{memory_usage / 1024:.2f} KB\"\n    \n    # Construct the Markdown content\n    content = f\"\"\"\n## Incarcerationsupervision_00000 Data Information:\n- **Rows**: {rows}\n- **Columns**: {cols}\n- **Memory Usage**: {memory_usage_str}\n### Data Details:\n| Column | Non-Null Count | Python Datatype | Description | Value Distribution |\n|--------|----------------|-------|-------------|---------------------|\n\"\"\"\n    # Columns that require value counts\n    value_count_columns = [\n        \"RACE_CODE\", \"SEX_CODE\", \"ETHNICITY_CODE\", \"PRIOR_INCARCERATION_IND\",\n        \"INCARC_PROG_PARTICIPATION_IND\", \"HIGHEST_EDUCATION_LEVEL\", \"SEXUAL_OFFENDER_IND\",\n        \"GANG_AFFILIATION_IND\", \"CORRECTION_ADMISSION_REASON_DESC\",\n        \"INCARCERATION_CUSTODY_LEVEL_TYPE_DESC\", \"SUPERVISION_CATEGORY_DESC\",\n        \"CUSTODY_RELEASE_REASON_DESC\"\n    ]\n    \n    # Iterate through columns to add their details to the Markdown table\n    for i, col in enumerate(df.columns):\n        dtype = df[col].dtype\n        non_null = df[col].count()\n        description = descriptions[i] if descriptions and i < len(descriptions) else \"\"\n        \n        # Determine value distribution based on column type\n        if col == \"INMATE_AGE\":\n            bins = [0, 18, 25, 35, 45, 55, 65, np.inf]\n            labels = ['<18', '18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n            age_bins = pd.cut(df[col], bins=bins, labels=labels, right=False)\n            value_dist = age_bins.value_counts().sort_index().to_dict()\n            value_dist_str = \", \".join([f\"{k}: {v}\" for k, v in value_dist.items()])\n        elif col in value_count_columns:\n            value_dist = df[col].value_counts().to_dict()\n            value_dist_str = \", \".join([f\"{k}: {v}\" for k, v in value_dist.items()])\n        elif pd.api.types.is_datetime64_any_dtype(df[col]):\n            value_dist_str = f\"Oldest: {df[col].min().strftime('%Y-%m-%d')}, Most recent: {df[col].max().strftime('%Y-%m-%d')}\"\n        else:\n            value_dist_str = f\"{df[col].nunique()} unique values\"\n        \n        content += f\"| {col} | {non_null} non-null | {dtype} | {description} | {value_dist_str} |\\n\"\n    \n    # Display the Markdown if display_output is True\n    if display_output:\n        display(Markdown(content))\n    \n    # Return the Markdown content as a string for AI summarizer\n    return content\n\n# Generate the Markdown content for df_root\ndf_root_content = df_info_markdown(df_root, descriptions)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:19:41.303133Z","iopub.execute_input":"2024-07-27T16:19:41.303712Z","iopub.status.idle":"2024-07-27T16:19:41.660268Z","shell.execute_reply.started":"2024-07-27T16:19:41.303644Z","shell.execute_reply":"2024-07-27T16:19:41.658102Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Code to Generate Visualizations for the IncarcerationSupervision_00000 Dataset","metadata":{}},{"cell_type":"code","source":"# Generating Visualizations\n## Demogrpahics Visual\ndef combine_race_ethnicity(row):\n    race = row['RACE_CODE']\n    ethnicity = row['ETHNICITY_CODE']\n    if ethnicity == 'Hispanic or Latino':\n        return f\"{race} Hispanic or Latino\"\n    elif ethnicity == 'Not Hispanic or Latino':\n        return f\"{race} Non-Hispanic\"\n    else:  \n        return f\"{race} Unknown Ethnicity\"\ndf_root['race_ethnicity'] = df_root.apply(combine_race_ethnicity, axis=1)\n\nage_mapping = {\n    (0, 17): '<18',\n    (18, 24): '18-24',\n    (25, 34): '25-34',\n    (35, 44): '35-44',\n    (45, 54): '45-54',\n    (55, 64): '55-64',\n    (65, float('inf')): '65+'\n}\n\ndf_root['age_group'] = pd.cut(df_root['INMATE_AGE'], \n                                      bins=[0, 17, 24, 34, 44, 54, 64, float('inf')], \n                                      labels=[v for v in age_mapping.values()])\n\naggregated_data = df_root.groupby(['age_group', 'SEX_CODE', 'race_ethnicity'], observed = True).size().reset_index(name='count')\n\n\n# Create the base chart\nbase = alt.Chart(aggregated_data).mark_bar().encode(\n    y=alt.Y('age_group:O', \n            axis=None, \n            sort=['65+', '55-64', '45-54', '35-44', '25-34', '18-24', '<18']),  # Inverted order\n    color=alt.Color('race_ethnicity:N', scale=alt.Scale(scheme='tableau20')),\n    tooltip=['age_group', 'SEX_CODE', 'race_ethnicity', 'sum(count)']\n).properties(\n    width=300,\n    height=300\n)\n\n# Calculate the maximum value for scaling\nmax_value = aggregated_data.groupby('SEX_CODE', observed=True)['count'].sum().max()\n\n# Create the male chart (left side)\nmale_chart = base.transform_filter(\n    alt.datum.SEX_CODE == 'Male'\n).encode(\n    x=alt.X('sum(count):Q', \n            title='Male',\n            scale=alt.Scale(domain=[0, max_value*.4]))\n)\n\n# Create the female chart (right side)\nfemale_chart = base.transform_filter(\n    alt.datum.SEX_CODE == 'Female'\n).encode(\n    x=alt.X('sum(count):Q', \n            title='Female',\n            scale=alt.Scale(domain=[max_value*.4, 0])),  # Reverse the scale\n    y=alt.Y('age_group:O', \n        axis=alt.Axis(title='Age Group'),\n        sort=['65+', '55-64', '45-54', '35-44', '25-34', '18-24', '<18'])\n)\n\n# Combine the charts\npyramid = alt.hconcat(female_chart, male_chart, spacing=0).resolve_scale(\n    x='independent'\n)\n\n# Add chart title and labels\npyramid_chart = pyramid.properties(\n    title='Demographic Age and Race Distribution by Sex'\n).configure_view(\n    stroke=None\n).configure_axis(\n    grid=False\n).configure_title(\n    fontSize=20,\n    font='Courier',\n    anchor='middle',\n    color='gray'\n).configure_legend(\n    orient='bottom',\n    title=None,\n    columns=3\n)\npyramid_chart.save('Demographic_Age_and_Race_Distribution_by_Sex.html')\n\n## Education Visual\neducation_tiers = {\n    'Unknown': 'Unknown',\n    'First Grade': 'Primary School',\n    'Second Grade': 'Primary School',\n    'Third Grade': 'Primary School',\n    'Fourth Grade': 'Primary School',\n    'Fifth Grade': 'Primary School',\n    'Six Grade': 'Primary School',\n    'Seventh Grade': 'Primary School',\n    'Eighth Grade': 'Primary School',\n    'Ninth Grade': 'High School',\n    'Tenth Grade': 'High School',\n    'Eleventh Grade': 'High School',\n    'Twelfth Grade': 'High School',\n    'First Year of College': 'College',\n    'Second Year of College': 'College',\n    'Third Year of College': 'College',\n    'Fourth Year of College': 'College',\n    'First Year of Grad School': 'Grad School',\n    'Second Year of Grad School': 'Grad School',\n    'Third Year of Grad School': 'Grad School',\n    'Fourth or More Years of Grad School': 'Grad School'\n}\ndf_education = df_root[['HIGHEST_EDUCATION_LEVEL']]\ndf_education = df_education['HIGHEST_EDUCATION_LEVEL'].value_counts().sort_index(ascending = False).reset_index(name='count').rename(columns={'index': 'education_level'})\ndf_education['percentage'] = round((df_education['count'] / df_education['count'].sum()) * 100, 2)\ndf_education['cumulative percentage'] = df_education['percentage'].cumsum()\ndf_education['educational_tier'] = df_education['HIGHEST_EDUCATION_LEVEL'].map(education_tiers)\ndf_education = df_education.sort_values('HIGHEST_EDUCATION_LEVEL').reset_index(drop=True)\ndf_education = df_education.iloc[1:].reset_index(drop=True)\neduction_chart = alt.Chart(df_education).mark_bar().encode(\n    x=alt.X('HIGHEST_EDUCATION_LEVEL:N', sort=education_order, axis=alt.Axis(labelAngle=-45)),\n    y=alt.Y('cumulative percentage:Q', axis=alt.Axis()),\n    color=alt.Color('educational_tier:N', scale=alt.Scale(scheme='set3')),\n    tooltip=['HIGHEST_EDUCATION_LEVEL', 'educational_tier', 'count', 'percentage', 'cumulative percentage']\n).properties(\n    width=600,\n    height=400,\n    title='Higest Grade Completed by Cumulative Percentage and Educational Tier'\n)\neduction_chart.save('Higest_Grade_Completed_by_Cumulative_Percentage_and_Educational_Tier.html')\n\n# Dates Charts (full data for display, filtered data for model review)\n##full data\ndf_custody = df_root[['CUSTODY_ADMISSION_DATE']].copy()\ndf_supervision = df_root[['SUPERVISION_BEGIN_DATE']].copy()\n\ndf_custody['CUSTODY_ADMISSION_DATE'] = df_custody['CUSTODY_ADMISSION_DATE'].dt.to_period('M')\ndf_supervision['SUPERVISION_BEGIN_DATE'] = df_supervision['SUPERVISION_BEGIN_DATE'].dt.to_period('M')\n\n# Count occurrences by month\ncount_by_month_custody = df_custody['CUSTODY_ADMISSION_DATE'].value_counts().sort_index().reset_index()\ncount_by_month_supervision = df_supervision['SUPERVISION_BEGIN_DATE'].value_counts().sort_index().reset_index()\n\n# Rename columns\ncount_by_month_custody.columns = ['Date', 'Count']\ncount_by_month_supervision.columns = ['Date', 'Count']\n\n# Add a type column to distinguish between the two series\ncount_by_month_custody['Type'] = 'Custody Admission'\ncount_by_month_supervision['Type'] = 'Supervision Begin'\n\n# Combine the two dataframes\ndf_combined = pd.concat([count_by_month_custody, count_by_month_supervision])\n\n# Convert Period to datetime for Altair\ndf_combined['Date'] = df_combined['Date'].dt.to_timestamp()\nmax_date = df_combined['Date'].max()\n# Create the Altair plot with initial view set using scale\ncustody_supervision_vs_time = alt.Chart(df_combined).mark_line().encode(\n    x=alt.X('Date:T', title='Month', \n            scale=alt.Scale(domain=(pd.Timestamp('2021-01-01'), max_date))),\n    y=alt.Y('Count:Q', title='Count', \n            scale=alt.Scale(domain=(1, 2800))),\n    color=alt.Color('Type:N', \n                    legend=alt.Legend(\n                        title=\"Event Type\",\n                        orient=\"top-left\",  \n                        fillColor=\"white\",  \n                        strokeColor=\"gray\",  \n                        padding=10,  \n                        cornerRadius=5 \n                    )),\n    tooltip=['Type', 'Count', alt.Tooltip('Date:T', title='Date')]\n).properties(\n    width=800,\n    height=400,\n    title='Counts of Custody Admissions and Supervison Starts, 2021 to Present'\n).interactive()\n\n# Configure the view\nview = custody_supervision_vs_time.configure_view(\n    continuousWidth=800,\n    continuousHeight=400,\n    stroke=None\n)\n\nview.save('Counts_of_Custody_Admissions_And_Supervison_Starts,_2021_To_Present.html')\n\n## Filtered data for passing to ai as .to_json()\ncurrent_year = datetime.datetime.now().year\n\n# List of the last 3 years\nlast_3_years = [current_year - i for i in range(1, 4)]\n\n# Filter the DataFrame\nfiltered_df = df_root[\n    (df_root['CUSTODY_ADMISSION_DATE'].dt.year.isin(last_3_years) | df_root['CUSTODY_ADMISSION_DATE'].isnull()) &\n    (df_root['SUPERVISION_BEGIN_DATE'].dt.year.isin(last_3_years) | df_root['SUPERVISION_BEGIN_DATE'].isnull())\n]\n\nfiltered_df = df_root[\n    (df_root['CUSTODY_ADMISSION_DATE'].dt.year.isin(last_3_years) | df_root['CUSTODY_ADMISSION_DATE'].isnull()) &\n    (df_root['SUPERVISION_BEGIN_DATE'].dt.year.isin(last_3_years) | df_root['SUPERVISION_BEGIN_DATE'].isnull())\n]\n\ndf_custody2 = filtered_df[['CUSTODY_ADMISSION_DATE']].copy()\ndf_supervision2 = filtered_df[['SUPERVISION_BEGIN_DATE']].copy()\n\ndf_custody2['CUSTODY_ADMISSION_DATE'] = df_custody2['CUSTODY_ADMISSION_DATE'].dt.to_period('M')\ndf_supervision2['SUPERVISION_BEGIN_DATE'] = df_supervision2['SUPERVISION_BEGIN_DATE'].dt.to_period('M')\n\n# Count occurrences by month\ncount_by_month_custody2 = df_custody2['CUSTODY_ADMISSION_DATE'].value_counts().sort_index().reset_index()\ncount_by_month_supervision2 = df_supervision2['SUPERVISION_BEGIN_DATE'].value_counts().sort_index().reset_index()\n\n# Rename columns\ncount_by_month_custody2.columns = ['Date', 'Count']\ncount_by_month_supervision2.columns = ['Date', 'Count']\n\n# Add a type column to distinguish between the two series\ncount_by_month_custody2['Type'] = 'Custody Admission'\ncount_by_month_supervision2['Type'] = 'Supervision Begin'\n\n# Combine the two dataframes\ndf_combined = pd.concat([count_by_month_custody2, count_by_month_supervision2])\n\n# Convert Period to datetime for Altair\ndf_combined['Date'] = df_combined['Date'].dt.to_timestamp()\nmax_date = df_combined['Date'].max()\n# Create the Altair plot with initial view set using scale\ncustody_supervision_vs_time_ai = alt.Chart(df_combined).mark_line().encode(\n    x=alt.X('Date:T', title='Month', \n            scale=alt.Scale(domain=(pd.Timestamp('2021-01-01'), max_date))),\n    y=alt.Y('Count:Q', title='Count', \n            scale=alt.Scale(domain=(1, 2800))),\n    color=alt.Color('Type:N', \n                    legend=alt.Legend(\n                        title=\"Event Type\",\n                        orient=\"top-left\",  \n                        fillColor=\"white\",  \n                        strokeColor=\"gray\",  \n                        padding=10,  \n                        cornerRadius=5 \n                    )),\n    tooltip=['Type', 'Count', alt.Tooltip('Date:T', title='Date')]\n).properties(\n    width=800,\n    height=400,\n    title='Counts of Custody Admissions and Supervison Starts, 2021 to Present'\n).interactive()\n\n# Configure the view\nview2 = custody_supervision_vs_time_ai.configure_view(\n    continuousWidth=800,\n    continuousHeight=400,\n    stroke=None\n)\n\n\nbool_columns = ['PRIOR_INCARCERATION_IND', 'INCARC_PROG_PARTICIPATION_IND', \n                'SEXUAL_OFFENDER_IND', 'GANG_AFFILIATION_IND']\n\n# Function to create a pie chart for a single column\ndef create_pie_chart(column):\n    chart_data = df_root[column].value_counts().reset_index()\n    chart_data.columns = ['value', 'count']\n    chart_data['percentage'] = chart_data['count'] / chart_data['count'].sum() * 100\n    \n    base = alt.Chart(chart_data).encode(\n        theta='count:Q',\n        color='value:N',\n        tooltip=['value:N', 'count:Q', alt.Tooltip('percentage:Q', format='.1f')]\n    )\n\n    pie = base.mark_arc()\n    return (pie).properties(\n        title=column,\n        width=250,\n        height=250\n    )\n\n# Create pie charts for each boolean column\ncharts = [create_pie_chart(col) for col in bool_columns]\n\n# Combine the charts into a 2x2 grid\ncombined_pie_chart = alt.vconcat(\n    alt.hconcat(charts[0], charts[1]),\n    alt.hconcat(charts[2], charts[3])\n)\n# Display the chart\ncombined_pie_chart.save('Combined_Pie_Carts_For_bools.html')\n\ncbf_palette = [\n    '#1170aa', '#fc7d0b', '#a3acb9', '#57606c', '#5fa2ce', \n    '#c85200', '#7b848f', '#e15759', '#76b7b2', '#59a14f',\n    '#edc948'\n]\n\n# Function to create a pie chart for a single column\ndef create_pie_chart(df, column):\n    # Calculate value counts and percentages\n    chart_data = df[column].value_counts().reset_index()\n    chart_data.columns = ['category', 'count']\n    chart_data['percentage'] = chart_data['count'] / chart_data['count'].sum() * 100\n    \n    # Calculate the cumulative percentages and midpoints for label positioning\n    chart_data['cumulative'] = chart_data['percentage'].cumsum() - chart_data['percentage'] / 2\n    chart_data['angle'] = chart_data['cumulative'] * 2 * np.pi / 100\n    chart_data['x'] = np.cos(chart_data['angle']) * 0.5 + 0.5\n    chart_data['y'] = np.sin(chart_data['angle']) * 0.5 + 0.5\n\n    # Create the base chart\n    base = alt.Chart(chart_data).encode(\n        theta=alt.Theta('count:Q', stack=True),\n        color=alt.Color('category:N', scale=alt.Scale(range=cbf_palette)),\n        tooltip=['category:N', 'count:Q', alt.Tooltip('percentage:Q', format='.1f')]\n    )\n\n    # Create the pie chart\n    pie = base.mark_arc(outerRadius=120)\n    \n    # Combine pie and text\n    return (pie).properties(\n        title=column,\n        width=300,\n        height=300\n    )\n\n# Create pie charts for both columns\nadmission_chart = create_pie_chart(df_root, 'CORRECTION_ADMISSION_REASON_DESC')\nrelease_chart = create_pie_chart(df_root, 'CUSTODY_RELEASE_REASON_DESC')\n\n# Combine the charts side by side\nreasons_chart = alt.hconcat(admission_chart, release_chart).properties(\n    title='Correction Admission Reasons vs Custody Release Reasons'\n)\nreasons_chart.save('Correction_Admission_Reasons_Vs_Custody_Release_Reasons.html')\n\n# Function to create a pie chart for a single column\ndef create_pie_chart(df, column):\n    # Calculate value counts and percentages\n    chart_data = df[column].value_counts().reset_index()\n    chart_data.columns = ['category', 'count']\n    chart_data['percentage'] = chart_data['count'] / chart_data['count'].sum() * 100\n    \n    # Calculate the cumulative percentages and midpoints for label positioning\n    chart_data['cumulative'] = chart_data['percentage'].cumsum() - chart_data['percentage'] / 2\n    chart_data['angle'] = chart_data['cumulative'] * 2 * np.pi / 100\n    chart_data['x'] = np.cos(chart_data['angle']) * 0.5 + 0.5\n    chart_data['y'] = np.sin(chart_data['angle']) * 0.5 + 0.5\n\n    # Create the base chart\n    base = alt.Chart(chart_data).encode(\n        theta=alt.Theta('count:Q', stack=True),\n        color=alt.Color('category:N', scale=alt.Scale(range=cbf_palette)),\n        tooltip=['category:N', 'count:Q', alt.Tooltip('percentage:Q', format='.1f')]\n    )\n\n    # Create the pie chart\n    pie = base.mark_arc(outerRadius=120)\n    \n    # Combine pie and text\n    return (pie).properties(\n        title=column,\n        width=300,\n        height=300\n    )\n\n# Create pie charts for both columns\ncustody_chart = create_pie_chart(df_root, 'INCARCERATION_CUSTODY_LEVEL_TYPE_DESC')\nsup_cat_chart = create_pie_chart(df_root, 'SUPERVISION_CATEGORY_DESC')\n\n# Combine the charts side by side\ncats_chart = alt.hconcat(custody_chart, sup_cat_chart).properties(\n    title='Incarceration Custody Level vs Supervision Categories'\n)\ncats_chart.save('Incarceration_Custody_Level_Vs_Supervision_Categories.html')\n\nvalue_counts = df_root['CURRENT_INSTITUTION_ORI_TYPE_DESC'].value_counts()\n\n# Convert to DataFrame for Altair\ndf_counts = value_counts.reset_index()\ndf_counts.columns = ['category', 'count']\n\n# Sort by count descending\ndf_counts = df_counts.sort_values('count', ascending=False)\n\n# Create the stacked bar chart\nchart = alt.Chart(df_counts).mark_bar().encode(\n    y=alt.Y('category:N', \n            sort='-x', \n            title='Institution Type',\n            axis=alt.Axis(labelLimit=250, labelFontSize=8)),  # Increase label limit and decrease font size\n    x=alt.X('count:Q', title='Count'),\n    color=alt.Color('category:N', legend=None),\n    tooltip=['category', 'count']\n).properties(\n    title='Institutions by Count',\n    width=900,\n    height=2000  # Increase height significantly\n)\n\n# Add text labels\ntext = chart.mark_text(\n    align='left',\n    baseline='middle',\n    dx=3,\n    fontSize=8  # Decrease font size for labels\n).encode(\n    text='count:Q'\n)\n\n# Combine chart and text\ninstitutions_chart = (chart + text).configure_axis(\n    labelFontSize=8,\n    titleFontSize=12\n).configure_title(\n    fontSize=14\n)\n\ninstitutions_chart.save('Institutions_by_Count.html')","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:19:47.068344Z","iopub.execute_input":"2024-07-27T16:19:47.068827Z","iopub.status.idle":"2024-07-27T16:19:50.457408Z","shell.execute_reply.started":"2024-07-27T16:19:47.068784Z","shell.execute_reply":"2024-07-27T16:19:50.456182Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AI Presentation of IncarcerationSupervison_00000 Dataset and Visualizations","metadata":{}},{"cell_type":"code","source":"# Generating first AI Presentation\nsystem = \"\"\"You are a member of a data presentation team.\nThe data you will present is a subset of metadata from a Florida Department of Law Enforcement file containing Florida Department of Corrections incarceration and supervision data. The main audience includes the public, researchers, and policymakers. This data has been downloaded in CSV format, cleaned, and used to create several visualizations. The purpose of the presentation is to make the information more accessible to the public.\n\nKey principles include objectivity, transparency, acknowledgment of data limitations, and accessibility. \n\nYou will also have a secondary audience: a data scientist with access to the loaded data. During your presentation, highlight critical information for the data scientist so they become familiar with the dataset variable names and data structures. Clearly identify dataset variables and specify categorical variable values precisely, maintaining case. This does not apply to calculated visualization variables like ‘count’ since they are not a concern for the data scientist who will be working with the dataset later.\n\nWhen you receive data in JSON, Markdown, and text format:\n- The JSON data represents Altair visualizations.\n- The text includes:\n    - The subject of the metadata subset\n    - Additional context\n    - One html file paths, which correspond to the Altair plot visualization file paths.\n    \nYou will:\n\n1. Use markdown formatting to enhance readability:\n    - Use the header ## to return the subject of the data, i.e., ## Demographics:\n    - Use the lower-level headers ### for subsections of your response.\n    \n2. For the html file path include a centered iframe tag in your markdown output to display the associated html file. Use the following format:\n\n<div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n\n<iframe src=\"html_file_name.html\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n\n</div>\n\nUse iframe only for the tag. Do not use img and do not use markdown tagging.\n \n3. Present all numerical data in context.\n4. Explain all visualizations, including potential insights.\n5. Do not conclude with a summary or conclusion.\n6. Unless instructed to be succinct, aim for lengthy and very detailed responses.\n7. Only include one iframe tag in each response.\n8. Do not refer to incarcerated or supervised persons as 'inmates'\n or 'offenders'. They are 'incarcerated' or 'supervised' persons.\n9. Address all unexpected data results and potential data quality concerns.\n\"\"\"\nprompt_template = ChatPromptTemplate.from_messages([\n    ('system', system),\n    ('human', \"{data_str}\")\n])\nllm_1 = ChatOpenAI(openai_api_key=secret_value_0, temperature = 0.0, model = model) \nllm_chain_1 = prompt_template | llm_1\n\ndemographic_columns = [\"INCARCERATION_SUPERVISION_ID\", \"RACE_CODE\",\"SEX_CODE\", \"ETHNICITY_CODE\", \"INMATE_AGE\"]\ndemographic_rows = extract_rows(df_root_content, demographic_columns)\neducation_columns = [\"HIGHEST_EDUCATION_LEVEL\"]\neducation_rows = extract_rows(df_root_content, education_columns)\ndates_columns = ['CUSTODY_ADMISSION_DATE', 'SUPERVISION_BEGIN_DATE']\ndates_rows = extract_rows(df_root_content, dates_columns)\nreasons_columns = ['CORRECTION_ADMISSION_REASON_DESC', 'CUSTODY_RELEASE_REASON_DESC']\nreasons_rows = extract_rows(df_root_content, reasons_columns)\ntags_columns = ['PRIOR_INCARCERATION_IND', 'INCARC_PROG_PARTICIPATION_IND', 'SEXUAL_OFFENDER_IND', 'GANG_AFFILIATION_IND']\ntags_rows = extract_rows(df_root_content, tags_columns)\ninstitutional_columns = ['INCARCERATION_CUSTODY_LEVEL_TYPE_DESC', 'SUPERVISION_CATEGORY_DESC']\ninstitutional_rows = extract_rows(df_root_content, institutional_columns)\nlocation_columns = ['CURRENT_INSTITUTION_ORI_TYPE_DESC', 'COUNTY_DESCRIPTION']\nlocation_rows = extract_rows(df_root_content, location_columns)\n\ndemographic_context = demographic_rows\neducation_context = education_rows\ndates_context = \"\"\"Context: The Criminal Justice Data Transparency data collection process began in 2020 upon establishing state and local system capabilities that allow electronic data transmission from the contributor agencies to FDLE. CJDT records go only as far back as the inception of the initiative in 2018. However, if individual agencies choose to provide older records as part of their submission process, they will be included in the publicly available datasets.\" It is not clear if the records in the dataset are for those currently in custody or under supervision, or if they include everyone who has been under the jurisdiction of the Florida Department of Corrections since that time. The author posits that any observed 'increase' in recent data is likely an indication that the the former is the case, that only those who are currently or have recently been incarcerated or under supervision are included - that the removal of older records can create the false impression that there is a current rise in the recent number of records. <<Contect for AI only: The json data you are being passed is filtered to the last three years. This is different from the user-visible visualization, which is pannable back to earlier dates.>>\"\"\" + dates_rows\nreasons_context = reasons_rows\ntags_context = tags_rows\ninstitutional_context = institutional_rows\nlocation_context = location_rows + 'Critical Additional Context (please include in your response!): As of 2024-07-17, Wikipedia lists the capactiy of Central Florida Reception Center at 3066 persons, The Florida Department of Corrections lists the capacity of the Reception and Medical Center at 1,503 persons, Wikipedia lists the capactiy of South Florida Reception Center at 1,315 persons. The reason/reasons for the disparity between reality and the data are so far unknown.(please include this information in your response!)'\n\n# Getting AI Responses\ndemographic_response = llm_chain_1.invoke(\n    {'data_str': \"Subject : Demographics  html filepath : 'Demographic_Age_and_Race_Distribution_by_Sex.html' \" + demographic_context + pyramid_chart.to_json()  + \"Important Instruction: Include only one iframe tag in this response.\"})\neducation_response = llm_chain_1.invoke(\n    {'data_str': 'Subject : Education ' + education_context + eduction_chart.to_json()  + \"html filepath: 'Higest_Grade_Completed_by_Cumulative_Percentage_and_Educational_Tier' \" + 'Context: The visual represents a transformation of the underlying data. The raw data simply records the highest completed grade for each individual.'})\ndates_response = llm_chain_1.invoke(\n    {'data_str': 'Subject : Dates' + dates_context + view2.to_json()  + \"File path: 'Counts_of_Custody_Admissions_And_Supervison_Starts,_2021_To_Present.html' \"})\nreasons_response = llm_chain_1.invoke(\n    {'data_str': \"Subject : Reasons', File path: 'Correction_Admission_Reasons_Vs_Custody_Release_Reasons.html'\" + reasons_context + reasons_chart.to_json() + ' Important Instruction: Only include one iframe tag in this response.'})\ntags_response = llm_chain_1.invoke({'data_str':  \"Subject : Indicators File path: 'Combined_Pie_Carts_For_bools.html'\" + tags_context + combined_pie_chart.to_json() + ' Important Instruction: Only include one iframe tag in this response.'})\ninstitutional_response = llm_chain_1.invoke({'data_str': \"Subject : Institutional Information File path: 'Incarceration_Custody_Level_Vs_Supervision_Categories.html'\" + institutional_context + cats_chart.to_json() +' Important Instruction: Only include one iframe tag in this response.'})\nlocation_response = llm_chain_1.invoke({'data_str': \"Subject : Locations File path: 'Institutions_by_Count.html'\" + location_context + institutions_chart.to_json()})\n\ndisplay(Markdown('<span style=\"color: red;\"> \\n\\n# AI Generated Presentation of `IncarcerationSupervision_00000` and Visualizations\\n' + demographic_response.content + '\\n\\n' + education_response.content + '\\n\\n' + dates_response.content + '\\n\\n' + reasons_response.content + '\\n\\n' + tags_response.content + '\\n\\n' + institutional_response.content + '\\n\\n' + location_response.content + ' \\n </span>'))","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:22:11.214623Z","iopub.execute_input":"2024-07-27T16:22:11.215137Z","iopub.status.idle":"2024-07-27T16:23:07.022308Z","shell.execute_reply.started":"2024-07-27T16:22:11.215098Z","shell.execute_reply":"2024-07-27T16:23:07.021151Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IncarcerationSupervisionCharge_00000 Dataset","metadata":{}},{"cell_type":"code","source":"# Dropping redundant columns from the charges dataset\ncharges_to_drop = ['FCIC_CODE', 'SUP_ASSIGNED_MAXIMUM_TERM_CODE', 'MAXIMUM_TERM_CODE', 'STATUTE_CHAPTER_CODE', 'STATUTE_SECTION', 'STATUTE_SUBSECTION', 'SUPERVISION_REVOCATION_REASON', 'SENTENCE_STATUS_CODE', 'MINIMUM_TERM_DURATION_DAYS', 'SENTENCE_PROBATION_DURATION_DAYS']\ndf_charges = df_charges.drop(columns = charges_to_drop)\n\n# Defining a mapping dictionary for county codes to county names\ncounty_code_mapper = {6.0: 'BROWARD', 58.0: 'SARASOTA', 41.0: 'MANATEE', 4.0: 'BRADFORD', 51.0: 'PASCO', 32.0: 'JACKSON', 3.0: 'BAY', 30.0: 'HOLMES', 29.0: 'HILLSBOROUGH', 11.0: 'COLLIER', 49.0: 'OSCEOLA', 17.0: 'ESCAMBIA', 50.0: 'PALM BEACH', 12.0: 'COLUMBIA', 13.0: 'MIAMI-DADE', 5.0: 'BREVARD', 52.0: 'PINELLAS', 1.0: 'ALACHUA', 53.0: 'POLK', 47.0: 'OKEECHOBEE', 36.0: 'LEE', 48.0: 'ORANGE', 16.0: 'DUVAL', 64.0: 'VOLUSIA', 59.0: 'SEMINOLE', 54.0: 'PUTNAM', 8.0: 'CHARLOTTE', 55.0: 'ST. JOHNS', 38.0: 'LEVY', 56.0: 'ST. LUCIE', 14.0: 'DESOTO', 23.0: 'GULF', 40.0: 'MADISON', 43.0: 'MARTIN', 63.0: 'UNION', 31.0: 'INDIAN RIVER', 21.0: 'GILCHRIST', 18.0: 'FLAGLER', 61.0: 'SUWANNEE', 20.0: 'GADSDEN', 44.0: 'MONROE', 65.0: 'WAKULLA', 57.0: 'SANTA ROSA', 66.0: 'WALTON', 45.0: 'NASSAU', 2.0: 'BAKER', 62.0: 'TAYLOR', 24.0: 'HAMILTON', 46.0: 'OKALOOSA', 67.0: 'WASHINGTON', 39.0: 'LIBERTY', 7.0: 'CALHOUN', 26.0: 'HENDRY', 15.0: 'DIXIE', 25.0: 'HARDEE', 19.0: 'FRANKLIN', 60.0: 'SUMTER', 22.0: 'GLADES', 34.0: 'LAFAYETTE', 42.0: 'MARION', 37.0: 'LEON', 28.0: 'HIGHLANDS', 10.0: 'CLAY', 33.0: 'JEFFERSON'}\n\n# Function to apply mapping and drop original column\ndef apply_mapping_and_drop(df, old_col, new_col, mapping_dict):\n    df[new_col] = [mapping_dict.get(val, None) for val in df[old_col]]\n    df.drop(columns=[old_col], inplace=True)\n    return df            \n\n# Apply county mapping and drop original column\ndf_charges = apply_mapping_and_drop(df_charges, 'CONVICTION_COUNTY', 'County_of_Conviction', county_code_mapper)\n\n# Combine 'CHARGE_DEGREE' and 'CHARGE_LEVEL' into a new 'Degree_Level' column\ndf_charges['Degree_Level'] = df_charges['CHARGE_DEGREE'] + ' ' + df_charges['CHARGE_LEVEL']\ndf_charges['Degree_Level'] = df_charges['Degree_Level'].replace({'Not Applicable Misdemeanor': 'Misdemeanor', 'Not Applicable Not Applicable': 'Not Applicable'})\ndf_charges = df_charges.drop(columns = ['CHARGE_DEGREE', 'CHARGE_LEVEL'])\n\n# Convert specified columns to categorical type for memory efficiency\ncategorical_columns = ['STATUTE', 'DRUG_TYPE_DESC', 'OFFENSE_FCIC_TYPE_DESC', 'SENTENCE_STATUS', 'County_of_Conviction']\nfor col in categorical_columns:\n    df_charges[col] = df_charges[col].astype('category')\n\n# Define the order of degree levels and convert 'Degree_Level' to an ordered categorical type\ndegree_Level_order = ['Not Applicable', 'Misdemeanor', 'Third Degree Felony', 'Second Degree Felony', 'First Degree Felony']\ndf_charges['Degree_Level'] = pd.Categorical(\n    df_charges['Degree_Level'],\n    categories=degree_Level_order,\n    ordered=True\n)\n\n# Define descriptions for each column in df_charges\ndescriptions_charges = [\n    \"Anonymized unique identifier\",\n    \"Days served for concurrent sentences\",\n    \"Days served for consecutive sentences\",\n    \"Total days served for the sentence\",\n    \"Assigned duration of supervision term in days\",\n    \"Amount of time earned for good behavior\",\n    \"Legal statute related to the charge\",\n    \"Maximum sentence duration in days\",\n    \"Indicator for habitual offender status\",\n    \"Indicator for habitual violent felony offender\",\n    \"Indicator for prison releasee reoffender\",\n    \"Indicator for violent career criminal\",\n    \"Days served under supervision\",\n    \"Description of drug type involved (if applicable)\",\n    \"Description of offense type\",\n    \"Status of the sentence\",\n    \"County where the conviction occurred\",\n    \"Degree and level of the charge (e.g., First Degree Felony)\"\n]\n\n# Function to generate a Markdown table with DataFrame information for df_charges\ndef df_charges_info_markdown(df, descriptions=None, display_output=True):\n    # Get basic DataFrame info\n    rows, cols = df.shape\n    memory_usage = df.memory_usage(deep=True).sum()\n    memory_usage_str = f\"{memory_usage / 1024**2:.2f} MB\" if memory_usage > 1024**2 else f\"{memory_usage / 1024:.2f} KB\"\n    \n    # Construct the Markdown content\n    content = f\"\"\"\n## IncarcerationSupervisionCharge_00000 Data Information:\n- **Rows**: {rows}\n- **Columns**: {cols}\n- **Memory Usage**: {memory_usage_str}\n### Data Details:\n| Column | Non-Null Count | Dtype | Description | Value Distribution |\n|--------|----------------|-------|-------------|---------------------|\n\"\"\"\n    # Columns that require min, max, median\n    numeric_columns = [\n        \"CONCURRENT_SENTENCES_SERVED_DAYS\", \"CONSECUTIVE_SENTENCES_SERVED_DAYS\",\n        \"SENTENCE_SERVED_DAYS\", \"SUP_ASSIGNED_TERM_DURATION_DAYS\", \"GAIN_TIME_EARNED\", \"MAXIMUM_TERM_DURATION_DAYS\", \"SUPERVISION_SERVED_DAYS\"\n    ]\n    \n    # Columns that require value counts\n    value_count_columns = [\n        \"DRUG_TYPE_DESC\", \"OFFENSE_FCIC_TYPE_DESC\", \"SENTENCE_STATUS\", \"Degree_Level\",\n        \"HABITUAL_OFNDR_IND\", \"HABITUAL_VIOL_FELONY_OFNDR_IND\", \n        \"PRISON_RELEASEE_REOFNDR_IND\", \"VIOLENT_CAREER_CRIM_IND\"\n    ]\n    \n    # Iterate through columns to add their details to the Markdown table\n    for i, col in enumerate(df.columns):\n        dtype = df[col].dtype\n        non_null = df[col].count()\n        description = descriptions[i] if descriptions and i < len(descriptions) else \"\"\n        \n        # Determine value distribution based on column type\n        if col in numeric_columns:\n            min_val = df[col].min()\n            max_val = df[col].max()\n            median_val = df[col].median()\n            value_dist_str = f\"Min: {min_val:.2f}, Max: {max_val:.2f}, Median: {median_val:.2f}\"\n        elif col in value_count_columns or pd.api.types.is_bool_dtype(df[col]):\n            value_dist = df[col].value_counts().to_dict()\n            value_dist_str = \", \".join([f\"{k}: {v}\" for k, v in value_dist.items()])\n        else:\n            value_dist_str = f\"{df[col].nunique()} unique values\"\n        \n        content += f\"| {col} | {non_null} non-null | {dtype} | {description} | {value_dist_str} |\\n\"\n    \n    # Display the Markdown if display_output is True\n    if display_output:\n        display(Markdown(content))\n    \n    # Return the Markdown content as a string\n    return content\n\n# Generate the Markdown content for df_charges\ndf_charges_content = df_charges_info_markdown(df_charges, descriptions_charges)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:23:36.584355Z","iopub.execute_input":"2024-07-27T16:23:36.585755Z","iopub.status.idle":"2024-07-27T16:23:36.644678Z","shell.execute_reply.started":"2024-07-27T16:23:36.585710Z","shell.execute_reply":"2024-07-27T16:23:36.643554Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Code to Generate Visualizations for the IncarcerationSupervisionCharge_00000 Dataset","metadata":{}},{"cell_type":"code","source":"# Size Comparison/Overlap Plot\n### Determine the sizes\nsize_large = len(df_root)\nsize_small = len(df_charges['INCARCERATION_SUPERVISION_ID'].unique())\n\n# Dataset names for passing\nlarge_dataset_name = \"IncarcerationSupervision_00000\"\nsmall_dataset_name = \"IncarcerationSupervisionCharge_00000\"\n\n# Find the overlap\nkey_column = 'INCARCERATION_SUPERVISION_ID'\noverlap = df_charges[df_charges[key_column].isin(df_root[key_column])].shape[0]\n\nradius_small = 1\nradius_large = math.sqrt(size_large / size_small)\n\n# Calculate the distance between circle centers based on overlap\noverlap_ratio = overlap / size_small\ndistance = radius_large + radius_small - (overlap_ratio * 2 * radius_small)\n\n# Adjust this factor to bring circles closer together or further apart\ndistance_factor = 0.5  # Experiment with this value\n\n# Create a dataframe for our visualization\nviz_data = pd.DataFrame({\n    'x': [distance * distance_factor, 0],\n    'y': [0, 0],\n    'size': [size_large, size_small],\n    'radius': [radius_large, radius_small],\n    'dataset': [large_dataset_name, small_dataset_name],\n    'overlap': [overlap, overlap]\n})\n\n# Calculate the domain for x and y axes\nmax_radius = max(radius_large, radius_small)\nx_domain = [-max_radius, (distance * distance_factor) + max_radius]\ny_domain = [-max_radius, max_radius]\n\n# Create the base chart\nbase = alt.Chart(viz_data).encode(\n    x=alt.X('x:Q', scale=alt.Scale(domain=x_domain), axis=None),\n    y=alt.Y('y:Q', scale=alt.Scale(domain=y_domain), axis=None)\n)\n\n# Create circles representing dataset sizes\ncircles = base.mark_circle(opacity=0.5).encode(\n    size=alt.Size('radius:Q', scale=alt.Scale(range=[0, 40000]), legend=None),\n    color=alt.Color('dataset:N', \n                    scale=alt.Scale(domain=[large_dataset_name, small_dataset_name], \n                                    range=['blue', 'red']),\n                    legend=alt.Legend(title=\"Datasets\", labelLimit=0)),\n    tooltip=['dataset', 'size', 'overlap']\n)\n\n# Combine all elements\nsize_comparison_chart = circles.properties(\n    width=600,\n    height=400,\n    title=f\"Dataset Size Comparison (Overlap: {overlap} persons)\"\n).configure_view(\n    strokeWidth=0\n).configure_legend(\n    labelLimit=0,  # Ensures full names are shown in legend\n    orient='bottom',  # Positions legend at the bottom\n    columns=1,  # Stacks legend entries vertically\n    titleFontSize=14,\n    labelFontSize=12\n)\nsize_comparison_chart.save('Dataset_Size_Comparison.html')\n\n# Sentencing Metrics Explorer: 7 Variables at a Glance development\n\"\"\"This interactive visualization presents seven histograms, each representing a different variable related to sentencing and supervision. For each variable:\nThe top chart shows the full distribution of all data. You can click and drag on any top chart to select a specific range of days you're interested in. When you do this, the bottom chart for that variable will update to show only the data within your selected range, automatically adjusting its scale to fit this subset of data. This feature lets you zoom in on particular parts of the distribution for each variable, making it easier to examine patterns or details that might be hard to see in the full dataset. You can adjust your selection at any time to explore different ranges, or click outside the selection to reset and view the full distribution again. Each variable can be explored independently, allowing for comparison across all seven measures simultaneously.\"\"\"\n\nvariables = [\n    'CONCURRENT_SENTENCES_SERVED_DAYS',\n    'CONSECUTIVE_SENTENCES_SERVED_DAYS',\n    'SENTENCE_SERVED_DAYS',\n    'SUP_ASSIGNED_TERM_DURATION_DAYS',\n    'GAIN_TIME_EARNED',\n    'MAXIMUM_TERM_DURATION_DAYS',\n    'SUPERVISION_SERVED_DAYS'\n]\n# Function to create a single histogram\ndef create_histogram(variable):\n    selection = alt.selection_interval(encodings=['x'])\n    \n    base = alt.Chart(df_charges).mark_bar().encode(\n        alt.X(variable, bin=alt.Bin(maxbins=20), title=''),\n        alt.Y('count()', title=''),\n        tooltip=[variable, 'count()']\n    ).properties(\n        width=100,\n        height=100\n    )\n    \n    upper = base.encode(\n        opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n    ).add_params(selection).properties(\n        title=alt.TitleParams(text=variable, anchor='middle', fontSize=8)\n    )\n    \n    lower = base.transform_filter(selection)\n    \n    return (upper & lower).resolve_scale(y='independent')\n\n# Create all histograms\nhistograms = [create_histogram(var) for var in variables]\n\n# Combine all histograms into a single chart\nsept_chart = alt.hconcat(*histograms).resolve_scale(\n    x='independent',\n    y='independent'\n).configure_axis(\n    labelFontSize=6,\n    titleFontSize=8\n).configure_title(\n    fontSize=10\n)\n\n# save the chart\nsept_chart.save('Sentencing_Metrics_Explorer:_7_Variables_at_a_Glance.html')\n\n# Pie charts for df_charges indicators\ncolumns = ['HABITUAL_OFNDR_IND', 'HABITUAL_VIOL_FELONY_OFNDR_IND', \n           'PRISON_RELEASEE_REOFNDR_IND', 'VIOLENT_CAREER_CRIM_IND']\n\n# Function to create a pie chart for a single column\ndef create_pie_chart(df, column):\n    count_data = df[column].value_counts().reset_index()\n    count_data.columns = ['value', 'count']\n    \n    pie = alt.Chart(count_data).mark_arc().encode(\n        theta='count:Q',\n        color='value:N',\n        tooltip=['value:N', 'count:Q']\n    ).properties(\n        title=column,\n        width=200,\n        height=200\n    )\n    \n    return pie\n\n# Create pie charts for all columns\ncharts = [create_pie_chart(df_charges, col) for col in columns]\n\n# Combine all charts into a single figure\nindicators_chart = alt.vconcat(\n    alt.hconcat(charts[0], charts[1]),\n    alt.hconcat(charts[2], charts[3])\n)\n\n# Saving the chart\nindicators_chart.save('Charges_Indicators.html')\n\n#Creating Pie chart for Drug type Descriptions\ndef create_drug_type_pie_chart(df, column='DRUG_TYPE_DESC'):\n    # Calculate the counts and percentages\n    count_data = df[column].value_counts().reset_index()\n    count_data.columns = ['Drug Type', 'Count']\n    count_data['Percentage'] = count_data['Count'] / count_data['Count'].sum() * 100\n    \n    # Sort the data by count in descending order\n    count_data = count_data.sort_values('Count', ascending=False)\n    \n    # Calculate the cumulative percentages for positioning\n    count_data['cumulative_percentage'] = count_data['Percentage'].cumsum() - count_data['Percentage'] / 2\n    \n    # Create the base chart\n    base = alt.Chart(count_data).encode(\n        theta=alt.Theta('Count:Q', stack=True),\n        color=alt.Color('Drug Type:N', scale=alt.Scale(scheme='category20')),\n        tooltip=['Drug Type:N', 'Count:Q', alt.Tooltip('Percentage:Q', format='.1f')]\n    )\n\n    # Create the pie chart\n    pie = base.mark_arc(outerRadius=120)\n    \n    # Create text labels\n    text = base.mark_text(radius=150, align='center', baseline='middle').encode(\n        text='Drug Type:N',\n        x=alt.X('Drug Type:N', axis=None),\n        y=alt.Y('cumulative_percentage:Q', axis=None, scale=alt.Scale(range=[0, 360])),\n    )\n    \n    # Combine the pie and text charts\n    chart = (pie + text).properties(\n        title='Distribution of Drug Types',\n        width=400,\n        height=400\n    )\n    \n    return chart\n\n# Create and save the chart\ndrug_type_chart = create_drug_type_pie_chart(df_charges)\ndrug_type_chart.save('Drug_type_descriptions.html')\n\n# Developing the AI-Statute Classifier and makeing waffle chart\nunique_statutes = df_charges['STATUTE'].unique()\nFL_CRIME_CATEGORIES = [\n    \"Violent Crimes\", \"Property Crimes\", \"Drug Offenses\", \"Sex Offenses\", \"White Collar Crimes\",\n    \"Cybercrime\", \"Traffic Offenses\", \"Domestic Offenses\", \"Public Order Crimes\", \"Weapons Offenses\", \"Environmental Crimes\", \"Regulatory Offenses\", \"Procedural Crimes\",\n    \"Organized Crime\", \"Hate Crimes\", \"Financial Crimes\", \"Animal-Related Crimes\",\n    \"Public Integrity Offenses\", \"Miscellaneous Crimes\", \"Law Enforcement-Appended Crimes\", \"DUI\", \"Murder\", \"Crimes Against Children\", \"Rape\"\n]\nstatutes_str = \"\\n\".join(unique_statutes)\nclassifications_str = \"\\n\".join(FL_CRIME_CATEGORIES)\nllm_statute_classifier = ChatOpenAI(openai_api_key=secret_value_0, model = 'gpt-4o-mini')\nprompt_template = ChatPromptTemplate.from_messages([\n    ('system', \"\"\"\n    You are a legal expert tasked with classifying Florida Statutes. Given the following list of statutes and potential classifications, create a mapping between each Florida statute and its most appropriate classification.\n    Please provide your response as a json object. Do not include the json object in code delimiters\"\"\"),\n    ('human',\"Classify the Florida statutes {input_string}\")\n])\n# Create the LLMChain\nllm_chain =  prompt_template | llm_statute_classifier\n# Prepare the input\nstatutes_str = \"\\n\".join(unique_statutes)\nclassifications_str = \"\\n\".join(FL_CRIME_CATEGORIES)\n# Invoke the chain\nresponse = llm_chain.invoke({\n\"input_string\": statutes_str + ' ' + classifications_str\n})\nresponse_dict = json.loads(response.content)\ndf_charges['Statue Category'] = df_charges['STATUTE'].map(response_dict)\n\nvalue_counts = df_charges['Statue Category'].value_counts()\n\n# Convert the value_counts to a DataFrame\ndf = pd.DataFrame({'category': value_counts.index, 'count': value_counts.values})\n\n# Calculate the percentage for each category\ndf['percentage'] = df['count'] / df['count'].sum() * 100\n\n# Set up the dimensions of the waffle chart\nwaffle_size = 100  # Total number of squares\nrows, cols = 10, 10  # 10x10 grid\n\n# Calculate the number of squares for each category\ndf['squares'] = (df['percentage'] / 100 * waffle_size).round().astype(int)\n\n# Create a new dataframe for the waffle chart\nwaffle_data = []\ncurrent_category = 0\ncurrent_square = 0\n\nfor row in range(rows):\n    for col in range(cols):\n        if current_square >= df['squares'].iloc[current_category]:\n            current_category += 1\n            current_square = 0\n            if current_category >= len(df):\n                break\n        \n        waffle_data.append({\n            'row': row,\n            'col': col,\n            'category': df['category'].iloc[current_category],\n            'count': df['count'].iloc[current_category],\n            'percentage': df['percentage'].iloc[current_category]\n        })\n        current_square += 1\n    \n    if current_category >= len(df):\n        break\n\nwaffle_df = pd.DataFrame(waffle_data)\n\n# Create the base waffle chart\nbase = alt.Chart(waffle_df).encode(\n    x=alt.X('col:O', axis=None),\n    y=alt.Y('row:O', axis=None, sort='descending')\n)\n\n# Create the colored squares\nsquares = base.mark_rect(stroke='white', strokeWidth=2).encode(\n    color=alt.Color('category:N', legend=alt.Legend(title=\"Statute Category\")),\n    tooltip=[\n        alt.Tooltip('category:N', title='Statute Category'),\n        alt.Tooltip('count:Q', title='Count'),\n        alt.Tooltip('percentage:Q', title='Percentage', format='.2f')\n    ]\n)\n\n# Create the grid\ngrid = base.mark_rect(fill='none', stroke='lightgray').encode()\n\n# Combine the layers\nwaffle_chart = (grid + squares).properties(\n    title=\"Distribution of Statute Categories (Waffle Chart)\",\n    width=400,\n    height=400\n)\n\n# Save the chart\nwaffle_chart.save('Distribution_of_Statute_Categories(Waffle_Chart).html')\n\n# Create the FCIC Classification, Degree Level Chart\noffense_counts = df_charges['OFFENSE_FCIC_TYPE_DESC'].value_counts().reset_index()\noffense_counts.columns = ['OFFENSE_FCIC_TYPE_DESC', 'count']\n\n# Merge with the original DataFrame to get the Statue Category for each offense\nmerged_df = pd.merge(offense_counts, df_charges[['OFFENSE_FCIC_TYPE_DESC', 'Degree_Level']].drop_duplicates(), \n                     on='OFFENSE_FCIC_TYPE_DESC', how='left')\n\n# Calculate the height based on the number of offense types\nrow_height = 20  # Height per row in pixels\ntotal_height = row_height * len(offense_counts)\n\n# Create the stacked bar chart\noffense_statute = alt.Chart(merged_df).mark_bar().encode(\n    y=alt.Y('OFFENSE_FCIC_TYPE_DESC:N', sort='-x', title='Offense Type'),\n    x=alt.X('count:Q', title='Count'),\n    color=alt.Color('Degree_Level:N', scale=alt.Scale(scheme='category20b'), \n                    legend=alt.Legend(title='Degree_Level')),\n    tooltip=[\n        alt.Tooltip('OFFENSE_FCIC_TYPE_DESC', title='Offense Type'),\n        alt.Tooltip('Degree_Level', title='Degree_Level'),\n        alt.Tooltip('count', title='Count')\n    ]\n).properties(\n    title='Offense Types by Count and Degree_Level',\n    width=600,\n    height=total_height  # Use the calculated total height\n)\n\n# Display the chart\noffense_statute.save('Offense_Types_by_Count_and_Degree_Level.html')\n\nsentence_status_counts = df_charges['SENTENCE_STATUS'].value_counts().reset_index()\nsentence_status_counts.columns = ['SENTENCE_STATUS', 'count']\n\n# Calculate the percentage for each status\nsentence_status_counts['percentage'] = sentence_status_counts['count'] / sentence_status_counts['count'].sum() * 100\n\n# Create the pie chart\nsentence_status_pie_chart = alt.Chart(sentence_status_counts).mark_arc().encode(\n    theta=alt.Theta(field=\"count\", type=\"quantitative\"),\n    color=alt.Color(field=\"SENTENCE_STATUS\", type=\"nominal\", legend=alt.Legend(title=\"Sentence Status\")),\n    tooltip=[\n        alt.Tooltip(\"SENTENCE_STATUS\", title=\"Sentence Status\"),\n        alt.Tooltip(\"count\", title=\"Count\"),\n        alt.Tooltip(\"percentage\", title=\"Percentage\", format=\".2f\")\n    ]\n).properties(\n    title=\"Distribution of Sentence Statuses\",\n    width=400,\n    height=400\n)\n\n# Display the chart\nsentence_status_pie_chart.save('Distribution_of_Sentece_Statuses.html')\n\ngdf = gpd.read_file('/kaggle/input/geojson-data/florida_geojson_file.geojson')\n\nflorida_county_mapping = {\n    'ALACHUA': 'Alachua',\n    'BAKER': 'Baker',\n    'BAY': 'Bay',\n    'BRADFORD': 'Bradford',\n    'BREVARD': 'Brevard',\n    'BROWARD': 'Broward',\n    'CALHOUN': 'Calhoun',\n    'CHARLOTTE': 'Charlotte',\n    'CITRUS': 'Citrus',\n    'CLAY': 'Clay',\n    'COLLIER': 'Collier',\n    'COLUMBIA': 'Columbia',\n    'DESOTO': 'DeSoto',\n    'DE SOTO': 'DeSoto',\n    'DIXIE': 'Dixie',\n    'DUVAL': 'Duval',\n    'ESCAMBIA': 'Escambia',\n    'FLAGLER': 'Flagler',\n    'FRANKLIN': 'Franklin',\n    'GADSDEN': 'Gadsden',\n    'GILCHRIST': 'Gilchrist',\n    'GLADES': 'Glades',\n    'GULF': 'Gulf',\n    'HAMILTON': 'Hamilton',\n    'HARDEE': 'Hardee',\n    'HENDRY': 'Hendry',\n    'HERNANDO': 'Hernando',\n    'HIGHLANDS': 'Highlands',\n    'HILLSBOROUGH': 'Hillsborough',\n    'HOLMES': 'Holmes',\n    'INDIAN RIVER': 'Indian River',\n    'JACKSON': 'Jackson',\n    'JEFFERSON': 'Jefferson',\n    'LAFAYETTE': 'Lafayette',\n    'LAKE': 'Lake',\n    'LEE': 'Lee',\n    'LEON': 'Leon',\n    'LEVY': 'Levy',\n    'LIBERTY': 'Liberty',\n    'MADISON': 'Madison',\n    'MANATEE': 'Manatee',\n    'MARION': 'Marion',\n    'MARTIN': 'Martin',\n    'MIAMI-DADE': 'Miami-Dade',\n    'MIAMI DADE': 'Miami-Dade',\n    'DADE': 'Miami-Dade',\n    'MONROE': 'Monroe',\n    'NASSAU': 'Nassau',\n    'OKALOOSA': 'Okaloosa',\n    'OKEECHOBEE': 'Okeechobee',\n    'ORANGE': 'Orange',\n    'OSCEOLA': 'Osceola',\n    'PALM BEACH': 'Palm Beach',\n    'PASCO': 'Pasco',\n    'PINELLAS': 'Pinellas',\n    'POLK': 'Polk',\n    'PUTNAM': 'Putnam',\n    'ST. JOHNS': 'St. Johns',\n    'SAINT JOHNS': 'St. Johns',\n    'ST JOHNS': 'St. Johns',\n    'SANTA ROSA': 'Santa Rosa',\n    'SARASOTA': 'Sarasota',\n    'SEMINOLE': 'Seminole',\n    'ST. LUCIE': 'St. Lucie',\n    'SAINT LUCIE': 'St. Lucie',\n    'ST LUCIE': 'St. Lucie',\n    'SUMTER': 'Sumter',\n    'SUWANNEE': 'Suwannee',\n    'TAYLOR': 'Taylor',\n    'UNION': 'Union',\n    'VOLUSIA': 'Volusia',\n    'WAKULLA': 'Wakulla',\n    'WALTON': 'Walton',\n    'WASHINGTON': 'Washington'\n}\ndf_charges['County of Conviction'] = df_charges['County_of_Conviction'].map(florida_county_mapping)\ndf_county_convictions = df_charges['County of Conviction'].value_counts().reset_index()\ndf_county_convictions.columns = ['NAME', 'count']\nfor_chloropleth = pd.merge(gdf, df_county_convictions, on = 'NAME')\n# Reproject the data to a projected CRS (e.g., EPSG:3857 - Web Mercator)\nfor_chloropleth = for_chloropleth.to_crs(epsg=3857)\n\n# Calculate the centroid in the projected CRS\ncentroid = for_chloropleth.geometry.centroid.to_crs(epsg=4326)\n\n# Create a base map\nm = folium.Map(location=[centroid.y.mean(), centroid.x.mean()], \n               zoom_start=6)\n\n# Create a colormap\ncolormap = cm.LinearColormap(colors=['yellow', 'orange', 'red'], \n                             vmin=for_chloropleth['count'].min(), \n                             vmax=for_chloropleth['count'].max())\n\n# Add the choropleth layer\nfolium.GeoJson(\n    for_chloropleth.to_crs(epsg=4326),  # Convert back to WGS84 for Folium\n    name='choropleth',\n    style_function=lambda feature: {\n        'fillColor': colormap(feature['properties']['count']),\n        'color': 'black',\n        'weight': 1,\n        'fillOpacity': 0.7,\n    },\n    tooltip=folium.GeoJsonTooltip(fields=['NAME', 'count'],\n                                  aliases=['County', 'Count'],\n                                  style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\"))\n).add_to(m)\n\n# Add the colormap to the map\ncolormap.add_to(m)\n\n# Save the map\nm.save('florida_counties_choropleth.html')","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:23:43.747359Z","iopub.execute_input":"2024-07-27T16:23:43.747826Z","iopub.status.idle":"2024-07-27T16:23:51.570011Z","shell.execute_reply.started":"2024-07-27T16:23:43.747786Z","shell.execute_reply":"2024-07-27T16:23:51.568884Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AI Presentation of the IncarcerationSupervisionCharge_00000 Dataset","metadata":{}},{"cell_type":"code","source":"# Preparing Data for AI\n\n# Overlap\noverlap_data = 'Dataset_Size_Comparison.html' + \"Additional Context: This plot shows the relative sizes of the two datasets `IncarcerationSupervision_00000` and `IncarcerationSupervisionCharges_00000`, as well as the number of common entries in the `INCARCERATION_SUPERVISION_ID` column, which serves as a common unique anonymized identifier. \" + size_comparison_chart.to_json()\n\n# Days Data\ndays_variables = [\n    'CONCURRENT_SENTENCES_SERVED_DAYS',\n    'CONSECUTIVE_SENTENCES_SERVED_DAYS',\n    'SENTENCE_SERVED_DAYS',\n    'SUP_ASSIGNED_TERM_DURATION_DAYS',\n    'GAIN_TIME_EARNED',\n    'MAXIMUM_TERM_DURATION_DAYS',\n    'SUPERVISION_SERVED_DAYS'\n]\ndays_rows = extract_rows(df_charges_content, days_variables)\ndays_context = days_rows + 'Sentencing_Metrics_Explorer:_7_Variables_at_a_Glance.html' + \"\"\"This interactive visualization presents seven histograms, each representing a different variable related to sentencing and supervision. For each variable:\nThe top chart shows the full distribution of all data. You can click and drag on any top chart to select a specific range of days you're interested in. When you do this, the bottom chart for that variable will update to show only the data within your selected range, automatically adjusting its scale to fit this subset of data. This feature lets you zoom in on particular parts of the distribution for each variable, making it easier to examine patterns or details that might be hard to see in the full dataset. You can adjust your selection at any time to explore different ranges, or click outside the selection to reset and view the full distribution again. Each variable can be explored independently, allowing for comparison across all seven measures simultaneously.\"\"\" + \" Additional Context: The most common entry among the few non-null values is 0. These column variables do not appear to represent well-kept data.\"\n\n# Indicators\nindicators_columns = ['HABITUAL_OFNDR_IND', 'HABITUAL_VIOL_FELONY_OFNDR_IND', \n           'PRISON_RELEASEE_REOFNDR_IND', 'VIOLENT_CAREER_CRIM_IND']\nindicators_rows = extract_rows(df_charges_content, indicators_columns)\nindicators_context = indicators_rows + 'Charges_Indicators.html'  + indicators_chart.to_json() + \" Additional Context: These column variables do not appear to represent well-kept data.\"\n\n# Drug Type\ndrug_type_rows = extract_rows(df_charges_content, ['DRUG_TYPE_DESC'])\ndrug_type_context = drug_type_rows + 'Drug_type_descriptions.html' + drug_type_chart.to_json()\n\n# Statutes\nstatute_rows = extract_rows(df_charges_content, ['STATUTE'])\nstatute_context = statute_rows  + 'Distribution_of_Statute_Categories(Waffle_Chart).html'  +  \"Please inform the user of the number of unique values in STATUTE. In an effort to take the many unique statute categories listed, like '817.62.1', into meaningful information, AI mapping from raw statute chapter numbers to offence categories.\" + waffle_chart.to_json()\n\n# Sentence Status\nstatus_rows = extract_rows(df_charges_content, ['SENTENCE_STATUS'])\nsentence_status_context = status_rows  + 'Distribution_of_Sentece_Statuses.html'  + \"Additional Context: Concurrent sentences are sentences that overlap for sentences on other offenses which are considered part of the same criminal event. This means that one day served counts as a day served for both of those two linked-crimes. On the other hand, consecutive sentences are sentences where one must first complete one term before starting the next; they do not overlap. 'Not applicable' just means that the sentences are neither concurrent nor consecutive.\" + sentence_status_pie_chart.to_json()\n\n# Offense Type\noffence_rows = extract_rows(df_charges_content, ['OFFENSE_FCIC_TYPE_DESC', 'Degree_Level'])\noffense_context = offence_rows + 'Offense_Types_by_Count_and_Degree_Level.html'  + \"Additional Context: These crime categories are determined by the FCIC.\" + offense_statute.to_json()\n\n\n# Chloropleth\ncounty_conviction_context =  df_charges['County of Conviction'].value_counts().to_json() + 'florida_counties_choropleth.html' + \" Additional context: The lack of reporting in many counties shows that the value of this map mainly indicates which counties submit data and which do not.\"\n\ncharges_overlap_response = llm_chain_1.invoke({'data_str': 'Subject: Relative Data Sizes and Overlap, Additional Context: This visual compares the size of the dataset of current discussion, IncarcerationSupervisionCharge_00000,  with the dataset presentted just previously, IncarcerationSupervisionCharge_00000. The reasons why there are so few entries in IncarcerationSupervisionCharge_00000 compared to IncarcerationSupervisionCharge_00000, as well as why there are so few common entries, are unknown. Do not offer a data interpretation of the radii for this response. Be succinct with this response.' + overlap_data})\ndays_response = llm_chain_1.invoke({'data_str':  'Subject: Sentence Metrics. Be succinct with this response.' + days_context})\nindicators_response = llm_chain_1.invoke({'data_str': 'Subject: Indicators, Be succint with this response.' + indicators_context})\ndrug_type_response = llm_chain_1.invoke({'data_str': 'Subject: Drug Type, Data Quality Concern: The plot does not appear to represent well-kept data. Be very succint with this response.' + drug_type_context})\nstatute_response = llm_chain_1.invoke({'data_str': 'Subject: Statues' +  statute_context})\nsentence_status_response = llm_chain_1.invoke({'data_str': \"Subject: Sentence Statuses\" + sentence_status_context })\noffence_response = llm_chain_1.invoke({'data_str': 'Subject: FCIC Sentence Offences Categories by Degree Type' + offense_context})\ncounty_conviction_response = llm_chain_1.invoke({'data_str': 'Subject: County of Conviction' + county_conviction_context})\n\ndisplay(Markdown('<span style=\"color: red;\"> \\n\\n# AI Generated Presentation of `IncarcerationSupervisionCharge_00000` and Visualizations\\n\\n' + charges_overlap_response.content + '\\n\\n' + days_response.content + '\\n\\n'+ indicators_response.content + '\\n\\n' + drug_type_response.content + '\\n\\n' + statute_response.content + '\\n\\n' + sentence_status_response.content + '\\n\\n' + offence_response.content + '\\n\\n' + county_conviction_response.content + ' \\n\\n </span>'))","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:23:51.572288Z","iopub.execute_input":"2024-07-27T16:23:51.572644Z","iopub.status.idle":"2024-07-27T16:24:42.445531Z","shell.execute_reply.started":"2024-07-27T16:23:51.572612Z","shell.execute_reply":"2024-07-27T16:24:42.444237Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IncarcerationSupervisionDisciplinary_00000 Dataset","metadata":{}},{"cell_type":"code","source":"# List of columns to drop from the df_dis DataFrame\ndisc_cols_to_drop = ['INCAR_DISCIPLINARY_VIOL_CODE', 'INCAR_DISCIPLINARY_ACTION_CODE', 'UNIQUE_CORRELATION_ID', 'CORRELATION_ID']\n# Drop the specified columns\ndf_dis = df_dis.drop(columns = disc_cols_to_drop)\n\n# Convert specified columns to categorical type for memory efficiency\ncategorical_columns = ['INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC', 'INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC']\nfor col in categorical_columns:\n    df_dis[col] = df_dis[col].astype('category')\n\n# Convert the 'INCAR_SUPERV_CREATED_DATE' column to datetime type    \ndf_dis['INCAR_SUPERV_CREATED_DATE'] = pd.to_datetime(df_dis['INCAR_SUPERV_CREATED_DATE'])\n\n# Define descriptions for each column in df_dis\ndescriptions_dis = [\n    \"Anonymized unique identifier\",\n    \"Description of the type of disciplinary action taken\",\n    \"Description of the type of disciplinary violation\",\n    \"Date when the incarceration/supervision record was created\"\n]\n\n# Function to generate a Markdown table with DataFrame information for df_dis\ndef df_dis_info_markdown(df, descriptions=None, display_output=True):\n    # Get basic DataFrame info\n    rows, cols = df.shape\n    memory_usage = df.memory_usage(deep=True).sum()\n    memory_usage_str = f\"{memory_usage / 1024**2:.2f} MB\" if memory_usage > 1024**2 else f\"{memory_usage / 1024:.2f} KB\"\n    \n    # Construct the Markdown content\n    content = f\"\"\"\n## IncarcerationSupervisionDisciplinary_00000 Data Information:\n- **Rows**: {rows}\n- **Columns**: {cols}\n- **Memory Usage**: {memory_usage_str}\n### Data Details:\n| Column | Non-Null Count | Dtype | Description | Value Distribution |\n|--------|----------------|-------|-------------|---------------------|\n\"\"\"\n    # Iterate through columns to add their details to the Markdown table\n    for i, col in enumerate(df.columns):\n        dtype = df[col].dtype\n        non_null = df[col].count()\n        description = descriptions[i] if descriptions and i < len(descriptions) else \"\"\n        \n        # Determine value distribution based on column type\n        if col == \"INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC\":\n            value_dist = df[col].value_counts().to_dict()\n            value_dist_str = \", \".join([f\"{k}: {v}\" for k, v in value_dist.items()])\n        elif col == \"INCAR_SUPERV_CREATED_DATE\":\n            earliest = df[col].min().strftime('%Y-%m-%d')\n            latest = df[col].max().strftime('%Y-%m-%d')\n            value_dist_str = f\"Earliest: {earliest}, Latest: {latest}\"\n        else:\n            value_dist_str = f\"{df[col].nunique()} unique values\"\n        \n        content += f\"| {col} | {non_null} non-null | {dtype} | {description} | {value_dist_str} |\\n\"\n    \n    # Display the Markdown if display_output is True\n    if display_output:\n        display(Markdown(content))\n    \n    # Return the Markdown content as a string\n    return content\n\n# Generate the Markdown content for df_dis\ndf_dis_content = df_dis_info_markdown(df_dis, descriptions_dis)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:25:51.113539Z","iopub.execute_input":"2024-07-27T16:25:51.114804Z","iopub.status.idle":"2024-07-27T16:25:51.401215Z","shell.execute_reply.started":"2024-07-27T16:25:51.114744Z","shell.execute_reply":"2024-07-27T16:25:51.399967Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating Visualizations for Disciplinary dataset\n# Size Comparison/Overlap Plot\n### Determine the sizes\nsize_large = len(df_root)\nsize_small = len(df_dis['INCARCERATION_SUPERVISION_ID'].unique())\n\n# Dataset names for passing\nlarge_dataset_name = \"IncarcerationSupervision_00000\"\nsmall_dataset_name = \"IncarcerationSupervisionDisciplinary_00000\"\n\n# Find the overlap\nkey_column = 'INCARCERATION_SUPERVISION_ID'\nunique_ids_in_df_dis = df_dis[key_column].unique()\noverlap = df_root[df_root[key_column].isin(unique_ids_in_df_dis)].shape[0]\n\nradius_small = 1\nradius_large = math.sqrt(size_large / size_small)\n\n# Calculate the distance between circle centers based on overlap\noverlap_ratio = overlap / size_small\ndistance = radius_large + radius_small - (overlap_ratio * 2 * radius_small)\n\n# Adjust this factor to bring circles closer together or further apart\ndistance_factor = 0.25  # Experiment with this value\n\n# Create a dataframe for our visualization\nviz_data = pd.DataFrame({\n    'x': [distance * distance_factor, 0],\n    'y': [0, 0],\n    'size': [size_large, size_small],\n    'radius': [radius_large, radius_small],\n    'dataset': [large_dataset_name, small_dataset_name],\n    'overlap': [overlap, overlap]\n})\n\n# Calculate the domain for x and y axes\nmax_radius = max(radius_large, radius_small)\nx_domain = [-max_radius, (distance * distance_factor) + max_radius]\ny_domain = [-max_radius, max_radius]\n\n# Create the base chart\nbase = alt.Chart(viz_data).encode(\n    x=alt.X('x:Q', scale=alt.Scale(domain=x_domain), axis=None),\n    y=alt.Y('y:Q', scale=alt.Scale(domain=y_domain), axis=None)\n)\n\n# Create circles representing dataset sizes\ncircles = base.mark_circle(opacity=0.5).encode(\n    size=alt.Size('radius:Q', scale=alt.Scale(range=[0, 40000]), legend=None),\n    color=alt.Color('dataset:N', \n                    scale=alt.Scale(domain=[large_dataset_name, small_dataset_name], \n                                    range=['blue', 'red']),\n                    legend=alt.Legend(title=\"Datasets\", labelLimit=0)),\n    tooltip=['dataset', 'size', 'overlap']\n)\n\n# Combine all elements\nsize_comparison_chart2 = circles.properties(\n    width=600,\n    height=400,\n    title=f\"Dataset Size Comparison (Overlap: {overlap} persons)\"\n).configure_view(\n    strokeWidth=0\n).configure_legend(\n    labelLimit=0,  # Ensures full names are shown in legend\n    orient='bottom',  # Positions legend at the bottom\n    columns=1,  # Stacks legend entries vertically\n    titleFontSize=14,\n    labelFontSize=12\n)\nsize_comparison_chart2.save('Dataset_Size_Comparison2.html')\n\n# Time series of disciplinary records creation\ndf_dis['INCAR_SUPERV_CREATED_DATE'] = pd.to_datetime(df_dis['INCAR_SUPERV_CREATED_DATE'])\n\n# Group by month and count\nmonthly_counts = df_dis.groupby(df_dis['INCAR_SUPERV_CREATED_DATE'].dt.to_period('M')).size().reset_index(name='count')\nmonthly_counts['INCAR_SUPERV_CREATED_DATE'] = monthly_counts['INCAR_SUPERV_CREATED_DATE'].dt.start_time\n\n# Create the Altair chart\ndis_record_creation_chart = alt.Chart(monthly_counts).mark_line().encode(\n    x=alt.X('INCAR_SUPERV_CREATED_DATE:T', title='Date'),\n    y=alt.Y('count:Q', title='Count'),\n    tooltip=['INCAR_SUPERV_CREATED_DATE:T', 'count:Q']\n).properties(\n    width=600,\n    height=400,\n    title='Time Series of Disciplinary Record Creation by Month'\n)\ndis_record_creation_chart.save('Time_Series_of_Disciplinary_Record_Creation_by_Month.html')\n\ninfractions = df_dis['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].unique()\n\nsystem = \"\"\"You are a Research Coordinator. You will be given a very long list of alleged rule violations by incarcerated or supervised persons under the jurisdiction of the Florida Department of Corrections.\nYou will:\n1. Use the list to compile a list of 10 mutually exclusive categories. Ensure the categories are informative to a broad range of stakeholders.\n2. Return ONLY a dictionary mapping the initial items to the categories you have compiled. Do not comment. Do not open and do not conclude. You will provide the dictionary only.\n3. Do not enclose your dictionary in code delimiters. Do not use newline characters '\\n'.\n4. Do not supply any additional response. \nYour response should be directly parseable as a Python dictionary.\"\"\"\nprompt_template = ChatPromptTemplate.from_messages([\n    ('system', system),\n    ('human', \"{data_str}\")\n])\nllm_2 = ChatOpenAI(openai_api_key=secret_value_0, temperature = 0, model = model) \nllm_chain_2 = prompt_template | llm_2\ninfractions_response = llm_chain_2.invoke(\n    {'data_str': infractions.tolist()})\n\ndict_string = infractions_response.content.replace(\"'\", '\"')\ninfractions_dictionary = json.loads(dict_string)\ndf_dis['alleged_violation_category'] = df_dis['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].map(infractions_dictionary)\ndf_dis['alleged_violation_category'].value_counts()\n\nviolation_counts = df_dis['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].value_counts().reset_index()\nviolation_counts.columns = ['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC', 'count']\n\naction_violation_counts = df_dis.groupby(['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC', 'INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC'], observed=True).size().reset_index(name='count')\n\ncategory_counts = df_dis['alleged_violation_category'].value_counts().reset_index()\ncategory_counts.columns = ['alleged_violation_category', 'count']\n\ncategory_action_counts = df_dis.groupby(['alleged_violation_category', 'INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC'], observed=True).size().reset_index(name='count')\n\n# Get top 50 violations\ntop_50_violations = violation_counts.nlargest(50, 'count')['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].tolist()\n\n# Calculate the total number of unique violations\ntotal_unique_violations = df_dis['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].nunique()\n\n# Define an extended, more accessible color scheme\ncolor_scheme = alt.Scale(range=[\n    '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n    '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',\n    '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5',\n    '#c49c94', '#f7b6d2', '#c7c7c7', '#dbdb8d', '#9edae5'\n])\n\n# First subfigure: Top 50 violations\nviolations_chart = (\n    alt.Chart(action_violation_counts[action_violation_counts['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC'].isin(top_50_violations)])\n    .mark_bar()\n    .encode(\n        y=alt.Y('INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC:N', \n                sort='-x', \n                title='Violation Type'),\n        x=alt.X('sum(count):Q', title='Count'),\n        color=alt.Color('INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC:N', \n                        scale=color_scheme,\n                        legend=alt.Legend(title='Action Type', orient='bottom', columns=3)),\n        tooltip=['INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC', \n                 'INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC', \n                 'sum(count)']\n    )\n    .properties(\n        title=f'Top 50 of {total_unique_violations} Disciplinary Violations',\n        width=800,\n        height=600\n    )\n)\n\n# Second subfigure: Violation categories\ncategories_chart = (\n    alt.Chart(category_action_counts)\n    .mark_bar()\n    .encode(\n        x=alt.X('alleged_violation_category:N', \n                sort='-y', \n                axis=alt.Axis(labelAngle=-45), \n                title='Violation Category'),\n        y=alt.Y('sum(count):Q', title='Count'),\n        color=alt.Color('INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC:N', \n                        scale=color_scheme,\n                        legend=None),\n        tooltip=['alleged_violation_category', \n                 'INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC', \n                 'sum(count)']\n    )\n    .properties(\n        title='Disciplinary Violations by Category',\n        width=800,\n        height=400\n    )\n)\n\n# Combine the two charts vertically\nviolations_by_actions_chart = alt.vconcat(violations_chart, categories_chart)\n\n# Save the chart\nviolations_by_actions_chart.save('Composite_Violations_by_Outcome_Top_50_and_Categorized.html')","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:26:12.579570Z","iopub.execute_input":"2024-07-27T16:26:12.580019Z","iopub.status.idle":"2024-07-27T16:26:31.016484Z","shell.execute_reply.started":"2024-07-27T16:26:12.579982Z","shell.execute_reply":"2024-07-27T16:26:31.014727Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AI Presentation of the IncarcerationSupervisionDisciplinary_00000 Dataset","metadata":{}},{"cell_type":"code","source":"# Generating context for AI Presentation:\noverlap2_context = \"Subject: Overlap with first dataset, html file path: 'Dataset_Size_Comparison2.html', This visualization shows the relative size comparison between the current dataset, `IncarcerationSupervisionDisciplinary_00000`, and the initially presented dataset, `IncarcerationSupervision_00000`. at this time the depicted shared area between the circles only approximates the overlap between datasets, given the complexity of finding the area shared between two overlapping circles.\" + size_comparison_chart2.to_json()\n\nrecord_creation_date_row = extract_rows(df_dis_content, ['INCAR_SUPERV_CREATED_DATE']) \nrecord_creation_date_context = \"Subject: Disciplinary Record Creation Dates, html file path: 'Time_Series_of_Disciplinary_Record_Creation_by_Month.html'\" + dis_record_creation_chart.to_json() + record_creation_date_row\n\ninfractions_actions_columns = ['INCARCERATION_DISCIPLINARY_ACTION_TYPE_DESC', 'INCARCERATION_DISCIPLINARY_VIOLATION_TYPE_DESC']\ninfractions_actions_rows = extract_rows(df_dis_content, infractions_actions_columns)\ninfractions_actions_context = \"\"\"Subject: Alleged Disciplinary Infactions and Outcomes, html file path: 'Composite_Violations_by_Outcome_Top_50_and_Categorized.html' **Please allow this figure a height of 1500 and a width of 1000, example: <div style=\"width: 1000px; height: 1500px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">**\"\"\" + infractions_actions_rows + df_dis['alleged_violation_category'].value_counts().to_markdown() + \"\"\"Context: Given the large number of unique rule violation categories in the Florida Department of Corrections data, AI mapping from the raw rule values into categories has been employed. <<context for AI only: It would add appeal to your response if you inform the user that the AI chatbot embedded at the end of this document has been trained to let users specify their own categories of rule infractions for review.>>\"\"\"\n\n# Generating AI Presentation:\noverlap2_response = llm_chain_1.invoke({'data_str': overlap2_context + \"Additional Instruction: The radii of the circles are not informative in this context; please do not comment on them. Please be succinct with this response.\"})\nrecord_creation_date_response = llm_chain_1.invoke({'data_str': record_creation_date_context})\ninfractions_actions_response = llm_chain_1.invoke({'data_str': infractions_actions_context})\n\ndisplay(Markdown('<span style=\"color: red;\"> \\n\\n# AI Generated Presentation of `IncarcerationSupervisionDisciplinary_00000` and Visualizations\\n\\n' + '\\n\\n' + overlap2_response.content + '\\n\\n' +  record_creation_date_response.content + '\\n\\n' + infractions_actions_response.content + ' \\n\\n </span>'))","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:26:33.819044Z","iopub.execute_input":"2024-07-27T16:26:33.819488Z","iopub.status.idle":"2024-07-27T16:26:53.152546Z","shell.execute_reply.started":"2024-07-27T16:26:33.819450Z","shell.execute_reply":"2024-07-27T16:26:53.151369Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Prepare categorical columns\ncategorical_columns = ['RACE_CODE', 'SEX_CODE', 'ETHNICITY_CODE', 'CORRECTION_ADMISSION_REASON_DESC', \n                       'CURRENT_INSTITUTION_ORI_TYPE_DESC', 'CUSTODY_RELEASE_REASON_DESC', \n                       'SUPERVISION_CATEGORY_DESC', 'COUNTY_DESCRIPTION', 'HIGHEST_EDUCATION_LEVEL',\n                       'INCARCERATION_CUSTODY_LEVEL_TYPE_DESC']\n\n# 3. Add new categories and fill nulls for all relevant columns\nnew_categories = {\n    'CUSTODY_RELEASE_REASON_DESC': 'Not Released',\n    'INCARCERATION_CUSTODY_LEVEL_TYPE_DESC': 'Unknown',\n    'SUPERVISION_CATEGORY_DESC': 'Not Under Supervision',\n    'HIGHEST_EDUCATION_LEVEL': 'Missing'\n}\n\nfor col in categorical_columns:\n    if col in new_categories:\n        # If the column is already categorical, add the new category\n        if df_root[col].dtype.name == 'category':\n            df_root[col] = df_root[col].cat.add_categories([new_categories[col]])\n        # Fill null values with the new category\n        df_root[col] = df_root[col].fillna(new_categories[col])\n    else:\n        # For other categorical columns, use 'Missing' as the fill value\n        if df_root[col].dtype.name == 'category':\n            df_root[col] = df_root[col].cat.add_categories(['Missing'])\n        df_root[col] = df_root[col].fillna('Missing')\n    \n    # Ensure the column is of categorical type\n    df_root[col] = df_root[col].astype('category')\n\n\n# 5. Ensure 'race_ethnicity' is categorical\ndf_root['race_ethnicity'] = df_root['race_ethnicity'].astype('category')","metadata":{"execution":{"iopub.status.busy":"2024-07-27T15:17:08.440162Z","iopub.execute_input":"2024-07-27T15:17:08.440586Z","iopub.status.idle":"2024-07-27T15:17:08.476342Z","shell.execute_reply.started":"2024-07-27T15:17:08.440555Z","shell.execute_reply":"2024-07-27T15:17:08.475307Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def simplify_text(text):\n    # Remove iframe tags\n    text = re.sub(r'<div[^>]*>.*?<iframe[^>]*>.*?</iframe>.*?</div>', '', text, flags=re.DOTALL)\n    \n    # Simplify headers\n    text = re.sub(r'#{1,6}\\s*', '', text)\n    \n    # Remove bold markdown\n    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)\n    \n    # Remove unnecessary newlines and spaces\n    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n    text = re.sub(r' {2,}', ' ', text)\n    \n    return text.strip()\ndf_root_presentation = demographic_response.content + '\\n\\n' + education_response.content + '\\n\\n' + dates_response.content + '\\n\\n' + reasons_response.content + '\\n\\n' + tags_response.content + '\\n\\n' + institutional_response.content + '\\n\\n' + location_response.content\ndf_charges_presentation = charges_overlap_response.content + '\\n\\n' + days_response.content + '\\n\\n'+ indicators_response.content + '\\n\\n' + drug_type_response.content + '\\n\\n' + statute_response.content + '\\n\\n' + sentence_status_response.content + '\\n\\n' + offence_response.content + '\\n\\n' + county_conviction_response.content\ndf_dis_presentation = overlap2_response.content + '\\n\\n' +  record_creation_date_response.content + '\\n\\n' + infractions_actions_response.content\n\ndf_root_presentation_cleaned = simplify_text(df_root_presentation)\ndf_charges_presentation_cleaned = simplify_text(df_charges_presentation)\ndf_dis_presentation_cleaned = simplify_text(df_dis_presentation)\n\nbuffer = io.StringIO()\nwith redirect_stdout(buffer):\n    df_root.info()\ndf_root_info_string = buffer.getvalue()\nwith redirect_stdout(buffer):\n    df_charges.info()\ndf_charges_info_string = buffer.getvalue()\nwith redirect_stdout(buffer):\n    df_dis.info()\ndf_dis_info_string = buffer.getvalue()","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:28:20.495391Z","iopub.execute_input":"2024-07-27T16:28:20.495907Z","iopub.status.idle":"2024-07-27T16:28:20.603204Z","shell.execute_reply.started":"2024-07-27T16:28:20.495868Z","shell.execute_reply":"2024-07-27T16:28:20.601500Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Current Experimental Version AI Chatbot","metadata":{}},{"cell_type":"code","source":"class CodingAgent:\n    def __init__(self, model: str = model, max_error_length: int = 500):\n        self.model = model\n        self.llm = ChatOpenAI(openai_api_key=secret_value_0, temperature=0, model=self.model)\n        self.max_error_length = max_error_length\n\n    def generate_step_by_step_plan(self, user_plan: str, context: str) -> str:\n        system = f\"\"\"You are the project manager for a Python data analytics project. The structure of the project is as follows: A user generates a query for an agent. The agent will then develop a broad plan to accomplish the query task. Next, the agent will pass the broad plan to you, along with the user's query.\nYour role is to take the broad plan and the context to generate a psudocode step-by-step coding plan, which you will then return. Your response will be delivered directly to the coding agent to write the code. You will not write any Python code yourself. As project manager, your role is to develop a detailed sequential psudocode plan for the coding agent. Use the exact and precise variables and variable category values from the data available to you. For visualizations, always plan to use Altair, not Matplotlib or Seaborn. Ensure the visualization is published by saving the Altair plot object as an html file, and also print the file path where the file will be saved. You will not provide any additional comments or invitations to continue the conversation; you will provide the psudocode step-by-step plan for the coding agent only. You will not wrap your response in code delimiters because you will not write code, you will produce a psudocode step-by-step plan only. The datasets InacerationSupervision_00000, InacerationSupervisionCharge_00000, and InacerationSupervisiondisciplinary_00000 are currently loaded in the coding environment as df_root, df_charges, and df_dis, respectively. The current structures are InacerationSupervision_00000: {df_root_info_string}, InacerationSupervisionCharge_00000: {df_charges_info_string}, and InacerationSupervisiondisciplinary_00000: {df_dis_info_string}. For additional context, here is a presentation of each dataset: InacerationSupervision_00000 (df_root): {df_root_presentation_cleaned}, InacerationSupervisionCharge_00000 (df_charges): {df_charges_presentation_cleaned}, and InacerationSupervisiondisciplinary_00000 (df_dis): {df_dis_presentation_cleaned}.\"\"\"\n        \n        prompt_template = ChatPromptTemplate.from_messages([\n            ('system', system),\n            ('human', f\"Context: {context}, user's plan: {user_plan}\")\n        ])\n        \n        llm_chain = prompt_template | self.llm\n        response = llm_chain.invoke({'context': context, 'user_plan': user_plan})\n        return response.content\n\n    def generate_code(self, step_by_step_plan: str) -> str:\n        system = f\"\"\"Based on the provided step-by-step plan, generate the appropriate Python code to execute these steps.\n\nThe datasets InacerationSupervision_00000, InacerationSupervisionCharge_00000, and InacerationSupervisiondisciplinary_00000 are currently loaded in the coding environment as `df_root`, `df_charges`, and `df_dis`, respectively. The current structures are:\n\n- InacerationSupervision_00000 (`df_root`): `{df_root_info_string}`\n- InacerationSupervisionCharge_00000 (`df_charges`): `{df_charges_info_string}`\n- InacerationSupervisiondisciplinary_00000 (`df_dis`): `{df_dis_info_string}`.\n\nIf you use the `.groupby()` function, pass the argument `observed=True` to it, for example: `groupby('grouping_variable', observed=True)`.\n\n**Return only the code, without any explanations.**\n\n**Do not wrap the code in triple backticks**, the string you provide should be directly executable when passed to `exec()`.\n\nEnsure you include a `print()` statement to capture any textual code outputs.\n\nFor visualizations, always use Altair, not Matplotlib or Seaborn.\n\nEnsure the visualization is published by saving the Altair plot object using the `.save()` method, and also print the file path where you saved the file.\n\n- For an Altair plot titled 'Pie Chart', for example, you will save the Altair plot object as `plot.save('Pie_Chart.html')` and `print('Altair plot saved to \"Pie_Chart.html\"')`.\n\nIf the plan you receive for a visualization conflicts with these instructions, you should ignore those aspects of the plan.\n\nAltair plot objects should be saved as HTML files, not PNG or other formats, and the filepath should be printed for image publication.\nDO NOT WRAP YOUR CODE IN TRIPLE BACKTICKS!\n        \"\"\"\n        \n        prompt_template = ChatPromptTemplate.from_messages([\n            ('system', system),\n            ('human', f\"Step-by-step plan: {step_by_step_plan}\")\n        ])\n        \n        llm_chain = prompt_template | self.llm\n        response = llm_chain.invoke({'step_by_step_plan': step_by_step_plan})\n        return response.content\n\n    def truncate_error(self, error_message: str) -> str:\n        if len(error_message) > self.max_error_length:\n            return error_message[:self.max_error_length] + \"... (truncated)\"\n        return error_message\n\n    def execute_code(self, code: str) -> Dict[str, Any]:\n        old_stdout = sys.stdout\n        redirected_output = sys.stdout = StringIO()\n        try:\n            exec(code, globals())\n            output = redirected_output.getvalue()\n            return {\n                \"status\": \"success\",\n                \"output\": self.truncate_error(output)\n            }\n        except Exception as e:\n            return {\n                \"status\": \"error\",\n                \"error_message\": self.truncate_error(str(e)),\n                \"problematic_code\": code\n            }\n        finally:\n            sys.stdout = old_stdout\n\n    def process_request(self, user_plan: str, context: str) -> Dict[str, Any]:\n        step_by_step_plan = self.generate_step_by_step_plan(user_plan, context)\n        generated_code = self.generate_code(step_by_step_plan)\n        execution_result = self.execute_code(generated_code)\n        \n        return {\n            \"step_by_step_plan\": step_by_step_plan,\n            \"generated_code\": generated_code,\n            \"execution_result\": execution_result\n        }","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:44:21.505263Z","iopub.execute_input":"2024-07-27T16:44:21.505740Z","iopub.status.idle":"2024-07-27T16:44:21.528499Z","shell.execute_reply.started":"2024-07-27T16:44:21.505704Z","shell.execute_reply":"2024-07-27T16:44:21.526964Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def chat_with_bot(user_input, llm, memory, coding_agent):\n    # Add the user's message to the memory\n    memory.chat_memory.add_user_message(user_input)\n    \n    # Create a list of messages\n    messages = memory.chat_memory.messages\n    \n    # Check if the system message is already present\n    system_message_present = any(isinstance(msg, SystemMessage) for msg in messages)\n    \n    # If the system message is not present, add it\n    if not system_message_present:\n        agent_instructions = f\"\"\"You are a data project manager, helping users explore data loaded into the current coding environment. Your primary role is to assist users by directing projects which analyze and visualize the datasets InacerationSupervision_00000, InacerationSupervisionCharge_00000, and InacerationSupervisiondisciplinary_00000, which are currently loaded in the coding environment as df_root, df_charges, and df_dis, respectively.\n\nInstructions:\n1. When a user's query requires code execution or data manipulation, you will manage the project by first verifying you have the necessary data. Then, create a broad plain language plan that includes which variables to use and how to use them. You have the autonomy to execute any plan by passing it to the coding agent, who will handle all code planning and coding. Do NOT micromanage the coding agent. Just ensure you have the variables needed to answer the user's query and provide the coding agent with a general plain language plan outlining which variables will be used and how. As project manager you do not know how to code, you will only approve plans where all the data needed is present, but you will not handle anything beyond passing the coding agent a broad plan on which variables will me used and in which way. Use the exact and precise variables and variable category values from the data available to you.\n2. Use the [EXECUTE] ... [/EXECUTE] format to pass the plain language plan to the coding agent. Do not pass json data to the coding agent.\n3. Always alert users that plan execution may take a few moments after passing the plan to the coding agent.\n4. If plan execution fails, explain the issue, reassess project feasability, and try again if you can succeed with a modified plan.\n5. If unable to answer a query, throughly explain why.\n7. Explain all coding agent results in context of all available information. Present the reasoning of the coding agent in plain language before the results.\n8. Always display all Altair plots inline with your response using the format: [ALTAIR_PLOT:filename.html].\n\nDataset Information:\n- Dataset names: IncarcerationSupervision_00000, InacerationSupervisionCharge_00000, InacerationSupervisiondisciplinary_00000\n- Loaded as: df_root, df_charges, df_dis\n- Columns: df_root: {df_root.columns}, df_charges: {df_charges.columns}, df_dis{df_dis.columns}\n\nPresentation of the datasets (extended context):\n{df_root_presentation_cleaned}, {df_charges_presentation_cleaned}, {df_dis_presentation_cleaned}\n\nRemember, your role is to guide any potential analysis and explain the data, NOT to execute code directly. Always provide clear, context-rich explanations and be prepared to adjust your approach based on user feedback or failed execution attempts.\"\"\"\n        messages.insert(1, SystemMessage(content=agent_instructions))\n    \n    # Create a widget to display the streaming output\n    output_widget = widgets.Output()\n    display(output_widget)\n    \n    # Function to display Altair plots\n    def display_plot(filename):\n        iframe_html = f'''\n        <div style=\"width: 800px; height: 600px; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n        <iframe src=\"{filename}\" style=\"width: 100%; height: 100%; border: none;\"></iframe>\n        </div>\n        '''\n        display(HTML(iframe_html))\n\n    # Function to update the output widget\n    def update_output(new_text):\n        output_widget.clear_output(wait=True)\n        with output_widget:\n            # Split the text into parts\n            parts = re.split(r'(\\[ALTAIR_PLOT:[^\\]]+\\])', new_text)\n            for part in parts:\n                if part.startswith('[ALTAIR_PLOT:'):\n                    # Extract filename and display plot\n                    filename = part[13:-1]  # Remove [ALTAIR_PLOT: and ]\n                    try:\n                        display_plot(filename)\n                    except FileNotFoundError:\n                        print(f'[Error: Plot file {filename} not found]')\n                else:\n                    # Display text in red\n                    display(HTML(f'<div style=\"color: red;\">{markdown(part)}</div>'))\n    \n    # Generate a streaming response from the AI\n    full_response = \"\"\n    for chunk in llm.stream(messages):\n        if chunk.content is not None:\n            full_response += chunk.content\n            update_output(full_response)\n            time.sleep(0.05)  # Add a small delay for smoother streaming\n    \n    # Check if the AI wants to execute a plan\n    if \"[EXECUTE]\" in full_response:\n        plan_start = full_response.index(\"[EXECUTE]\") + len(\"[EXECUTE]\")\n        plan_end = full_response.index(\"[/EXECUTE]\")\n        plan = full_response[plan_start:plan_end].strip()\n        \n        try:\n            agent_result = coding_agent.process_request(user_plan=plan, context=user_input)\n            if agent_result['execution_result']['status'] == 'error':\n                error_message = f\"Error in code execution: {agent_result['execution_result']['error_message']}\"\n                if 'fixed_code' in agent_result['execution_result']:\n                    error_message += f\"\\nAttempted fix:\\n{agent_result['execution_result']['fixed_code']}\"\n                messages.append(SystemMessage(content=error_message))\n            else:\n                # Truncate the agent result for the message\n                truncated_result = {\n                    \"step_by_step_plan\": agent_result[\"step_by_step_plan\"],\n                    \"generated_code\": agent_result[\"generated_code\"],\n                    \"execution_result\": {\n                        \"status\": agent_result[\"execution_result\"][\"status\"],\n                        \"output\": coding_agent.truncate_error(agent_result[\"execution_result\"][\"output\"])\n                    }\n                }\n                messages.append(SystemMessage(content=f\"Coding Agent Result: {truncated_result}\"))\n        except Exception as e:\n            messages.append(SystemMessage(content=f\"Error in Coding Agent: {coding_agent.truncate_error(str(e))}\"))\n        \n        # Stream the new response\n        new_response = \"\"\n        for chunk in llm.stream(messages):\n            if chunk.content is not None:\n                new_response += chunk.content\n                update_output(new_response)\n                time.sleep(0.05)\n        \n        full_response = new_response\n    \n    # Add the AI's response to the memory\n    memory.chat_memory.add_ai_message(full_response)\n    \n    return full_response\n\ndef run_interactive_chat_v3():\n    llm = ChatOpenAI(openai_api_key=secret_value_0, model=model, streaming=True)\n    memory = ConversationBufferWindowMemory(k=5)\n    coding_agent = CodingAgent(max_error_length=500)  # Set max error length to 500 characters\n    \n    buffer = StringIO()\n    df_root.info(buf=buffer)\n    df_root_info_str = buffer.getvalue()\n    \n    print(\"Welcome to the AI Chatbot! Type 'quit' to exit.\")\n    \n    while True:\n        user_input = input(\"You: \")\n        if user_input.lower() == 'quit':\n            print(\"Thanks for chatting! Goodbye.\")\n            break\n        \n        response = chat_with_bot(user_input, llm, memory, coding_agent)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:57:10.978300Z","iopub.execute_input":"2024-07-27T16:57:10.978762Z","iopub.status.idle":"2024-07-27T16:57:11.009232Z","shell.execute_reply.started":"2024-07-27T16:57:10.978724Z","shell.execute_reply":"2024-07-27T16:57:11.007751Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_interactive_chat_v3()","metadata":{"execution":{"iopub.status.busy":"2024-07-27T16:57:14.319342Z","iopub.execute_input":"2024-07-27T16:57:14.319787Z","iopub.status.idle":"2024-07-27T16:58:51.873726Z","shell.execute_reply.started":"2024-07-27T16:57:14.319752Z","shell.execute_reply":"2024-07-27T16:58:51.872370Z"},"trusted":true},"execution_count":null,"outputs":[]}]}